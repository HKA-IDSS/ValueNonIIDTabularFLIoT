{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..' + os.sep + '..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import xgboost as xgb\n",
    "import prince\n",
    "import scipy\n",
    "import plotly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 21:47:04.745482: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-08 21:47:05.007624: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-08 21:47:05.681361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from experiment_parameters.model_builder.Model import XGBoostModel\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_ROUTE_MAIN_DIR = \"..\" + os.sep + \"..\" + os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_route(dataset_name, type_of_partition, additional_parameter):\n",
    "    if type_of_partition == \"manual\":\n",
    "        path_to_train_datasets = CONST_ROUTE_MAIN_DIR + \"data\" + os.sep + \"partitioned_training_data\" + os.sep + type_of_partition + os.sep + additional_parameter\n",
    "    else:\n",
    "        path_to_train_datasets = CONST_ROUTE_MAIN_DIR + \"data\" + os.sep + \"partitioned_training_data\" + os.sep + type_of_partition + os.sep + \"dataset_\" + dataset_name + os.sep + \"alpha_\" + additional_parameter\n",
    "\n",
    "    return path_to_train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_route(dataset_name, type_of_partition, additional_parameter):\n",
    "    # path_to_result_dataframes = CONST_ROUTE_MAIN_DIR + \"results\" + os.sep + \"FedAvg\" + os.sep + dataset_name + os.sep + type_of_partition + os.sep + additional_parameter + os.sep + \"mlp\"\n",
    "    if type_of_partition == \"dirichlet\":\n",
    "        path_to_result_dataframes = CONST_ROUTE_MAIN_DIR + \"results\" + os.sep + \"dataframes\" + os.sep + \"FedAvg\" + os.sep + dataset_name + os.sep + type_of_partition + os.sep + \"alpha_\" + additional_parameter + os.sep + \"mlp\"\n",
    "    else:\n",
    "        path_to_result_dataframes = CONST_ROUTE_MAIN_DIR + \"results\" + os.sep + \"dataframes\" + os.sep + \"FedAvg\" + os.sep + dataset_name + os.sep + type_of_partition + os.sep + additional_parameter + os.sep + \"mlp\"\n",
    "    return path_to_result_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances_from_route(dataset_name, type_of_partition, additional_parameter):\n",
    "    path_to_result_dataframes = CONST_ROUTE_MAIN_DIR + \"results\" + os.sep + \"distances_values\" + os.sep + dataset_name + os.sep + type_of_partition + os.sep + additional_parameter\n",
    "    return path_to_result_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "\n",
    "def number_of_clients_and_all_combinations(path_to_train_datasets):\n",
    "    num_clients = int(len(os.listdir(path_to_train_datasets)) / 4)\n",
    "    client_numbers_original_order = list(range(num_clients))\n",
    "    client_numbers_reverse_order = list(range(num_clients - 1, -1, -1))\n",
    "\n",
    "    all_combinations = list(combinations_with_replacement(client_numbers_original_order, 2)) + list(combinations_with_replacement(client_numbers_reverse_order, 2))\n",
    "    all_combinations = sorted(list(set(all_combinations)))\n",
    "    print(all_combinations)\n",
    "    return num_clients, all_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_types(dataframe):\n",
    "    for column in dataframe.select_dtypes(\"int\"):\n",
    "        dataframe[column] = dataframe[column].astype(\"int16\")\n",
    "\n",
    "    for column in dataframe.select_dtypes(\"float\"):\n",
    "        dataframe[column] = dataframe[column].astype(\"float32\")\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distances measuring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : CUDA was detected, but driver API could not be initialized. Switching to CPU only.\n"
     ]
    }
   ],
   "source": [
    "from metrics.Distances import compute_coupling, compute_CE\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "import torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geomloss import SamplesLoss\n",
    "\n",
    "def wasserstein_distance(src_x, tar_x):\n",
    "    # Define a Sinkhorn (~Wasserstein) loss between sampled measures\n",
    "    loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.01, scaling=0.8) # Although the euclidean distance usually square's root the results, it is not done here. No clue.\n",
    "\n",
    "    L = loss(torch.tensor(src_x.values).type(dtype), torch.tensor(tar_x.values).type(dtype))  # By default, use constant weights = 1/number of samples\n",
    "    if use_cuda:\n",
    "        torch.cuda.synchronize()\n",
    "    return 2 * L.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mmd_distance(src_x, tar_x):\n",
    "    # Define a Gaussian MMD loss between sampled measures\n",
    "    loss = SamplesLoss(loss=\"gaussian\", blur=0.05) # Although the euclidean distance usually square's root the results, it is not done here. No clue.\n",
    "\n",
    "    L = loss(torch.tensor(src_x.values).type(dtype), torch.tensor(tar_x.values).type(dtype))  # By default, use constant weights = 1/number of samples\n",
    "    if use_cuda:\n",
    "        torch.cuda.synchronize()\n",
    "    return L.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_X_training, global_y_training = dataset_model_dictionary[\"covertype\"]().get_dataset().get_training_data()\n",
    "# global_X_test, global_y_test = dataset_model_dictionary[\"covertype\"]().get_dataset().get_test_data()\n",
    "\n",
    "# display(wasserstein_distance(global_X_training, global_X_test))\n",
    "# display(gaussian_mmd_distance(global_X_training, global_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def optimal_transport_conditional_entropy(src_x, src_y, tar_x, tar_y):\n",
    "#     P, W = compute_coupling(src_x, tar_x, src_y, tar_y)\n",
    "#     # compute the conditonal entropy (ce)\n",
    "#     ce = compute_CE(P, src_y, tar_y)\n",
    "#     print('Wasserstein distance:%.4f, Conditonal Entropy: %.4f' % (W, ce))\n",
    "\n",
    "#     return W, ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(optimal_transport_conditional_entropy(torch.tensor(global_X_training.to_numpy(), dtype=torch.float), np.argmax(global_y_training, axis=1).astype(int), torch.tensor(global_X_test.to_numpy(), dtype=torch.float), np.argmax(global_y_test, axis=1).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def regularized_h_score(features: np.ndarray, labels: np.ndarray):\n",
    "#     r\"\"\"\n",
    "#     Regularized H-score in `Newer is not always better: Rethinking transferability metrics, their peculiarities, stability and performance (NeurIPS 2021)\n",
    "#     <https://openreview.net/pdf?id=iz_Wwmfquno>`_.\n",
    "\n",
    "#     The  regularized H-Score :math:`\\mathcal{H}_{\\alpha}` can be described as:\n",
    "\n",
    "#     .. math::\n",
    "#         \\mathcal{H}_{\\alpha}=\\operatorname{tr}\\left(\\operatorname{cov}_{\\alpha}(f)^{-1}\\left(1-\\alpha \\right)\\operatorname{cov}\\left(\\mathbb{E}[f \\mid y]\\right)\\right)\n",
    "\n",
    "#     where :math:`f` is the features extracted by the model to be ranked, :math:`y` is the groud-truth label vector and :math:`\\operatorname{cov}_{\\alpha}` the  Ledoit-Wolf\n",
    "#     covariance estimator with shrinkage parameter :math:`\\alpha`\n",
    "#     Args:\n",
    "#         features (np.ndarray):features extracted by pre-trained model.\n",
    "#         labels (np.ndarray):  groud-truth labels.\n",
    "\n",
    "#     Shape:\n",
    "#         - features: (N, F), with number of samples N and feature dimension F.\n",
    "#         - labels: (N, ) elements in [0, :math:`C_t`), with target class number :math:`C_t`.\n",
    "#         - score: scalar.\n",
    "#     \"\"\"\n",
    "#     f = features.astype('float64')\n",
    "#     f = f - np.mean(f, axis=0, keepdims=True)  # Center the features for correct Ledoit-Wolf Estimation\n",
    "#     y = labels\n",
    "\n",
    "#     C = int(y.max() + 1)\n",
    "#     g = np.zeros_like(f)\n",
    "\n",
    "#     cov = LedoitWolf(assume_centered=False).fit(f)\n",
    "#     alpha = cov.shrinkage_\n",
    "#     covf_alpha = cov.covariance_\n",
    "\n",
    "#     for i in range(C):\n",
    "#         Ef_i = np.mean(f[y == i, :], axis=0)\n",
    "#         g[y == i] = Ef_i\n",
    "\n",
    "#     covg = np.cov(g, rowvar=False)\n",
    "#     score = np.trace(np.dot(np.linalg.pinv(covf_alpha, rcond=1e-15), (1 - alpha) * covg))\n",
    "\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_conditional_entropy(source_labels: np.ndarray, target_labels: np.ndarray):\n",
    "    r\"\"\"\n",
    "    Negative Conditional Entropy in `Transferability and Hardness of Supervised\n",
    "    Classification Tasks (ICCV 2019) <https://arxiv.org/pdf/1908.08142v1.pdf>`_.\n",
    "\n",
    "    The NCE :math:`\\mathcal{H}` can be described as:\n",
    "\n",
    "    .. math::\n",
    "        \\mathcal{H}=-\\sum_{y \\in \\mathcal{C}_t} \\sum_{z \\in \\mathcal{C}_s} \\hat{P}(y, z) \\log \\frac{\\hat{P}(y, z)}{\\hat{P}(z)}\n",
    "\n",
    "    where :math:`\\hat{P}(z)` is the empirical distribution and :math:`\\hat{P}\\left(y \\mid z\\right)` is the empirical\n",
    "    conditional distribution estimated by source and target label.\n",
    "\n",
    "    Args:\n",
    "        source_labels (np.ndarray): predicted source labels.\n",
    "        target_labels (np.ndarray): groud-truth target labels.\n",
    "\n",
    "    Shape:\n",
    "        - source_labels: (N, ) elements in [0, :math:`C_s`), with source class number :math:`C_s`.\n",
    "        - target_labels: (N, ) elements in [0, :math:`C_t`), with target class number :math:`C_t`.\n",
    "    \"\"\"\n",
    "    C_t = int(np.max(target_labels) + 1)\n",
    "    C_s = int(np.max(source_labels) + 1)\n",
    "    N = len(source_labels)\n",
    "\n",
    "    joint = np.zeros((C_t, C_s), dtype=float)  # placeholder for the joint distribution, shape [C_t, C_s]\n",
    "    for s, t in zip(source_labels, target_labels):\n",
    "        s = int(s)\n",
    "        t = int(t)\n",
    "        joint[t, s] += 1.0 / N\n",
    "    p_z = joint.sum(axis=0, keepdims=True)\n",
    "\n",
    "    p_target_given_source = (joint / p_z).T  # P(y | z), shape [C_s, C_t]\n",
    "    mask = p_z.reshape(-1) != 0  # valid Z, shape [C_s]\n",
    "    p_target_given_source = p_target_given_source[mask] + 1e-20  # remove NaN where p(z) = 0, add 1e-20 to avoid log (0)\n",
    "    entropy_y_given_z = np.sum(- p_target_given_source * np.log(p_target_given_source), axis=1, keepdims=True)\n",
    "    conditional_entropy = np.sum(entropy_y_given_z * p_z.reshape((-1, 1))[mask])\n",
    "\n",
    "    return -conditional_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import njit\n",
    "\n",
    "# def log_maximum_evidence(features: np.ndarray, targets: np.ndarray, regression=False, return_weights=False):\n",
    "#     r\"\"\"\n",
    "#     Log Maximum Evidence in `LogME: Practical Assessment of Pre-trained Models\n",
    "#     for Transfer Learning (ICML 2021) <https://arxiv.org/pdf/2102.11005.pdf>`_.\n",
    "\n",
    "#     Args:\n",
    "#         features (np.ndarray): feature matrix from pre-trained model.\n",
    "#         targets (np.ndarray): targets labels/values.\n",
    "#         regression (bool, optional): whether to apply in regression setting. (Default: False)\n",
    "#         return_weights (bool, optional): whether to return bayesian weight. (Default: False)\n",
    "\n",
    "#     Shape:\n",
    "#         - features: (N, F) with element in [0, :math:`C_t`) and feature dimension F, where :math:`C_t` denotes the number of target class\n",
    "#         - targets: (N, ) or (N, C), with C regression-labels.\n",
    "#         - weights: (F, :math:`C_t`).\n",
    "#         - score: scalar.\n",
    "#     \"\"\"\n",
    "#     f = features.astype(np.float64)\n",
    "#     y = targets\n",
    "#     if regression:\n",
    "#         y = targets.astype(np.float64)\n",
    "\n",
    "#     fh = f\n",
    "#     f = f.transpose()\n",
    "#     D, N = f.shape\n",
    "#     v, s, vh = np.linalg.svd(f @ fh, full_matrices=True)\n",
    "\n",
    "#     evidences = []\n",
    "#     weights = []\n",
    "#     if regression:\n",
    "#         C = y.shape[1]\n",
    "#         for i in range(C):\n",
    "#             y_ = y[:, i]\n",
    "#             evidence, weight = each_evidence(y_, f, fh, v, s, vh, N, D)\n",
    "#             evidences.append(evidence)\n",
    "#             weights.append(weight)\n",
    "#     else:\n",
    "#         C = int(y.max() + 1)\n",
    "#         for i in range(C):\n",
    "#             y_ = (y == i).astype(np.float64)\n",
    "#             evidence, weight = each_evidence(y_, f, fh, v, s, vh, N, D)\n",
    "#             evidences.append(evidence)\n",
    "#             weights.append(weight)\n",
    "\n",
    "#     score = np.mean(evidences)\n",
    "#     weights = np.vstack(weights)\n",
    "\n",
    "#     if return_weights:\n",
    "#         return score, weights\n",
    "#     else:\n",
    "#         return score\n",
    "\n",
    "\n",
    "# @njit\n",
    "# def each_evidence(y_, f, fh, v, s, vh, N, D):\n",
    "#     \"\"\"\n",
    "#     compute the maximum evidence for each class\n",
    "#     \"\"\"\n",
    "#     alpha = 1.0\n",
    "#     beta = 1.0\n",
    "#     lam = alpha / beta\n",
    "#     print(f.shape)\n",
    "#     print(y_.shape)\n",
    "#     tmp = (vh @ (f @ y_))\n",
    "\n",
    "#     for _ in range(11):\n",
    "#         # should converge after at most 10 steps\n",
    "#         # typically converge after two or three steps\n",
    "#         gamma = (s / (s + lam)).sum()\n",
    "#         m = v @ (tmp * beta / (alpha + beta * s))\n",
    "#         alpha_de = (m * m).sum()\n",
    "#         alpha = gamma / alpha_de\n",
    "#         beta_de = ((y_ - fh @ m) ** 2).sum()\n",
    "#         beta = (N - gamma) / beta_de\n",
    "#         new_lam = alpha / beta\n",
    "#         if np.abs(new_lam - lam) / lam < 0.01:\n",
    "#             break\n",
    "#         lam = new_lam\n",
    "\n",
    "#     evidence = D / 2.0 * np.log(alpha) \\\n",
    "#                + N / 2.0 * np.log(beta) \\\n",
    "#                - 0.5 * np.sum(np.log(alpha + beta * s)) \\\n",
    "#                - beta / 2.0 * beta_de \\\n",
    "#                - alpha / 2.0 * alpha_de \\\n",
    "#                - N / 2.0 * np.log(2 * np.pi)\n",
    "\n",
    "#     return evidence / N, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from metrics.Evaluator import evaluator\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def accuracy(y_test, y_pred):\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    ground_truth_np = np.argmax(y_test, axis=1)\n",
    "    return accuracy_score(ground_truth_np, y_pred)\n",
    "\n",
    "def degradation_decomp(source_X, source_y, other_X_raw, other_y_raw, best_method, column_names, data_sum=20000, K=8, domain_classifier=None, draw_calibration=False, save_calibration_png='calibration.png'):\n",
    "    perm1 = np.random.permutation(other_X_raw.shape[0])\n",
    "    other_X = other_X_raw[perm1[:data_sum],:]\n",
    "    other_y = other_y_raw[perm1[:data_sum]]\n",
    "\n",
    "    piA = np.zeros(source_X.shape[0])\n",
    "    piB = np.zeros(other_X.shape[0])\n",
    "    permA = np.random.permutation(piA.shape[0])\n",
    "    permB = np.random.permutation(piB.shape[0])\n",
    "\n",
    "    kf = KFold(n_splits=K, shuffle=False)\n",
    "    A_train_index_list = []\n",
    "    A_test_index_list = []\n",
    "    B_train_index_list = []\n",
    "    B_test_index_list = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(source_X)):\n",
    "        A_train_index_list.append(train_index)\n",
    "        A_test_index_list.append(test_index)\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(other_X)):\n",
    "        B_train_index_list.append(train_index)\n",
    "        B_test_index_list.append(test_index)\n",
    "\n",
    "    for i in range(K):\n",
    "        trainX = np.concatenate([source_X[permA[A_train_index_list[i]]],other_X[permB[B_train_index_list[i]]]], axis=0)\n",
    "        trainT = np.zeros(trainX.shape[0])\n",
    "        trainT[len(A_train_index_list[i]):] = 1.0\n",
    "\n",
    "        if domain_classifier is None:\n",
    "            model = XGBClassifier(random_state=0).fit(trainX, trainT)\n",
    "        else:\n",
    "            model = domain_classifier.fit(trainX, trainT)\n",
    "\n",
    "        piA[permA[A_test_index_list[i]]] = model.predict_proba(source_X[permA[A_test_index_list[i]]])[:,1]\n",
    "        piB[permB[B_test_index_list[i]]] = model.predict_proba(other_X[permB[B_test_index_list[i]]])[:,1]\n",
    "\n",
    "    # if draw_calibration:\n",
    "    #     plot_calibration(piA, piB, save_dir=save_calibration_png)\n",
    "\n",
    "    alpha = (other_X.shape[0])/ (source_X.shape[0]+other_X.shape[0])\n",
    "    wA = piA / ((1-alpha)*piA + alpha * (1-piA))\n",
    "    wB = (1-piB) / ((1-alpha)*piB + alpha * (1-piB))\n",
    "    # Changing to support the model type of XGBoost.\n",
    "    # accuracyA = best_method.score(source_X, source_y)\n",
    "    # accuracyB = best_method.score(other_X, other_y)\n",
    "    pd_source_X = pd.DataFrame(source_X, columns=column_names)\n",
    "    pd_other_X = pd.DataFrame(other_X, columns=column_names)\n",
    "    accuracyA = accuracy(source_y, best_method.predict_proba(pd_source_X))\n",
    "    accuracyB = accuracy(other_y, best_method.predict_proba(pd_other_X))\n",
    "    wA = wA / np.sum(wA)\n",
    "    wB = wB / np.sum(wB)\n",
    "    # predA = (best_method.predict(source_X) == source_y)\n",
    "    # predB = (best_method.predict(other_X) == other_y)\n",
    "    predA = (np.argmax(best_method.predict_proba(pd_source_X), axis=1) == np.argmax(source_y, axis=1))\n",
    "    predB = (np.argmax(best_method.predict_proba(pd_other_X), axis=1) == np.argmax(other_y, axis=1))\n",
    "    sx_A = np.dot(wA, predA)\n",
    "    sx_B = np.dot(wB, predB)\n",
    "    return accuracyA, accuracyB, sx_A, sx_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_shift(src_x, src_y, tar_x, tar_y, tree_model, column_names):\n",
    "    p2p, q2q, p2s, s2q = degradation_decomp(src_x, src_y, tar_x, tar_y, tree_model, column_names, data_sum=20000, K=8, draw_calibration=False, save_calibration_png='calibration.png')\n",
    "    # print(f\"Total Performance Degradation is {p2p-q2q}\")\n",
    "    # print(f\"Proportion of Y|X-shift is {(p2s-s2q)/(p2p-q2q)}\")\n",
    "    perf_degradation = p2p-q2q\n",
    "    proportion_yshift = (p2s-s2q)/(p2p-q2q)\n",
    "    return perf_degradation, proportion_yshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_agnostic_data_valuation(src_x, tar_x):\n",
    "    cov_mat_src = src_x.cov()\n",
    "    src_eig_vals, src_eig_vecs = np.linalg.eig((cov_mat_src.T @ cov_mat_src) * (1 / len(src_x)))\n",
    "    cov_mat_tar = ((tar_x.cov().T @ tar_x.cov()) * (1 / len(tar_x)))\n",
    "    tar_eig_vals = [np.sqrt(np.sum(np.square(cov_mat_tar.dot(eigen_vec)))) for eigen_vec in src_eig_vecs]\n",
    "    src_eig_vals = np.array(src_eig_vals)\n",
    "    tar_eig_vals = np.array(tar_eig_vals)\n",
    "    diversity, relevance = 1, 1\n",
    "    for src_eig, tar_eig in zip(src_eig_vals, tar_eig_vals):\n",
    "        diversity *= np.power((abs(src_eig - tar_eig) / max(src_eig, tar_eig)), 1 / len(src_eig_vals))\n",
    "        relevance *= np.power((min(src_eig, tar_eig) / max(src_eig, tar_eig)), 1 / len(src_eig_vals))\n",
    "    return relevance, diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_volumes(X, d=1):\n",
    "def compute_volumes(datasets, d=1):\n",
    "    d = datasets[0].shape[1]\n",
    "    for i in range(len(datasets)):\n",
    "        datasets[i] = datasets[i].reshape(-1 ,d)\n",
    "\n",
    "    X = np.concatenate(datasets, axis=0).reshape(-1, d)\n",
    "    volumes = np.zeros(len(datasets))\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        volumes[i] = np.sqrt(np.linalg.det( dataset.T @ dataset ) + 1e-8)\n",
    "\n",
    "    volume_all = np.sqrt(np.linalg.det(X.T @ X) + 1e-8).round(3)\n",
    "    return volumes, volume_all\n",
    "    # return volume_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, floor\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import stack, cat, zeros_like, pinverse\n",
    "\n",
    "def compute_X_tilde_and_counts(X, omega):\n",
    "    \"\"\"\n",
    "    Compresses the original feature matrix X to  X_tilde with the specified omega.\n",
    "\n",
    "    Returns:\n",
    "       X_tilde: compressed np.ndarray\n",
    "       cubes: a dictionary of cubes with the respective counts in each dcube\n",
    "    \"\"\"\n",
    "    D = X.shape[1]\n",
    "\n",
    "    # assert 0 < omega <= 1, \"omega must be within range [0,1].\"\n",
    "\n",
    "    m = ceil(1.0 / omega) # number of intervals for each dimension\n",
    "\n",
    "    cubes = Counter() # a dictionary to store the freqs\n",
    "    # key: (1,1,..)  a d-dimensional tuple, each entry between [0, m-1]\n",
    "    # value: counts\n",
    "\n",
    "    Omega = defaultdict(list)\n",
    "    # Omega = {}\n",
    "\n",
    "    min_ds = torch.min(X, axis=0).values\n",
    "\n",
    "    # a dictionary to store cubes of not full size\n",
    "    for x in X:\n",
    "        cube = []\n",
    "        for d, xd in enumerate(x - min_ds):\n",
    "            d_index = floor(xd / omega)\n",
    "            cube.append(d_index)\n",
    "\n",
    "        cube_key = tuple(cube)\n",
    "        cubes[cube_key] += 1\n",
    "\n",
    "        Omega[cube_key].append(x)\n",
    "\n",
    "        '''\n",
    "        if cube_key in Omega:\n",
    "\n",
    "            # Implementing mean() to compute the average of all rows which fall in the cube\n",
    "\n",
    "            Omega[cube_key] = Omega[cube_key] * (1 - 1.0 / cubes[cube_key]) + 1.0 / cubes[cube_key] * x\n",
    "            # Omega[cube_key].append(x)\n",
    "        else:\n",
    "             Omega[cube_key] = x\n",
    "        '''\n",
    "    X_tilde = stack([stack(list(value)).mean(axis=0) for key, value in Omega.items()])\n",
    "\n",
    "    # X_tilde = stack(list(Omega.values()))\n",
    "\n",
    "    return X_tilde, cubes\n",
    "\n",
    "def compute_robust_volumes(X_tildes, dcube_collections):\n",
    "\n",
    "    N = sum([len(X_tilde) for X_tilde in X_tildes])\n",
    "    alpha = 1.0 / (10 * N) # it means we set beta = 10\n",
    "    # print(\"alpha is :{}, and (1 + alpha) is :{}\".format(alpha, 1 + alpha))\n",
    "\n",
    "    volumes, volume_all = compute_volumes(X_tildes, d=X_tildes[0].shape[1])\n",
    "    robust_volumes = np.zeros_like(volumes)\n",
    "    for i, (volume, hypercubes) in enumerate(zip(volumes, dcube_collections)):\n",
    "        rho_omega_prod = 1.0\n",
    "        for cube_index, freq_count in hypercubes.items():\n",
    "\n",
    "            # if freq_count == 1: continue # volume does not monotonically increase with omega\n",
    "            # commenting this if will result in volume monotonically increasing with omega\n",
    "            rho_omega = (1 - alpha**(freq_count + 1)) / (1 - alpha)\n",
    "\n",
    "            rho_omega_prod *= rho_omega\n",
    "\n",
    "        robust_volumes[i] = (volume * rho_omega_prod).round(3)\n",
    "    return robust_volumes\n",
    "\n",
    "\n",
    "def robust_volume(Xs, omega=0.1):\n",
    "    # M = len(Xs)\n",
    "    D = Xs.shape[1]\n",
    "    # orderings = list(permutations(range(M)))\n",
    "\n",
    "    # s_values = torch.zeros(M)\n",
    "    # monte_carlo_s_values = torch.zeros(M)\n",
    "\n",
    "    # s_value_robust = torch.zeros(M)\n",
    "    # monts_carlo_s_values_robust = torch.zeros(M)\n",
    "\n",
    "    # Monte-carlo : shuffling the ordering and taking the first K orderings\n",
    "    # random.shuffle(orderings)\n",
    "    # K = 4 # number of permutations to sample\n",
    "    # for ordering_count, ordering in enumerate(orderings):\n",
    "\n",
    "        # prefix_vol = 0\n",
    "        # prefix_robust_vol = 0\n",
    "        # for position, i in enumerate(ordering):\n",
    "\n",
    "        #     curr_indices = set(ordering[:position+1])\n",
    "\n",
    "    # curr_train_X = torch.cat(torch.tensor(Xs.values)).reshape(-1, D)\n",
    "    curr_train_X = torch.tensor(Xs.values).reshape(-1, D)\n",
    "\n",
    "    # curr_train_X = torch.tensor(Xs.values)\n",
    "\n",
    "    # curr_vol = torch.sqrt(torch.linalg.det(curr_train_X.T @ curr_train_X) + 1e-8)\n",
    "\n",
    "\n",
    "    # marginal = curr_vol - prefix_vol\n",
    "    # prefix_vol = curr_vol\n",
    "    # s_values[i] += marginal\n",
    "\n",
    "    X_tilde, cubes = compute_X_tilde_and_counts(curr_train_X, omega)\n",
    "\n",
    "    robust_vol = compute_robust_volumes([X_tilde], [cubes])[0]\n",
    "\n",
    "    return robust_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb_tree(train_x, train_y, test_x, test_y):\n",
    "    parameters_dict = {\"batch_size\": 64}\n",
    "    d_matrix = xgb.DMatrix(train_x, label=np.argmax(train_y, axis=1))\n",
    "    d_test_matrix = xgb.DMatrix(test_x, label=np.argmax(test_y, axis=1))\n",
    "    if train_y.shape[1] == 2:\n",
    "        parameters_dict[\"objective\"] = \"binary:logistic\"\n",
    "        parameters_dict[\"eval_metric\"] = \"logloss\"\n",
    "    elif train_y.shape[1] > 2:\n",
    "        parameters_dict[\"objective\"] = \"multi:softprob\"\n",
    "        parameters_dict['num_class'] = train_y.shape[1]\n",
    "        parameters_dict[\"disable_default_eval_metric\"] = 1\n",
    "        parameters_dict[\"eval_metric\"] = \"mlogloss\"\n",
    "    tree_model = xgb.train(parameters_dict, d_matrix, evals=[(d_matrix, \"train\"), (d_test_matrix, \"validate\")], num_boost_round=500, early_stopping_rounds=10)\n",
    "    tree_model = XGBoostModel(tree_model)\n",
    "    return tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def hellinger_distance(src_y, tar_y, type_continuous=False):\n",
    "    # if type_continuous:\n",
    "    #     kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(src_y.reshape(-1, 1))\n",
    "    #     src_y = kde.score_samples(src_y.reshape(-1, 1))\n",
    "\n",
    "    #     kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(tar_y.reshape(-1, 1))\n",
    "    #     tar_y = kde.score_samples(tar_y.reshape(-1, 1))\n",
    "\n",
    "    # else:\n",
    "    total_instances_per_label_src = np.sum(src_y, axis=0)\n",
    "    total_instances_per_label_tar = np.sum(tar_y, axis=0)\n",
    "    p = np.divide(total_instances_per_label_src, np.sum(total_instances_per_label_src))\n",
    "    q = np.divide(total_instances_per_label_tar, np.sum(total_instances_per_label_tar))\n",
    "    \n",
    "    return (1/math.sqrt(2)) * np.sqrt(np.sum(np.square(np.sqrt(p) - np.sqrt(q))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hellinger_distance(p, q):\n",
    "#     \"\"\"Hellinger distance between two discrete distributions.\n",
    "#        In pure Python.\n",
    "#        Fastest version.\"\"\"\n",
    "#     z = np.sqrt(p) - np.sqrt(q)\n",
    "#     return np.sqrt(z @ z / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import OptunaConnection\n",
    "from experiment_parameters.model_builder.ModelBuilder import Director, get_training_configuration\n",
    "from experiment_parameters.model_builder.Model import XGBoostModel, KerasModel\n",
    "from sklearn.metrics import log_loss, mean_absolute_error\n",
    "import gc\n",
    "\n",
    "director = Director()\n",
    "\n",
    "def get_parameters(trial, model_type):\n",
    "    parameters = get_training_configuration(trial=trial, model_type=model_type)\n",
    "    return parameters\n",
    "\n",
    "def get_mlp(input_dim, num_classes, parameters):\n",
    "    return director.create_mlp(input_parameters=input_dim, num_classes=num_classes, parameters=parameters)\n",
    "\n",
    "def performance_degradation(train_src_x, train_src_y, train_tar_x, train_tar_y, test_tar_x, test_tar_y, dataset_name):\n",
    "    if dataset_name == \"har\":\n",
    "        study = OptunaConnection.load_study(\"mlp_har\")\n",
    "    elif dataset_name == \"edge-iot-coreset\":\n",
    "        study = OptunaConnection.load_study(\"mlp_edge_iiot_coreset\")\n",
    "    elif dataset_name == \"electric-consumption\":\n",
    "        study = OptunaConnection.load_study(\"mlp_electric_consumption\")\n",
    "    best_trial = study.best_trial\n",
    "    parameters_dict = get_training_configuration(best_trial, \"mlp\")\n",
    "\n",
    "    model_src = get_mlp(train_src_x.shape[1], train_src_y.shape[1], parameters_dict)\n",
    "    model_src.fit(train_src_x, train_src_y, epochs=30)\n",
    "\n",
    "    model_tar = get_mlp(train_src_x.shape[1], train_src_y.shape[1], parameters_dict)\n",
    "    model_tar.fit(train_tar_x, train_tar_y, epochs=30)\n",
    "\n",
    "    if train_src_y.shape[1] == 1:\n",
    "        metric_list = [\"MAE\"]\n",
    "        evaluation_result_src = evaluator(test_tar_x, test_tar_y, model_src, metric_list=metric_list).get_value_of_metric(\"MAE\")\n",
    "        evaluation_result_tar = evaluator(test_tar_x, test_tar_y, model_tar, metric_list=metric_list).get_value_of_metric(\"MAE\")\n",
    "    else:\n",
    "        metric_list = [\"CrossEntropyLoss\"]\n",
    "        evaluation_result_src = evaluator(test_tar_x, test_tar_y, model_src, metric_list=metric_list).get_value_of_metric(\"CrossEntropyLoss\")\n",
    "        evaluation_result_tar = evaluator(test_tar_x, test_tar_y, model_tar, metric_list=metric_list).get_value_of_metric(\"CrossEntropyLoss\")\n",
    "\n",
    "    return evaluation_result_src - evaluation_result_tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!Comment about the prince library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_distances_and_volumes(dataset_name, path_to_train_datasets):\n",
    "    wassersteinDataframe = pd.DataFrame()\n",
    "    gaussianMMDDataframe = pd.DataFrame()\n",
    "    relevanceDataframe = pd.DataFrame()\n",
    "    diversityDataframe = pd.DataFrame()\n",
    "    volumeDataframe = pd.Series()\n",
    "\n",
    "    performanceDegradation = pd.DataFrame()\n",
    "    negativeConditionalEntropyDataframe = pd.DataFrame()\n",
    "    yShiftDataframe = pd.DataFrame()\n",
    "    hellingerDistanceDataframe = pd.DataFrame()\n",
    "    \n",
    "    # regularizedHScoreDataframe = pd.DataFrame()\n",
    "    classification = False\n",
    "\n",
    "    global_X_training, global_y_training = dataset_model_dictionary[dataset_name]().get_dataset().get_training_data()\n",
    "    global_X_test, global_y_test = dataset_model_dictionary[dataset_name]().get_dataset().get_test_data()\n",
    "    column_names = global_X_training.columns.values.tolist()\n",
    "\n",
    "    if len(global_y_training.shape) > 1: # Classification problem\n",
    "        classification = True\n",
    "\n",
    "    # global_X_training = downcast_types(global_X_training)\n",
    "    # global_X_test = downcast_types(global_X_test)\n",
    "\n",
    "    num_clients, all_combinations = number_of_clients_and_all_combinations(path_to_train_datasets)\n",
    "    # volumeDataframe.loc[\"Global\"] = compute_volumes(prince.PCA(n_components=10).fit_transform(pd.concat([global_X_training, global_X_test]).reset_index(drop=True)).to_numpy())\n",
    "    # volumeDataframe.loc[\"Global\"] = robust_volume(prince.PCA(n_components=10).fit_transform(pd.concat([global_X_training, global_X_test])))\n",
    "\n",
    "    for source_client in range(num_clients):\n",
    "        src_train_x = pd.read_csv(path_to_train_datasets + os.sep + \"client_\" + str(source_client) + \"_X_training.csv\", index_col=0)\n",
    "        src_train_y = pd.read_csv(path_to_train_datasets + os.sep + \"client_\" + str(source_client) + \"_y_training.csv\", index_col=0)\n",
    "        src_test_x = pd.read_csv(path_to_train_datasets + os.sep + \"client_\" + str(source_client) + \"_X_test.csv\", index_col=0)\n",
    "        src_test_y = pd.read_csv(path_to_train_datasets + os.sep + \"client_\" + str(source_client) + \"_y_test.csv\", index_col=0)\n",
    "\n",
    "        src_train_x = downcast_types(src_train_x)\n",
    "        src_test_x = downcast_types(src_test_x)\n",
    "\n",
    "        # tree_model = get_xgb_tree(src_train_x, src_train_y, src_test_x, src_test_y)\n",
    "        # wassersteinDataframe.loc[source_client, \"Global\"], conditionalEntropy.loc[source_client, \"Global\"] = optimal_transport_conditional_entropy(torch.tensor(pd.concat([src_train_x, src_test_x]).to_numpy(), dtype=torch.float),\n",
    "        #                                                                 np.argmax(pd.concat([src_train_y, src_test_y]).astype(int).to_numpy(), axis=1),\n",
    "        #                                                                 torch.tensor(pd.concat([global_X_training, global_X_test]).to_numpy(), dtype=torch.float),\n",
    "        #                                                                 np.argmax(pd.concat([global_y_training, global_y_test]).astype(int).to_numpy(), axis=1))\n",
    "        # wassersteinDataframe.loc[source_client, \"Global\"]= wasserstein_distance(pd.concat([src_train_x, src_test_x]),\n",
    "        #                                                                         pd.concat([global_X_training, global_X_test]))\n",
    "        # gaussianMMDDataframe.loc[source_client, \"Global\"]= gaussian_mmd_distance(pd.concat([src_train_x, src_test_x]),\n",
    "        #                                                                         pd.concat([global_X_training, global_X_test]))\n",
    "        # relevanceDataframe.loc[source_client, \"Global\"], diversityDataframe.loc[source_client, \"Global\"] = task_agnostic_data_valuation(\n",
    "        #     prince.PCA(n_components=10).fit_transform(pd.concat([src_train_x, src_test_x])),\n",
    "        #     prince.PCA(n_components=10).fit_transform(pd.concat([global_X_training, global_X_test]))\n",
    "        # )\n",
    "        # volumeDataframe.loc[source_client] = robust_volume(prince.PCA(n_components=10).fit_transform(pd.concat([src_train_x, src_test_x])))\n",
    "\n",
    "        # if classification:\n",
    "        #     _, yShiftDataframe.loc[source_client, \"Global\"] = y_shift(pd.concat([src_train_x, src_test_x]).to_numpy(),\n",
    "        #                                                             pd.concat([src_train_y, src_test_y]).to_numpy(),\n",
    "        #                                                             pd.concat([global_X_training, global_X_test]).to_numpy(),\n",
    "        #                                                             pd.concat([global_y_training, global_y_test]).to_numpy(),\n",
    "        #                                                             tree_model,\n",
    "        #                                                             column_names)\n",
    "            # negativeConditionalEntropyDataframe.loc[source_client, \"Global\"] = negative_conditional_entropy(np.argmax(pd.concat([src_train_y, src_test_y]).astype(int).to_numpy(), axis=1), np.argmax(pd.concat([global_y_training, global_y_test]).astype(int).to_numpy(), axis=1))\n",
    "\n",
    "        performanceDegradation.loc[source_client, \"Global\"] = performance_degradation(src_train_x, src_train_y, global_X_training, global_y_training, global_X_test, global_y_test, dataset_name=dataset_name)\n",
    "        # if dataset_name == \"electric-consumption\":\n",
    "        #     hellingerDistanceDataframe.loc[source_client, \"Global\"] = hellinger_distance(pd.concat([src_train_y, src_test_y]).to_numpy(), pd.concat([global_y_training, global_y_test]).to_numpy(), type_continuous=True)\n",
    "        # else:\n",
    "        #     hellingerDistanceDataframe.loc[source_client, \"Global\"] = hellinger_distance(pd.concat([src_train_y, src_test_y]).to_numpy(), pd.concat([global_y_training, global_y_test]).to_numpy())\n",
    "\n",
    "        gc.collect()\n",
    "        for target_client in range(num_clients):\n",
    "            tar_train_x = pd.read_csv(path_to_train_datasets + os.sep + \"client_\" + str(target_client) + \"_X_training.csv\", index_col=0)\n",
    "            tar_train_y = pd.read_csv(path_to_train_datasets + os.sep + \"client_\" + str(target_client) + \"_y_training.csv\", index_col=0)\n",
    "            tar_test_x = pd.read_csv(path_to_train_datasets + os.sep + \"client_\" + str(target_client) + \"_X_test.csv\", index_col=0)\n",
    "            tar_test_y = pd.read_csv(path_to_train_datasets + os.sep + \"client_\" + str(target_client) + \"_y_test.csv\", index_col=0)\n",
    "\n",
    "            tar_train_x = downcast_types(tar_train_x)\n",
    "            tar_test_x = downcast_types(tar_test_x)\n",
    "\n",
    "            performanceDegradation.loc[source_client, target_client] = performance_degradation(src_train_x, src_train_y, tar_train_x, tar_train_y, tar_test_x, tar_test_y, dataset_name=dataset_name)\n",
    "\n",
    "            # wassersteinDataframe.loc[source_client, target_client]= wasserstein_distance(pd.concat([src_train_x, src_test_x]),\n",
    "            #                                                                     pd.concat([tar_train_x, tar_test_x]))\n",
    "            # gaussianMMDDataframe.loc[source_client, target_client]= gaussian_mmd_distance(pd.concat([src_train_x, src_test_x]),\n",
    "            #                                                                     pd.concat([tar_train_x, tar_test_x]))\n",
    "            # relevanceDataframe.loc[source_client, target_client], diversityDataframe.loc[source_client, target_client] = task_agnostic_data_valuation(\n",
    "            #     prince.PCA(n_components=10).fit_transform(pd.concat([src_train_x, src_test_x])),\n",
    "            #     prince.PCA(n_components=10).fit_transform(pd.concat([tar_train_x, tar_test_x]))\n",
    "            # )\n",
    "\n",
    "            # if classification:\n",
    "            #     _, yShiftDataframe.loc[source_client, target_client] = y_shift(pd.concat([src_train_x, src_test_x]).to_numpy(),\n",
    "            #                                                                 pd.concat([src_train_y, src_test_y]).to_numpy(),\n",
    "            #                                                                 pd.concat([tar_train_x, tar_test_x]).to_numpy(),\n",
    "            #                                                                 pd.concat([tar_train_y, tar_test_y]).to_numpy(),\n",
    "            #                                                                 tree_model,\n",
    "            #                                                                 column_names)\n",
    "                # negativeConditionalEntropyDataframe.loc[source_client, target_client] = negative_conditional_entropy(np.argmax(pd.concat([src_train_y, src_test_y]).astype(int).to_numpy(), axis=1), np.argmax(pd.concat([tar_train_y, tar_test_y]).astype(int).to_numpy(), axis=1))\n",
    "            # if dataset_name == \"electric-consumption\":\n",
    "            #     hellingerDistanceDataframe.loc[source_client, target_client] = hellinger_distance(pd.concat([src_train_y, src_test_y]).to_numpy(), pd.concat([tar_train_y, tar_test_y]).to_numpy(), type_continuous=True)\n",
    "            # else:\n",
    "            #     hellingerDistanceDataframe.loc[source_client, target_client] = hellinger_distance(pd.concat([src_train_y, src_test_y]).to_numpy(), pd.concat([tar_train_y, tar_test_y]).to_numpy())\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "    return wassersteinDataframe, gaussianMMDDataframe, performanceDegradation, yShiftDataframe, negativeConditionalEntropyDataframe, relevanceDataframe, diversityDataframe, volumeDataframe, hellingerDistanceDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances_and_values(dataset_name, type_of_partition, additional_parameter):\n",
    "    path_to_result_dataframes = get_distances_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "    path_to_train_datasets = get_data_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "    wassersteinDataframe, gaussianMMDDataframe, performanceDegradation, yShiftDataframe, negativeConditionalEntropy, relevance, diversity, volume, hellinger = compute_all_distances_and_volumes(dataset_name, path_to_train_datasets)\n",
    "    \n",
    "    os.makedirs(path_to_result_dataframes, exist_ok=True)\n",
    "\n",
    "    if yShiftDataframe.shape[0] > 0:\n",
    "        yShiftDataframe.to_csv(path_to_result_dataframes + os.sep + \"yShiftDataframe.csv\")\n",
    "    \n",
    "    if negativeConditionalEntropy.shape[0] > 0:\n",
    "        negativeConditionalEntropy.to_csv(path_to_result_dataframes + os.sep + \"negativeConditionalEntropy.csv\")\n",
    "\n",
    "    if performanceDegradation.shape[0] > 0:\n",
    "        performanceDegradation.to_csv(path_to_result_dataframes + os.sep + \"performanceDegradation.csv\")\n",
    "\n",
    "    if hellinger.shape[0] > 0:\n",
    "        hellinger.to_csv(path_to_result_dataframes + os.sep + \"hellinger.csv\")\n",
    "\n",
    "    if wassersteinDataframe.shape[0] > 0:\n",
    "        wassersteinDataframe.to_csv(path_to_result_dataframes + os.sep + \"wasserstein.csv\")\n",
    "\n",
    "    if gaussianMMDDataframe.shape[0] > 0:\n",
    "        gaussianMMDDataframe.to_csv(path_to_result_dataframes + os.sep + \"gaussian_mmd.csv\")\n",
    "    # conditionalEntropy.to_csv(path_to_result_dataframes + os.sep + \"conditionalEntropy.csv\")\n",
    "\n",
    "    if relevance.shape[0] > 0:\n",
    "        relevance.to_csv(path_to_result_dataframes + os.sep + \"relevance.csv\")\n",
    "\n",
    "    if diversity.shape[0] > 0:\n",
    "        diversity.to_csv(path_to_result_dataframes + os.sep + \"diversity.csv\")\n",
    "    \n",
    "    if volume.shape[0] > 0:\n",
    "        volume.to_csv(path_to_result_dataframes + os.sep + \"volume.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_configurations_for_distances = [\n",
    "    # (\"adult\", \"dirichlet\", \"0.1\"),\n",
    "    # (\"adult\", \"dirichlet\", \"1\"),\n",
    "    # (\"adult\", \"dirichlet\", \"10\"),\n",
    "    # (\"adult\", \"dirichlet\", \"100\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Doctorate\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Masters\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Occupation\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Occupation_ExecManagerial\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Studies\"),\n",
    "    (\"har\", \"dirichlet\", \"1\"),\n",
    "    (\"har\", \"dirichlet\", \"10\"),\n",
    "    (\"har\", \"dirichlet\", \"100\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_label_skew\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_LessLabels\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_MissingTwoLabels\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Laying\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_HellingerTrap\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_1\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_2\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_3\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_4\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_5\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_2\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_3\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_4\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_5\"),\n",
    "    # # (\"covertype\", \"dirichlet\", \"1\"),\n",
    "    # # (\"covertype\", \"dirichlet\", \"10\"),\n",
    "    # # (\"covertype\", \"dirichlet\", \"100\"),\n",
    "    # # (\"covertype\", \"manual\", \"Covertype_Maverick_LeastNumerousClass\"),\n",
    "    # # (\"covertype\", \"manual\", \"Covertype_Maverick_MostNumerousClass\"),\n",
    "    # # (\"covertype\", \"manual\", \"Covertype_FS_WildernessArea\"),\n",
    "    # # (\"new_adult\", \"dirichlet\", \"1\"),\n",
    "    # # (\"new_adult\", \"dirichlet\", \"10\"),\n",
    "    # # (\"new_adult\", \"dirichlet\", \"100\"),\n",
    "    # # (\"new_adult\", \"manual\", \"New_Adult_AL_CO_CT_MA\")\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"10\"),\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"100\"),\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"1000\"),\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"10000\"),\n",
    "    (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_LeastAttack\"),\n",
    "    (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_OnlyNormal\"),\n",
    "    (\"electric-consumption\", \"manual\", \"Electric_Consumption_Random_Sampling\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumptionFacilityType\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumptionNoniid\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumptionStateFactor\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickMultifamilyUncategorized\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickGroceryStore\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name, type_of_partition, additional_parameter in training_configurations_for_distances:\n",
    "    compute_distances_and_values(dataset_name, type_of_partition, additional_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_of_training(dataset_name, type_of_partition, additional_parameter):\n",
    "    results_dataframe = pd.Series()\n",
    "\n",
    "    path_to_result_dataframes = get_results_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "\n",
    "    # metrics = []\n",
    "    # result = []\n",
    "\n",
    "    results_dataframe.loc[\"Dataset\"] = dataset_name\n",
    "    results_dataframe.loc[\"Type_of_partition\"] = type_of_partition\n",
    "    results_dataframe.loc[\"dirichlet/NamePartition\"] = additional_parameter\n",
    "\n",
    "    for file in os.listdir(path_to_result_dataframes + os.sep + \"Evaluation\"):\n",
    "        # spearman_rank_distance_sv = pd.DataFrame(columns=[\"Dataset\", \"TypePartition\", \"AdditionalParameter\", \"Metric\", \"Evaluator\", \"Distance\", \"SpearmanRank\", \"p-value\"])\n",
    "        metric_name = file.split(\"_\")[1]\n",
    "\n",
    "        if file != \"Evaluation_F1Score\":\n",
    "            evaluation_dataframe = pd.read_csv(path_to_result_dataframes + os.sep + \"Evaluation\" + os.sep + file)\n",
    "            results_dataframe.loc[metric_name] = evaluation_dataframe.loc[evaluation_dataframe.index[-1], \"Global\"]\n",
    "\n",
    "    return results_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe = pd.DataFrame()\n",
    "\n",
    "for dataset_name, type_of_partition, additional_parameter in training_configurations_for_distances:\n",
    "    # display(get_results_of_training(dataset_name, type_of_partition, additional_parameter))\n",
    "    results_dataframe = pd.concat([results_dataframe, get_results_of_training(dataset_name, type_of_partition, additional_parameter).to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing distances and value for the different experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_configurations = [\n",
    "    # (\"adult\", \"dirichlet\", \"0.1\"),\n",
    "    # (\"adult\", \"dirichlet\", \"1\"),\n",
    "    # (\"adult\", \"dirichlet\", \"10\"),\n",
    "    # (\"adult\", \"dirichlet\", \"100\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Doctorate\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Masters\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Occupation\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Occupation_ExecManagerial\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Studies\"),\n",
    "    # (\"har\", \"dirichlet\", \"1\"),\n",
    "    # (\"har\", \"dirichlet\", \"10\"),\n",
    "    # (\"har\", \"dirichlet\", \"100\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_1_label_skew\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_1_LessLabels\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_1_MissingTwoLabels\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_1_HellingerTrap\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_Laying\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_1\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_2\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_3\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_4\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_5\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_2\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_3\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_4\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_5\"),\n",
    "    # (\"covertype\", \"dirichlet\", \"1\"),\n",
    "    # (\"covertype\", \"dirichlet\", \"10\"),\n",
    "    # (\"covertype\", \"dirichlet\", \"100\"),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_Maverick_LeastNumerousClass\"),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_Maverick_MostNumerousClass\"),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_FS_WildernessArea\"),\n",
    "    # (\"new_adult\", \"dirichlet\", \"1\"),\n",
    "    # (\"new_adult\", \"dirichlet\", \"10\"),\n",
    "    # (\"new_adult\", \"dirichlet\", \"100\"),\n",
    "    # (\"new_adult\", \"manual\", \"New_Adult_AL_CO_CT_MA\")\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"10\"),\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"100\"),\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"1000\"),\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"10000\"),\n",
    "    # (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_LeastAttack\"),\n",
    "    # (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_OnlyNormal\"),\n",
    "    # (\"electric-consumption\", \"manual\", \"Electric_Consumption_Random_Sampling\"),\n",
    "    # (\"electric-consumption\", \"manual\", \"ElectricConsumptionFacilityType\"),\n",
    "    # (\"electric-consumption\", \"manual\", \"ElectricConsumptionNoniid\"),\n",
    "    # (\"electric-consumption\", \"manual\", \"ElectricConsumptionStateFactor\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickMultifamilyUncategorized\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickGroceryStore\")\n",
    "]\n",
    "\n",
    "# training_configurations = [\n",
    "#     (\"adult\", \"manual\", \"Adult_FeatureSkew_Occupation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearman_correlation_sv(dataset_name, type_of_partition, additional_parameter):\n",
    "    path_to_result_dataframes = get_results_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "\n",
    "    spearman_rank_sv_metric_centralized_decentralized = pd.DataFrame(columns=[\"Dataset\", \"TypePartition\", \"AdditionalParameter\", \"Metric\", \"SpearmanRank\", \"p-value\"])\n",
    "    spearman_sv_metrics = []\n",
    "    spearman_sv_values = []\n",
    "    spearman_sv_p_values = []\n",
    "\n",
    "    for file in os.listdir(path_to_result_dataframes + os.sep + \"Shapley_Value\"):\n",
    "        results_dataframe = pd.read_csv(path_to_result_dataframes + os.sep + \"Shapley_Value\" + os.sep + file)\n",
    "        # display(path_to_result_dataframes)\n",
    "        # display(file)\n",
    "        spearman_sv_metrics.append(file.split('_')[1])\n",
    "        if \"SV_F1Score\" == file:\n",
    "            grouped_sv = results_dataframe.groupby([\"Evaluator\", \"Classes\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Classes\", \"Round\"], axis=1)\n",
    "            spearman_sv_values.append(0)\n",
    "            spearman_sv_p_values.append(0)\n",
    "        else:\n",
    "            grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)\n",
    "            # display(grouped_sv)\n",
    "        # spearman_rank, pvalue = scipy.stats.spearmanr(grouped_sv.loc[\"Centralized\"], grouped_sv.loc[\"Aggregated\"])\n",
    "            def statistic(x): # permute only `x`\n",
    "                return scipy.stats.spearmanr(x, grouped_sv.loc[\"Aggregated\"]).statistic\n",
    "            res_exact = scipy.stats.permutation_test((grouped_sv.loc[\"Centralized\"],), statistic,\n",
    "                permutation_type='pairings')\n",
    "            # res_asymptotic = scipy.stats.spearmanr(grouped_sv.loc[\"Centralized\"], grouped_sv.loc[\"Aggregated\"])\n",
    "            # res_exact.pvalue # asymptotic pvalue is too low\n",
    "            # display(res_exact.statistic)\n",
    "            # display(res_exact.pvalue)\n",
    "            spearman_sv_values.append(res_exact.statistic)\n",
    "            spearman_sv_p_values.append(res_exact.pvalue)\n",
    "            # display(spearman_sv_values)\n",
    "            # display(spearman_sv_p_values)\n",
    "\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"Dataset\"] = [dataset_name for _ in range(len(spearman_sv_metrics))]\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"TypePartition\"] = [type_of_partition for _ in range(len(spearman_sv_metrics))]\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"AdditionalParameter\"] = [additional_parameter for _ in range(len(spearman_sv_metrics))]\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"Metric\"] = spearman_sv_metrics\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"SpearmanRank\"] = spearman_sv_values\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"p-value\"] = spearman_sv_p_values\n",
    "\n",
    "    return spearman_rank_sv_metric_centralized_decentralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pearson_correlation_sv(dataset_name, type_of_partition, additional_parameter):\n",
    "    path_to_result_dataframes = get_results_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "\n",
    "    pearson_rank_sv_metric_centralized_decentralized = pd.DataFrame(columns=[\"Dataset\", \"TypePartition\", \"AdditionalParameter\", \"Metric\", \"PearsonCorrelation\", \"p-value\"])\n",
    "    pearson_sv_metrics = []\n",
    "    pearson_sv_values = []\n",
    "    pearson_sv_p_values = []\n",
    "\n",
    "    for file in os.listdir(path_to_result_dataframes + os.sep + \"Shapley_Value\"):\n",
    "        results_dataframe = pd.read_csv(path_to_result_dataframes + os.sep + \"Shapley_Value\" + os.sep + file)\n",
    "        # display(path_to_result_dataframes)\n",
    "        # display(file)\n",
    "        pearson_sv_metrics.append(file.split('_')[1])\n",
    "        if file == \"SV_F1Score\":\n",
    "            grouped_sv = results_dataframe.groupby([\"Evaluator\", \"Classes\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Classes\", \"Round\"], axis=1)\n",
    "            pearson_sv_values.append(0)\n",
    "            pearson_sv_p_values.append(0)\n",
    "        elif file == \"SV_CosineSimilarity\":\n",
    "            grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)\n",
    "            pearson_sv_values.append(0)\n",
    "            pearson_sv_p_values.append(0)\n",
    "        else:\n",
    "            grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)\n",
    "            # def statistic(x): # permute only `x`\n",
    "            #     return scipy.stats.pearsonr(x, grouped_sv.loc[\"Aggregated\"]).statistic\n",
    "            # res_exact = scipy.stats.permutation_test((grouped_sv.loc[\"Centralized\"],), statistic,\n",
    "            #     permutation_type='pairings')\n",
    "            res_exact = scipy.stats.pearsonr(grouped_sv.loc[\"Centralized\"], grouped_sv.loc[\"Aggregated\"])\n",
    "            pearson_sv_values.append(res_exact.statistic)\n",
    "            pearson_sv_p_values.append(res_exact.pvalue)\n",
    "\n",
    "    pearson_rank_sv_metric_centralized_decentralized[\"Dataset\"] = [dataset_name for _ in range(len(pearson_sv_metrics))]\n",
    "    pearson_rank_sv_metric_centralized_decentralized[\"TypePartition\"] = [type_of_partition for _ in range(len(pearson_sv_metrics))]\n",
    "    pearson_rank_sv_metric_centralized_decentralized[\"AdditionalParameter\"] = [additional_parameter for _ in range(len(pearson_sv_metrics))]\n",
    "    pearson_rank_sv_metric_centralized_decentralized[\"Metric\"] = pearson_sv_metrics\n",
    "    pearson_rank_sv_metric_centralized_decentralized[\"PearsonCorrelation\"] = pearson_sv_values\n",
    "    pearson_rank_sv_metric_centralized_decentralized[\"p-value\"] = pearson_sv_p_values\n",
    "\n",
    "    return pearson_rank_sv_metric_centralized_decentralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_rank_sv_metric_centralized_decentralized = pd.DataFrame(columns=[\"Dataset\", \"TypePartition\", \"AdditionalParameter\", \"Metric\", \"SpearmanRank\", \"p-value\"])\n",
    "pearson_correlation_sv_metric_centralized_decentralized = pd.DataFrame(columns=[\"Dataset\", \"TypePartition\", \"AdditionalParameter\", \"Metric\", \"PearsonCorrelation\", \"p-value\"])\n",
    "\n",
    "\n",
    "for dataset_name, type_of_partition, additional_parameter in training_configurations:\n",
    "    spearman_rank_sv_metric_centralized_decentralized = pd.concat([spearman_rank_sv_metric_centralized_decentralized, compute_spearman_correlation_sv(dataset_name, type_of_partition, additional_parameter)], ignore_index=True)\n",
    "    pearson_correlation_sv_metric_centralized_decentralized = pd.concat([pearson_correlation_sv_metric_centralized_decentralized, compute_pearson_correlation_sv(dataset_name, type_of_partition, additional_parameter)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_rank_sv_metric_centralized_decentralized_no_f1 = spearman_rank_sv_metric_centralized_decentralized[(spearman_rank_sv_metric_centralized_decentralized[\"Metric\"] != \"F1Score\") & (spearman_rank_sv_metric_centralized_decentralized[\"Metric\"] != \"CosineSimilarity\")]\n",
    "\n",
    "spearman_rank_sv_metric_centralized_decentralized_no_f1[\"SpearmanRank\"] = spearman_rank_sv_metric_centralized_decentralized_no_f1[\"SpearmanRank\"].astype('float')\n",
    "spearman_rank_sv_metric_centralized_decentralized_no_f1[\"p-value\"] = spearman_rank_sv_metric_centralized_decentralized_no_f1[\"p-value\"].astype('float')\n",
    "\n",
    "pearson_correlation_sv_metric_centralized_decentralized_no_f1 = pearson_correlation_sv_metric_centralized_decentralized[(pearson_correlation_sv_metric_centralized_decentralized[\"Metric\"] != \"F1Score\") & (spearman_rank_sv_metric_centralized_decentralized[\"Metric\"] != \"CosineSimilarity\")]\n",
    "\n",
    "pearson_correlation_sv_metric_centralized_decentralized_no_f1[\"PearsonCorrelation\"] = pearson_correlation_sv_metric_centralized_decentralized_no_f1[\"PearsonCorrelation\"].astype('float')\n",
    "pearson_correlation_sv_metric_centralized_decentralized_no_f1[\"p-value\"] = pearson_correlation_sv_metric_centralized_decentralized_no_f1[\"p-value\"].astype('float')\n",
    "\n",
    "display(spearman_rank_sv_metric_centralized_decentralized_no_f1.groupby([\"Dataset\"]).mean(numeric_only=True))\n",
    "\n",
    "display(spearman_rank_sv_metric_centralized_decentralized_no_f1.groupby([\"Dataset\", \"Metric\"]).mean(numeric_only=True))\n",
    "\n",
    "display(spearman_rank_sv_metric_centralized_decentralized_no_f1.groupby([\"Metric\"]).mean(numeric_only=True))\n",
    "\n",
    "display(spearman_rank_sv_metric_centralized_decentralized_no_f1[spearman_rank_sv_metric_centralized_decentralized_no_f1[\"SpearmanRank\"] != 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spearman_rank_sv_metric_centralized_decentralized_no_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pearson_correlation_sv_metric_centralized_decentralized_no_f1.groupby([\"Dataset\"]).mean(numeric_only=True))\n",
    "\n",
    "display(pearson_correlation_sv_metric_centralized_decentralized_no_f1.groupby([\"Dataset\", \"Metric\"]).mean(numeric_only=True))\n",
    "\n",
    "display(pearson_correlation_sv_metric_centralized_decentralized_no_f1[pearson_correlation_sv_metric_centralized_decentralized_no_f1[\"PearsonCorrelation\"] != 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_results_dataframes = get_results_from_route(\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_1\")\n",
    "\n",
    "results_dataframe = pd.read_csv(path_to_results_dataframes + os.sep + \"Shapley_Value\" + os.sep + \"SV_CrossEntropyLoss\")\n",
    "grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearman_correlation_distance(dataset_name, type_of_partition, additional_parameter, type_of_loss):\n",
    "    path_to_distance_dataframes = get_distances_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "    path_to_results_dataframes = get_results_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "\n",
    "    spearman_rank_sv_metric_centralized_decentralized = pd.DataFrame()\n",
    "    distances = []\n",
    "    spearman_values = []\n",
    "    spearman_p_values = []\n",
    "\n",
    "    print(f\"Dataset name: {dataset_name}\")\n",
    "    print(f\"Type_of_partition name: {type_of_partition}\")\n",
    "    print(f\"Additional_parameter name: {additional_parameter}\")\n",
    "    \n",
    "    if type_of_loss == \"MAE\":\n",
    "        results_dataframe = pd.read_csv(path_to_results_dataframes + os.sep + \"Shapley_Value\" + os.sep + \"SV_MAE\")\n",
    "    else:\n",
    "        results_dataframe = pd.read_csv(path_to_results_dataframes + os.sep + \"Shapley_Value\" + os.sep + \"SV_CrossEntropyLoss\")\n",
    "    \n",
    "    grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)\n",
    "    grouped_sv.drop(\"Aggregated\", inplace=True)\n",
    "\n",
    "    # display(grouped_sv)\n",
    "\n",
    "    for file in os.listdir(path_to_distance_dataframes):\n",
    "        distances.append(file.split('.')[0])\n",
    "        if file == \"volume.csv\":\n",
    "            volume_series = pd.read_csv(path_to_distance_dataframes + os.sep + file, index_col=0)\n",
    "            volume_series.drop(\"Global\", inplace=True)\n",
    "            def statistic(x): # permute only `x`\n",
    "                return scipy.stats.spearmanr(x, grouped_sv.loc[\"Centralized\"]).statistic\n",
    "            res_exact = scipy.stats.permutation_test((volume_series.loc[:],), statistic,\n",
    "                permutation_type='pairings')\n",
    "            spearman_values.append(res_exact.statistic[0])\n",
    "            spearman_p_values.append(res_exact.pvalue[0])\n",
    "\n",
    "        else:\n",
    "            distance_dataframe = pd.read_csv(path_to_distance_dataframes + os.sep + file, index_col=0)\n",
    "            spearman_list = []\n",
    "            pvalue_list = []\n",
    "            for index, row in grouped_sv.iterrows():\n",
    "                if index == \"Centralized\":\n",
    "                    # def statistic(x): # permute only `x`\n",
    "                    #     return scipy.stats.spearmanr(x, grouped_sv.loc[\"Centralized\"]).statistic\n",
    "                    # res_exact = scipy.stats.permutation_test((distance_dataframe.loc[:, \"Global\"],), statistic,\n",
    "                    #     permutation_type='pairings')\n",
    "                    res_exact = scipy.stats.spearmanr(grouped_sv.loc[\"Centralized\"], distance_dataframe.loc[:, \"Global\"])\n",
    "                    spearman_list.append(res_exact.statistic)\n",
    "                    pvalue_list.append(res_exact.pvalue)\n",
    "                else:\n",
    "                    # def statistic(x): # permute only `x`\n",
    "                    #     return scipy.stats.spearmanr(x, grouped_sv.loc[str(index)]).statistic\n",
    "                    # res_exact = scipy.stats.permutation_test((distance_dataframe.loc[:, str(index)],), statistic,\n",
    "                    #     permutation_type='pairings')\n",
    "                    res_exact = scipy.stats.spearmanr(grouped_sv.loc[str(index)], distance_dataframe.loc[:, str(index)])\n",
    "                    spearman_list.append(res_exact.statistic)\n",
    "                    pvalue_list.append(res_exact.pvalue)\n",
    "\n",
    "            # Fisher transformation for averaging correlations.\n",
    "            spearman_values.append(np.tanh(np.mean(np.arctanh(spearman_list))))\n",
    "            spearman_p_values.append(np.mean(pvalue_list))\n",
    "\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"Dataset\"] = [dataset_name for _ in range(len(distances))]\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"TypePartition\"] = [type_of_partition for _ in range(len(distances))]\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"AdditionalParameter\"] = [additional_parameter for _ in range(len(distances))]\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"Distance\"] = distances\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"SpearmanCorrelation\"] = spearman_values\n",
    "    spearman_rank_sv_metric_centralized_decentralized[\"p-value-spearman\"] = spearman_p_values\n",
    "\n",
    "    return spearman_rank_sv_metric_centralized_decentralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pearson_correlation_distance(dataset_name, type_of_partition, additional_parameter, type_of_loss=\"CrossEntropyLoss\"):\n",
    "    path_to_distance_dataframes = get_distances_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "    path_to_results_dataframes = get_results_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "\n",
    "    pearson_sv_metric_centralized_decentralized = pd.DataFrame()\n",
    "    distances = []\n",
    "    pearson_values = []\n",
    "    pearson_p_values = []\n",
    "    variance_scenario = []\n",
    "\n",
    "    print(f\"Dataset name: {dataset_name}\")\n",
    "    print(f\"Type_of_partition name: {type_of_partition}\")\n",
    "    print(f\"Additional_parameter name: {additional_parameter}\")\n",
    "\n",
    "    if type_of_loss == \"MAE\":\n",
    "        results_dataframe = pd.read_csv(path_to_results_dataframes + os.sep + \"Shapley_Value\" + os.sep + \"SV_MAE\")\n",
    "    else:\n",
    "        results_dataframe = pd.read_csv(path_to_results_dataframes + os.sep + \"Shapley_Value\" + os.sep + \"SV_CrossEntropyLoss\")\n",
    "        \n",
    "    grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)\n",
    "    grouped_sv.drop(\"Aggregated\", inplace=True)\n",
    "\n",
    "    # display(grouped_sv)\n",
    "\n",
    "    for file in os.listdir(path_to_distance_dataframes):\n",
    "        distances.append(file.split('.')[0])\n",
    "        if file == \"volume.csv\":\n",
    "            volume_series = pd.read_csv(path_to_distance_dataframes + os.sep + file, index_col=0)\n",
    "            volume_series.drop(\"Global\", inplace=True)\n",
    "            res_exact = scipy.stats.pearsonr(grouped_sv.loc[\"Centralized\"], volume_series.to_numpy().reshape(-1))\n",
    "            pearson_values.append(res_exact.statistic)\n",
    "            pearson_p_values.append(res_exact.pvalue)\n",
    "            # variance_scenario.append(np.var(grouped_sv.loc[\"Centralized\"]))\n",
    "        else:\n",
    "            distance_dataframe = pd.read_csv(path_to_distance_dataframes + os.sep + file, index_col=0)\n",
    "            if file == \"yShiftDataframe.csv\":\n",
    "                distance_dataframe.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "                distance_dataframe.replace([np.NAN], 0, inplace=True)\n",
    "            pearsonr_list = []\n",
    "            pvalue_list = []\n",
    "            for index, row in grouped_sv.iterrows():\n",
    "                if index == \"Centralized\":\n",
    "                    res_exact = scipy.stats.pearsonr(grouped_sv.loc[\"Centralized\"], distance_dataframe.loc[:, \"Global\"])\n",
    "                    pearsonr_list.append(res_exact.statistic)\n",
    "                    pvalue_list.append(res_exact.pvalue)\n",
    "                else:            \n",
    "                    res_exact = scipy.stats.pearsonr(grouped_sv.loc[str(index)], distance_dataframe.loc[:, str(index)])\n",
    "                    pearsonr_list.append(res_exact.statistic)\n",
    "                    pvalue_list.append(res_exact.pvalue)\n",
    "\n",
    "            # variance_scenario.append(np.var(grouped_sv.loc[\"Centralized\"]))\n",
    "            # Fisher transformation for averaging correlations.\n",
    "            pearson_values.append(np.tanh(np.mean(np.arctanh(pearsonr_list))))\n",
    "            pearson_p_values.append(np.mean(pvalue_list))\n",
    "\n",
    "    pearson_sv_metric_centralized_decentralized[\"Dataset\"] = [dataset_name for _ in range(len(distances))]\n",
    "    pearson_sv_metric_centralized_decentralized[\"TypePartition\"] = [type_of_partition for _ in range(len(distances))]\n",
    "    pearson_sv_metric_centralized_decentralized[\"AdditionalParameter\"] = [additional_parameter for _ in range(len(distances))]\n",
    "    pearson_sv_metric_centralized_decentralized[\"Distance\"] = distances\n",
    "    pearson_sv_metric_centralized_decentralized[\"PearsonCorrelation\"] = pearson_values\n",
    "    pearson_sv_metric_centralized_decentralized[\"p-value-pearson\"] = pearson_p_values\n",
    "    # pearson_sv_metric_centralized_decentralized[\"VarianceSV\"] = variance_scenario\n",
    "\n",
    "    return pearson_sv_metric_centralized_decentralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_to_compare = [\n",
    "    # (\"adult\", \"dirichlet\", \"0.1\"),\n",
    "    # (\"adult\", \"dirichlet\", \"1\"),\n",
    "    # (\"adult\", \"dirichlet\", \"10\"),\n",
    "    # (\"adult\", \"dirichlet\", \"100\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Doctorate\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Masters\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Occupation\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Occupation_ExecManagerial\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Studies\"),\n",
    "    (\"har\", \"dirichlet\", \"1\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"dirichlet\", \"10\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"dirichlet\", \"100\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_label_skew\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_LessLabels\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_MissingTwoLabels\", \"CrossEntropyLoss\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_1_HellingerTrap\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Laying\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_1\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_2\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_3\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_4\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_5\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_2\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_3\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_4\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_5\", \"CrossEntropyLoss\"),\n",
    "    # (\"covertype\", \"dirichlet\", \"1\"),\n",
    "    # (\"covertype\", \"dirichlet\", \"10\"),\n",
    "    # (\"covertype\", \"dirichlet\", \"100\"),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_Maverick_LeastNumerousClass\"),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_Maverick_MostNumerousClass\"),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_FS_WildernessArea\"),\n",
    "    # (\"new_adult\", \"dirichlet\", \"1\"),\n",
    "    # (\"new_adult\", \"dirichlet\", \"10\"),\n",
    "    # (\"new_adult\", \"dirichlet\", \"100\"),\n",
    "    # (\"new_adult\", \"manual\", \"New_Adult_AL_CO_CT_MA\")\n",
    "    (\"edge-iot-coreset\", \"dirichlet\", \"10\", \"CrossEntropyLoss\"),\n",
    "    (\"edge-iot-coreset\", \"dirichlet\", \"100\", \"CrossEntropyLoss\"),\n",
    "    (\"edge-iot-coreset\", \"dirichlet\", \"1000\", \"CrossEntropyLoss\"),\n",
    "    (\"edge-iot-coreset\", \"dirichlet\", \"10000\", \"CrossEntropyLoss\"),\n",
    "    (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_LeastAttack\", \"CrossEntropyLoss\"),\n",
    "    (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_OnlyNormal\", \"CrossEntropyLoss\"),\n",
    "    (\"electric-consumption\", \"manual\", \"Electric_Consumption_Random_Sampling\", \"MAE\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumptionFacilityType\", \"MAE\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumptionNoniid\", \"MAE\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumptionStateFactor\", \"MAE\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickMultifamilyUncategorized\", \"MAE\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickGroceryStore\", \"MAE\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: har\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 1\n",
      "Dataset name: har\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 1\n",
      "Dataset name: har\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: har\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 10\n",
      "Dataset name: har\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 100\n",
      "Dataset name: har\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 100\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_label_skew\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_label_skew\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_LessLabels\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_LessLabels\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_MissingTwoLabels\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_MissingTwoLabels\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_HellingerTrap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_HellingerTrap\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Laying\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Laying\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_1\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_1\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_2\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_2\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_3\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_3\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_4\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_4\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_5\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_5\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_2\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_2\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_3\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_3\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_4\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_4\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_5\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_5\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 10\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 10\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 100\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 100\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 1000\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 1000\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 10000\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: dirichlet\n",
      "Additional_parameter name: 10000\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: EdgeIIOT_Maverick_LeastAttack\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: EdgeIIOT_Maverick_LeastAttack\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: EdgeIIOT_Maverick_OnlyNormal\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: EdgeIIOT_Maverick_OnlyNormal\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: Electric_Consumption_Random_Sampling\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: Electric_Consumption_Random_Sampling\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumptionFacilityType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumptionFacilityType\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumptionNoniid\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumptionNoniid\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumptionStateFactor\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumptionStateFactor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumption_FeatureSkew_MaverickMultifamilyUncategorized\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumption_FeatureSkew_MaverickMultifamilyUncategorized\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumption_FeatureSkew_MaverickGroceryStore\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumption_FeatureSkew_MaverickGroceryStore\n"
     ]
    }
   ],
   "source": [
    "spearman_rank_sv_distance = pd.DataFrame()\n",
    "pearson_rank_sv_distance = pd.DataFrame()\n",
    "\n",
    "\n",
    "for dataset_name, type_of_partition, additional_parameter, type_of_loss in distances_to_compare:\n",
    "    spearman_rank_sv_distance = pd.concat([spearman_rank_sv_distance, compute_spearman_correlation_distance(dataset_name, type_of_partition, additional_parameter, type_of_loss)], ignore_index=True)\n",
    "    pearson_rank_sv_distance = pd.concat([pearson_rank_sv_distance, compute_pearson_correlation_distance(dataset_name, type_of_partition, additional_parameter, type_of_loss)], ignore_index=True)\n",
    "\n",
    "correlation_sv_distance = spearman_rank_sv_distance.copy()\n",
    "correlation_sv_distance[\"PearsonCorrelation\"] = pearson_rank_sv_distance[\"PearsonCorrelation\"]\n",
    "correlation_sv_distance[\"p-value-pearson\"] = pearson_rank_sv_distance[\"p-value-pearson\"]\n",
    "# correlation_sv_distance[\"VarianceSV\"] = pearson_rank_sv_distance[\"VarianceSV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spearman_rank_sv_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>TypePartition</th>\n",
       "      <th>AdditionalParameter</th>\n",
       "      <th>Distance</th>\n",
       "      <th>SpearmanCorrelation</th>\n",
       "      <th>p-value-spearman</th>\n",
       "      <th>PearsonCorrelation</th>\n",
       "      <th>p-value-pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>har</td>\n",
       "      <td>dirichlet</td>\n",
       "      <td>1</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.136397</td>\n",
       "      <td>-0.739649</td>\n",
       "      <td>0.211859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>har</td>\n",
       "      <td>dirichlet</td>\n",
       "      <td>10</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.829407</td>\n",
       "      <td>0.083019</td>\n",
       "      <td>-0.895273</td>\n",
       "      <td>0.023951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>har</td>\n",
       "      <td>dirichlet</td>\n",
       "      <td>100</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.574081</td>\n",
       "      <td>0.095417</td>\n",
       "      <td>0.534690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_label_skew</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.469520</td>\n",
       "      <td>0.309531</td>\n",
       "      <td>-0.860720</td>\n",
       "      <td>0.299710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_LessLabels</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.670174</td>\n",
       "      <td>0.221135</td>\n",
       "      <td>-0.839781</td>\n",
       "      <td>0.148267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_MissingTwoLabels</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.315995</td>\n",
       "      <td>0.362822</td>\n",
       "      <td>-0.486999</td>\n",
       "      <td>0.202048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_HellingerTrap</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.589194</td>\n",
       "      <td>0.291905</td>\n",
       "      <td>-0.833615</td>\n",
       "      <td>0.230653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Laying</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.414618</td>\n",
       "      <td>0.336900</td>\n",
       "      <td>-0.739578</td>\n",
       "      <td>0.280458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Balanced_Laying_1</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.594310</td>\n",
       "      <td>0.298389</td>\n",
       "      <td>-0.782848</td>\n",
       "      <td>0.262692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Balanced_Laying_2</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.257906</td>\n",
       "      <td>0.523555</td>\n",
       "      <td>-0.714719</td>\n",
       "      <td>0.309511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Balanced_Laying_3</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.201825</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>-0.655634</td>\n",
       "      <td>0.478997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Balanced_Laying_4</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.118655</td>\n",
       "      <td>0.543880</td>\n",
       "      <td>-0.412555</td>\n",
       "      <td>0.359112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Balanced_Laying_5</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.368818</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>-0.739509</td>\n",
       "      <td>0.382954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_Balanced_WalkingUpstairs</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.241428</td>\n",
       "      <td>0.534357</td>\n",
       "      <td>-0.720465</td>\n",
       "      <td>0.304173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_Balanced_WalkingUpstairs_2</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.223964</td>\n",
       "      <td>0.519990</td>\n",
       "      <td>-0.577770</td>\n",
       "      <td>0.181766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_Balanced_WalkingUpstairs_3</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.368207</td>\n",
       "      <td>0.484245</td>\n",
       "      <td>-0.722061</td>\n",
       "      <td>0.223588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_Balanced_WalkingUpstairs_4</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.053974</td>\n",
       "      <td>0.460481</td>\n",
       "      <td>-0.477469</td>\n",
       "      <td>0.187742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_Balanced_WalkingUpstairs_5</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.023425</td>\n",
       "      <td>0.494354</td>\n",
       "      <td>-0.558173</td>\n",
       "      <td>0.212005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>edge-iot-coreset</td>\n",
       "      <td>dirichlet</td>\n",
       "      <td>10</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.999997</td>\n",
       "      <td>0.239609</td>\n",
       "      <td>-0.860849</td>\n",
       "      <td>0.220415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>edge-iot-coreset</td>\n",
       "      <td>dirichlet</td>\n",
       "      <td>100</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.857921</td>\n",
       "      <td>0.070737</td>\n",
       "      <td>-0.928630</td>\n",
       "      <td>0.074096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>edge-iot-coreset</td>\n",
       "      <td>dirichlet</td>\n",
       "      <td>1000</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.523655</td>\n",
       "      <td>0.162617</td>\n",
       "      <td>-0.790853</td>\n",
       "      <td>0.048101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>edge-iot-coreset</td>\n",
       "      <td>dirichlet</td>\n",
       "      <td>10000</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.587017</td>\n",
       "      <td>0.355997</td>\n",
       "      <td>-0.671126</td>\n",
       "      <td>0.301018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>edge-iot-coreset</td>\n",
       "      <td>manual</td>\n",
       "      <td>EdgeIIOT_Maverick_LeastAttack</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.080916</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>-0.021178</td>\n",
       "      <td>0.550751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>edge-iot-coreset</td>\n",
       "      <td>manual</td>\n",
       "      <td>EdgeIIOT_Maverick_OnlyNormal</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.725631</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>-0.999249</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>electric-consumption</td>\n",
       "      <td>manual</td>\n",
       "      <td>Electric_Consumption_Random_Sampling</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.263347</td>\n",
       "      <td>0.621113</td>\n",
       "      <td>-0.370049</td>\n",
       "      <td>0.516338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>electric-consumption</td>\n",
       "      <td>manual</td>\n",
       "      <td>ElectricConsumptionFacilityType</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.790235</td>\n",
       "      <td>0.100158</td>\n",
       "      <td>-0.721441</td>\n",
       "      <td>0.131823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>electric-consumption</td>\n",
       "      <td>manual</td>\n",
       "      <td>ElectricConsumptionNoniid</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-0.977659</td>\n",
       "      <td>0.048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>electric-consumption</td>\n",
       "      <td>manual</td>\n",
       "      <td>ElectricConsumptionStateFactor</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.024277</td>\n",
       "      <td>-0.907130</td>\n",
       "      <td>0.031149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>electric-consumption</td>\n",
       "      <td>manual</td>\n",
       "      <td>ElectricConsumption_FeatureSkew_MaverickMultif...</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.461969</td>\n",
       "      <td>0.553917</td>\n",
       "      <td>-0.457121</td>\n",
       "      <td>0.551401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>electric-consumption</td>\n",
       "      <td>manual</td>\n",
       "      <td>ElectricConsumption_FeatureSkew_MaverickGrocer...</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.519048</td>\n",
       "      <td>0.056933</td>\n",
       "      <td>0.412629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Dataset TypePartition  \\\n",
       "0                     har     dirichlet   \n",
       "9                     har     dirichlet   \n",
       "18                    har     dirichlet   \n",
       "27                    har        manual   \n",
       "36                    har        manual   \n",
       "45                    har        manual   \n",
       "54                    har        manual   \n",
       "63                    har        manual   \n",
       "72                    har        manual   \n",
       "81                    har        manual   \n",
       "90                    har        manual   \n",
       "99                    har        manual   \n",
       "108                   har        manual   \n",
       "117                   har        manual   \n",
       "126                   har        manual   \n",
       "135                   har        manual   \n",
       "144                   har        manual   \n",
       "153                   har        manual   \n",
       "162      edge-iot-coreset     dirichlet   \n",
       "171      edge-iot-coreset     dirichlet   \n",
       "180      edge-iot-coreset     dirichlet   \n",
       "189      edge-iot-coreset     dirichlet   \n",
       "198      edge-iot-coreset        manual   \n",
       "207      edge-iot-coreset        manual   \n",
       "216  electric-consumption        manual   \n",
       "222  electric-consumption        manual   \n",
       "228  electric-consumption        manual   \n",
       "234  electric-consumption        manual   \n",
       "240  electric-consumption        manual   \n",
       "246  electric-consumption        manual   \n",
       "\n",
       "                                   AdditionalParameter  \\\n",
       "0                                                    1   \n",
       "9                                                   10   \n",
       "18                                                 100   \n",
       "27                         HAR_1_Maverick_1_label_skew   \n",
       "36                         HAR_1_Maverick_1_LessLabels   \n",
       "45                   HAR_1_Maverick_1_MissingTwoLabels   \n",
       "54                      HAR_1_Maverick_1_HellingerTrap   \n",
       "63                               HAR_1_Maverick_Laying   \n",
       "72                    HAR_1_Maverick_Balanced_Laying_1   \n",
       "81                    HAR_1_Maverick_Balanced_Laying_2   \n",
       "90                    HAR_1_Maverick_Balanced_Laying_3   \n",
       "99                    HAR_1_Maverick_Balanced_Laying_4   \n",
       "108                   HAR_1_Maverick_Balanced_Laying_5   \n",
       "117          HAR_1_Maverick_1_Balanced_WalkingUpstairs   \n",
       "126        HAR_1_Maverick_1_Balanced_WalkingUpstairs_2   \n",
       "135        HAR_1_Maverick_1_Balanced_WalkingUpstairs_3   \n",
       "144        HAR_1_Maverick_1_Balanced_WalkingUpstairs_4   \n",
       "153        HAR_1_Maverick_1_Balanced_WalkingUpstairs_5   \n",
       "162                                                 10   \n",
       "171                                                100   \n",
       "180                                               1000   \n",
       "189                                              10000   \n",
       "198                      EdgeIIOT_Maverick_LeastAttack   \n",
       "207                       EdgeIIOT_Maverick_OnlyNormal   \n",
       "216               Electric_Consumption_Random_Sampling   \n",
       "222                    ElectricConsumptionFacilityType   \n",
       "228                          ElectricConsumptionNoniid   \n",
       "234                     ElectricConsumptionStateFactor   \n",
       "240  ElectricConsumption_FeatureSkew_MaverickMultif...   \n",
       "246  ElectricConsumption_FeatureSkew_MaverickGrocer...   \n",
       "\n",
       "                   Distance  SpearmanCorrelation  p-value-spearman  \\\n",
       "0    performanceDegradation            -1.000000          0.136397   \n",
       "9    performanceDegradation            -0.829407          0.083019   \n",
       "18   performanceDegradation             0.000700          0.574081   \n",
       "27   performanceDegradation            -0.469520          0.309531   \n",
       "36   performanceDegradation            -0.670174          0.221135   \n",
       "45   performanceDegradation            -0.315995          0.362822   \n",
       "54   performanceDegradation            -0.589194          0.291905   \n",
       "63   performanceDegradation            -0.414618          0.336900   \n",
       "72   performanceDegradation            -0.594310          0.298389   \n",
       "81   performanceDegradation            -0.257906          0.523555   \n",
       "90   performanceDegradation            -0.201825          0.616456   \n",
       "99   performanceDegradation            -0.118655          0.543880   \n",
       "108  performanceDegradation            -0.368818          0.455450   \n",
       "117  performanceDegradation            -0.241428          0.534357   \n",
       "126  performanceDegradation            -0.223964          0.519990   \n",
       "135  performanceDegradation            -0.368207          0.484245   \n",
       "144  performanceDegradation            -0.053974          0.460481   \n",
       "153  performanceDegradation            -0.023425          0.494354   \n",
       "162  performanceDegradation            -0.999997          0.239609   \n",
       "171  performanceDegradation            -0.857921          0.070737   \n",
       "180  performanceDegradation            -0.523655          0.162617   \n",
       "189  performanceDegradation            -0.587017          0.355997   \n",
       "198  performanceDegradation            -0.080916          0.560000   \n",
       "207  performanceDegradation            -0.725631          0.320000   \n",
       "216  performanceDegradation            -0.263347          0.621113   \n",
       "222  performanceDegradation            -0.790235          0.100158   \n",
       "228  performanceDegradation            -1.000000          0.080000   \n",
       "234  performanceDegradation            -1.000000          0.024277   \n",
       "240  performanceDegradation            -0.461969          0.553917   \n",
       "246  performanceDegradation             0.132353          0.519048   \n",
       "\n",
       "     PearsonCorrelation  p-value-pearson  \n",
       "0             -0.739649         0.211859  \n",
       "9             -0.895273         0.023951  \n",
       "18             0.095417         0.534690  \n",
       "27            -0.860720         0.299710  \n",
       "36            -0.839781         0.148267  \n",
       "45            -0.486999         0.202048  \n",
       "54            -0.833615         0.230653  \n",
       "63            -0.739578         0.280458  \n",
       "72            -0.782848         0.262692  \n",
       "81            -0.714719         0.309511  \n",
       "90            -0.655634         0.478997  \n",
       "99            -0.412555         0.359112  \n",
       "108           -0.739509         0.382954  \n",
       "117           -0.720465         0.304173  \n",
       "126           -0.577770         0.181766  \n",
       "135           -0.722061         0.223588  \n",
       "144           -0.477469         0.187742  \n",
       "153           -0.558173         0.212005  \n",
       "162           -0.860849         0.220415  \n",
       "171           -0.928630         0.074096  \n",
       "180           -0.790853         0.048101  \n",
       "189           -0.671126         0.301018  \n",
       "198           -0.021178         0.550751  \n",
       "207           -0.999249         0.001033  \n",
       "216           -0.370049         0.516338  \n",
       "222           -0.721441         0.131823  \n",
       "228           -0.977659         0.048384  \n",
       "234           -0.907130         0.031149  \n",
       "240           -0.457121         0.551401  \n",
       "246            0.056933         0.412629  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(correlation_sv_distance[correlation_sv_distance[\"Distance\"] == \"performanceDegradation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/plotly/io/_renderers.py:395: DeprecationWarning:\n",
      "\n",
      "distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4
         ],
         "xaxis": "x",
         "y": [
          0,
          1,
          4,
          9,
          16
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Performance Degradation (I)",
         "type": "box",
         "y": [
          -0.7396489793567154,
          -0.8952730246719276,
          0.0954174509076023,
          -0.860720468490259,
          -0.8397808925541382,
          -0.48699881288579067,
          -0.8336153804556183,
          -0.7395783948974589,
          -0.7828480997029419,
          -0.714719115106486,
          -0.6556339062716975,
          -0.4125551279637467,
          -0.7395093173640934,
          -0.7204652255222602,
          -0.5777701400099555,
          -0.7220613619738355,
          -0.47746897191959575,
          -0.5581727296576867,
          -0.8608486299658092,
          -0.9286298003437425,
          -0.7908533987801258,
          -0.6711255190685709,
          -0.02117811614719925,
          -0.9992489242869516,
          -0.3700486211531173,
          -0.7214410015143873,
          -0.977659370576703,
          -0.9071303258230654,
          -0.45712087683731467,
          0.056932914557039006
         ]
        },
        {
         "name": "X->Y Shift (I)",
         "type": "box",
         "y": [
          -0.6435469279094704,
          0.33335674718722147,
          -0.16215416602798466,
          -0.112463481482596,
          0.26720728304687746,
          0.010624764404130776,
          -0.2074382667204021,
          0.08390319750443963,
          0.09757500397076156,
          0.14427491226174458,
          -0.06851589543103878,
          -0.048412606762613525,
          0.06718732014525276,
          -0.32783616283215883,
          0.07755351865735338,
          -0.17087187972808296,
          -0.3281309799192527,
          -0.07193921093020676,
          0.8706041787682308,
          0.6647635360587322,
          0.4197009642370714,
          -0.13614242782159852,
          0.07185267930034278,
          0.2610229072216012
         ]
        },
        {
         "name": "Relevance (D)",
         "type": "box",
         "y": [
          0.23141536126932485,
          0.07279563564059488,
          0.25084009757476605,
          0.8855564517560233,
          0.7813808534242065,
          0.7236252524010833,
          0.7673732542069264,
          0.5889580097968315,
          0.4228683486530428,
          0.6289298123023312,
          0.7364805793205094,
          0.4007618013966283,
          0.6920297210946502,
          -0.0007523773386801709,
          0.09612164011358265,
          0.006030961978410667,
          0.2899227126168447,
          0.41845592149058497,
          0.5558812615165374,
          0.1564851954309201,
          0.8020385414517852,
          0.5491873049610525,
          -0.028142375947970175,
          0.99846722698509,
          -0.45861910253176186,
          0.8617288965383954,
          0.1567303057993076,
          0.9591798579928471,
          0.6847823596789568,
          -0.4096214630479249
         ]
        },
        {
         "name": "Diversity (D)",
         "type": "box",
         "y": [
          -0.2542899764473408,
          -0.1015842304117175,
          -0.18183878680471013,
          -0.8857285008830107,
          -0.8572573829066078,
          -0.7165883256528509,
          -0.8398121927867848,
          -0.6355994566823694,
          -0.5235782968534739,
          -0.6135683477871475,
          -0.644597347921074,
          -0.4144254003737963,
          -0.6228894161904578,
          -0.45505465166328224,
          -0.16760323253777754,
          -0.21663649483938294,
          -0.34627493500446316,
          -0.4482246992470378,
          -0.5246872357230086,
          -0.41557988782074456,
          -0.9278373721033856,
          -0.6668490538731604,
          -0.12609251230902144,
          -0.9997610748553825,
          0.44182060928991046,
          -0.8744985974399306,
          -0.7314831546610423,
          -0.9539730460687387,
          -0.6785291195518186,
          -0.04506360329289912
         ]
        },
        {
         "name": "Hellinger Distance (I)",
         "type": "box",
         "y": [
          -0.8415271735668401,
          -0.8698222019761781,
          -0.2701268041682608,
          -0.819275851975691,
          -0.7556737084195664,
          -0.7708186811021968,
          -0.9719171075387679,
          -0.6477368732774152,
          -0.8024248315636371,
          -0.5027626830558364,
          -0.9319320697440344,
          -0.6747227668113155,
          -0.9156227963993826,
          -0.8744543571399408,
          -0.7756162005175992,
          -0.729176321598804,
          -0.8531726379937116,
          -0.896833461048736,
          -0.8359199873704414,
          -0.9368229020519082,
          -0.910663752924278,
          -0.868602582839655,
          -0.46355405148010087,
          -0.9999918375934651
         ]
        },
        {
         "name": "Wasserstein Distance (I)",
         "type": "box",
         "y": [
          -0.1366091172221408,
          -0.3753752953890878,
          -0.1417516027388004,
          -0.7221511725928396,
          -0.5609230400525919,
          -0.6064159515105518,
          -0.7877759061282308,
          -0.1841509046141856,
          -0.8272286510075479,
          -0.6773420811144789,
          -0.8452034574299482,
          -0.7385346493763615,
          -0.833663226360627,
          -0.7374363469366002,
          -0.6900517894893616,
          -0.5798772109351871,
          -0.7715974683214815,
          -0.7346575842661048,
          -0.5048107920852828,
          -0.8160446826730829,
          -0.9778151586160105,
          -0.6979633659518361,
          -0.28919578448982536,
          -0.9999903662769516,
          0.11768985730335904,
          -0.8029766283941527,
          -0.6609671617850462,
          -0.914874425805888,
          -0.6721713722638384,
          -0.04306339458108322
         ]
        },
        {
         "name": "MMD - Gaussian Kernel (I)",
         "type": "box",
         "y": [
          -0.5895098792653282,
          -0.38139565149060667,
          -0.034468149031055384,
          -0.7763531209426201,
          -0.6917121451791555,
          -0.36695838157081423,
          -0.7616337248012623,
          -0.6607222472174431,
          -0.7253470065178035,
          -0.6800477631614493,
          -0.6946606792778677,
          -0.7499967795278661,
          -0.6974531314763418,
          -0.6830182038203291,
          -0.6474305906850649,
          -0.5844058566235307,
          -0.7385050795327852,
          -0.7310177198992036,
          -0.40006402440434474,
          -0.7958788096806698,
          -0.5365124271102214,
          -0.6515749488766459,
          -0.4195623551502995,
          -0.9999035537270232,
          0.007697108385444554,
          -0.753832587607394,
          -0.8190045378040185,
          -0.9610937614399943,
          -0.6747193193091693,
          -0.004371285589789116
         ]
        },
        {
         "name": "Volume of data (D)",
         "type": "box",
         "y": [
          0.5807921379731323,
          0.0031297786302292158,
          -0.3978558695342257,
          0.9984796720484961,
          0.9645196781601566,
          0.9372674124536785,
          0.9462882574395162,
          0.9771163644968677,
          0.8399114606802965,
          0.8606283290594224,
          0.8309675289686376,
          0.8793165258124618,
          0.8159862672961831,
          0.7219482781666132,
          0.7505509405905877,
          0.4668553020901338,
          0.9098091182853213,
          0.8490511868917285,
          0.593979230627667,
          -0.888178633099534,
          -0.8269747874682731,
          0.36447750677023316,
          0.39588061075791486,
          0.9994610393041108,
          0.07122920669253802,
          0.962476129074936,
          -0.7001825808746092,
          0.8220525859879961,
          0.6881411157371031,
          -0.418775124922553
         ]
        }
       ],
       "layout": {
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Pearson Correlation between Distance and Value"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "#garbage graph\n",
    "fig = px.scatter(x=[0, 1, 2, 3, 4], y=[0, 1, 4, 9, 16])\n",
    "fig.show()\n",
    "fig.write_image(\"random.pdf\")\n",
    "\n",
    "\n",
    "distance_dictionary = {\n",
    "    \"performanceDegradation\": \"Performance Degradation (I)\",\n",
    "    \"yShiftDataframe\": \"X->Y Shift (I)\",\n",
    "    \"relevance\": \"Relevance (D)\",\n",
    "    \"diversity\": \"Diversity (D)\",\n",
    "    \"hellinger\": \"Hellinger Distance (I)\",\n",
    "    \"wasserstein\": \"Wasserstein Distance (I)\",\n",
    "    \"gaussian_mmd\": \"MMD - Gaussian Kernel (I)\",\n",
    "    \"volume\": \"Volume of data (D)\"\n",
    "}\n",
    "\n",
    "fig = go.Figure()\n",
    "for metric, name_of_metric in distance_dictionary.items():\n",
    "    sliced_df = correlation_sv_distance[correlation_sv_distance[\"Distance\"] == metric]\n",
    "    fig.add_trace(go.Box(y=sliced_df[\"PearsonCorrelation\"], name=name_of_metric))\n",
    "\n",
    "\n",
    "fig.update_layout(title_text=\"Pearson Correlation between Distance and Value\", showlegend=False)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(\"images/distance_value_pearson_correlation.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_only_mavericks_to_compare = [\n",
    "    # (\"adult\", \"dirichlet\", \"0.1\"),\n",
    "    # (\"adult\", \"dirichlet\", \"1\"),\n",
    "    # (\"adult\", \"dirichlet\", \"10\"),\n",
    "    # (\"adult\", \"dirichlet\", \"100\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Doctorate\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Masters\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Occupation\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Occupation_ExecManagerial\"),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Studies\"),\n",
    "    # (\"har\", \"dirichlet\", \"1\", \"CrossEntropyLoss\"),\n",
    "    # (\"har\", \"dirichlet\", \"10\", \"CrossEntropyLoss\"),\n",
    "    # (\"har\", \"dirichlet\", \"100\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_label_skew\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_LessLabels\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_MissingTwoLabels\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Laying\", \"CrossEntropyLoss\"),\n",
    "    # (\"har\", \"manual\", \"HAR_1_Maverick_1_HellingerTrap\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_1\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_2\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_3\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_4\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_5\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_2\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_3\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_4\", \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_5\", \"CrossEntropyLoss\"),\n",
    "    # (\"covertype\", \"dirichlet\", \"1\"),\n",
    "    # (\"covertype\", \"dirichlet\", \"10\"),\n",
    "    # (\"covertype\", \"dirichlet\", \"100\"),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_Maverick_LeastNumerousClass\"),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_Maverick_MostNumerousClass\"),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_FS_WildernessArea\"),\n",
    "    # (\"new_adult\", \"dirichlet\", \"1\"),\n",
    "    # (\"new_adult\", \"dirichlet\", \"10\"),\n",
    "    # (\"new_adult\", \"dirichlet\", \"100\"),\n",
    "    # (\"new_adult\", \"manual\", \"New_Adult_AL_CO_CT_MA\")\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"10\", \"CrossEntropyLoss\"),\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"100\", \"CrossEntropyLoss\"),\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"1000\", \"CrossEntropyLoss\"),\n",
    "    # (\"edge-iot-coreset\", \"dirichlet\", \"10000\", \"CrossEntropyLoss\"),\n",
    "    (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_LeastAttack\", \"CrossEntropyLoss\"),\n",
    "    (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_OnlyNormal\", \"CrossEntropyLoss\"),\n",
    "    # (\"electric-consumption\", \"manual\", \"Electric_Consumption_Random_Sampling\", \"MAE\"),\n",
    "    # (\"electric-consumption\", \"manual\", \"ElectricConsumptionFacilityType\", \"MAE\"),\n",
    "    # (\"electric-consumption\", \"manual\", \"ElectricConsumptionNoniid\", \"MAE\"),\n",
    "    # (\"electric-consumption\", \"manual\", \"ElectricConsumptionStateFactor\", \"MAE\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickMultifamilyUncategorized\", \"MAE\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickGroceryStore\", \"MAE\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_label_skew\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_label_skew\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_LessLabels\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_LessLabels\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_MissingTwoLabels\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_MissingTwoLabels\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Laying\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Laying\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_1\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_1\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_2\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_2\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_3\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_3\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_4\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_4\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_5\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_Balanced_Laying_5\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_2\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_2\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_3\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_3\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_4\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_4\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_5\n",
      "Dataset name: har\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: HAR_1_Maverick_1_Balanced_WalkingUpstairs_5\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: EdgeIIOT_Maverick_LeastAttack\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: EdgeIIOT_Maverick_LeastAttack\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: EdgeIIOT_Maverick_OnlyNormal\n",
      "Dataset name: edge-iot-coreset\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: EdgeIIOT_Maverick_OnlyNormal\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumption_FeatureSkew_MaverickMultifamilyUncategorized\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumption_FeatureSkew_MaverickMultifamilyUncategorized\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumption_FeatureSkew_MaverickGroceryStore\n",
      "Dataset name: electric-consumption\n",
      "Type_of_partition name: manual\n",
      "Additional_parameter name: ElectricConsumption_FeatureSkew_MaverickGroceryStore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n",
      "/tmp/ipykernel_10820/1154078255.py:59: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in arctanh\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spearman_rank_sv_distance = pd.DataFrame()\n",
    "pearson_rank_sv_distance = pd.DataFrame()\n",
    "\n",
    "\n",
    "for dataset_name, type_of_partition, additional_parameter, type_of_loss in distances_only_mavericks_to_compare:\n",
    "    spearman_rank_sv_distance = pd.concat([spearman_rank_sv_distance, compute_spearman_correlation_distance(dataset_name, type_of_partition, additional_parameter, type_of_loss)], ignore_index=True)\n",
    "    pearson_rank_sv_distance = pd.concat([pearson_rank_sv_distance, compute_pearson_correlation_distance(dataset_name, type_of_partition, additional_parameter, type_of_loss)], ignore_index=True)\n",
    "\n",
    "correlation_sv_distance_only_mavericks = spearman_rank_sv_distance.copy()\n",
    "correlation_sv_distance_only_mavericks[\"PearsonCorrelation\"] = pearson_rank_sv_distance[\"PearsonCorrelation\"]\n",
    "correlation_sv_distance_only_mavericks[\"p-value-pearson\"] = pearson_rank_sv_distance[\"p-value-pearson\"]\n",
    "# correlation_sv_distance[\"VarianceSV\"] = pearson_rank_sv_distance[\"VarianceSV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>TypePartition</th>\n",
       "      <th>AdditionalParameter</th>\n",
       "      <th>Distance</th>\n",
       "      <th>SpearmanCorrelation</th>\n",
       "      <th>p-value-spearman</th>\n",
       "      <th>PearsonCorrelation</th>\n",
       "      <th>p-value-pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_label_skew</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.469520</td>\n",
       "      <td>0.309531</td>\n",
       "      <td>-0.860720</td>\n",
       "      <td>0.299710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_LessLabels</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.670174</td>\n",
       "      <td>0.221135</td>\n",
       "      <td>-0.839781</td>\n",
       "      <td>0.148267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_MissingTwoLabels</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.315995</td>\n",
       "      <td>0.362822</td>\n",
       "      <td>-0.486999</td>\n",
       "      <td>0.202048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Laying</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.414618</td>\n",
       "      <td>0.336900</td>\n",
       "      <td>-0.739578</td>\n",
       "      <td>0.280458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Balanced_Laying_1</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.594310</td>\n",
       "      <td>0.298389</td>\n",
       "      <td>-0.782848</td>\n",
       "      <td>0.262692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Balanced_Laying_2</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.257906</td>\n",
       "      <td>0.523555</td>\n",
       "      <td>-0.714719</td>\n",
       "      <td>0.309511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Balanced_Laying_3</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.201825</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>-0.655634</td>\n",
       "      <td>0.478997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Balanced_Laying_4</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.118655</td>\n",
       "      <td>0.543880</td>\n",
       "      <td>-0.412555</td>\n",
       "      <td>0.359112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_Balanced_Laying_5</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.368818</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>-0.739509</td>\n",
       "      <td>0.382954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_Balanced_WalkingUpstairs</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.241428</td>\n",
       "      <td>0.534357</td>\n",
       "      <td>-0.720465</td>\n",
       "      <td>0.304173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_Balanced_WalkingUpstairs_2</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.223964</td>\n",
       "      <td>0.519990</td>\n",
       "      <td>-0.577770</td>\n",
       "      <td>0.181766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_Balanced_WalkingUpstairs_3</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.368207</td>\n",
       "      <td>0.484245</td>\n",
       "      <td>-0.722061</td>\n",
       "      <td>0.223588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_Balanced_WalkingUpstairs_4</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.053974</td>\n",
       "      <td>0.460481</td>\n",
       "      <td>-0.477469</td>\n",
       "      <td>0.187742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>har</td>\n",
       "      <td>manual</td>\n",
       "      <td>HAR_1_Maverick_1_Balanced_WalkingUpstairs_5</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.023425</td>\n",
       "      <td>0.494354</td>\n",
       "      <td>-0.558173</td>\n",
       "      <td>0.212005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>edge-iot-coreset</td>\n",
       "      <td>manual</td>\n",
       "      <td>EdgeIIOT_Maverick_LeastAttack</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.080916</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>-0.021178</td>\n",
       "      <td>0.550751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>edge-iot-coreset</td>\n",
       "      <td>manual</td>\n",
       "      <td>EdgeIIOT_Maverick_OnlyNormal</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.725631</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>-0.999249</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>electric-consumption</td>\n",
       "      <td>manual</td>\n",
       "      <td>ElectricConsumption_FeatureSkew_MaverickMultif...</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>-0.461969</td>\n",
       "      <td>0.553917</td>\n",
       "      <td>-0.457121</td>\n",
       "      <td>0.551401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>electric-consumption</td>\n",
       "      <td>manual</td>\n",
       "      <td>ElectricConsumption_FeatureSkew_MaverickGrocer...</td>\n",
       "      <td>performanceDegradation</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.519048</td>\n",
       "      <td>0.056933</td>\n",
       "      <td>0.412629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Dataset TypePartition  \\\n",
       "0                     har        manual   \n",
       "9                     har        manual   \n",
       "18                    har        manual   \n",
       "27                    har        manual   \n",
       "36                    har        manual   \n",
       "45                    har        manual   \n",
       "54                    har        manual   \n",
       "63                    har        manual   \n",
       "72                    har        manual   \n",
       "81                    har        manual   \n",
       "90                    har        manual   \n",
       "99                    har        manual   \n",
       "108                   har        manual   \n",
       "117                   har        manual   \n",
       "126      edge-iot-coreset        manual   \n",
       "135      edge-iot-coreset        manual   \n",
       "144  electric-consumption        manual   \n",
       "150  electric-consumption        manual   \n",
       "\n",
       "                                   AdditionalParameter  \\\n",
       "0                          HAR_1_Maverick_1_label_skew   \n",
       "9                          HAR_1_Maverick_1_LessLabels   \n",
       "18                   HAR_1_Maverick_1_MissingTwoLabels   \n",
       "27                               HAR_1_Maverick_Laying   \n",
       "36                    HAR_1_Maverick_Balanced_Laying_1   \n",
       "45                    HAR_1_Maverick_Balanced_Laying_2   \n",
       "54                    HAR_1_Maverick_Balanced_Laying_3   \n",
       "63                    HAR_1_Maverick_Balanced_Laying_4   \n",
       "72                    HAR_1_Maverick_Balanced_Laying_5   \n",
       "81           HAR_1_Maverick_1_Balanced_WalkingUpstairs   \n",
       "90         HAR_1_Maverick_1_Balanced_WalkingUpstairs_2   \n",
       "99         HAR_1_Maverick_1_Balanced_WalkingUpstairs_3   \n",
       "108        HAR_1_Maverick_1_Balanced_WalkingUpstairs_4   \n",
       "117        HAR_1_Maverick_1_Balanced_WalkingUpstairs_5   \n",
       "126                      EdgeIIOT_Maverick_LeastAttack   \n",
       "135                       EdgeIIOT_Maverick_OnlyNormal   \n",
       "144  ElectricConsumption_FeatureSkew_MaverickMultif...   \n",
       "150  ElectricConsumption_FeatureSkew_MaverickGrocer...   \n",
       "\n",
       "                   Distance  SpearmanCorrelation  p-value-spearman  \\\n",
       "0    performanceDegradation            -0.469520          0.309531   \n",
       "9    performanceDegradation            -0.670174          0.221135   \n",
       "18   performanceDegradation            -0.315995          0.362822   \n",
       "27   performanceDegradation            -0.414618          0.336900   \n",
       "36   performanceDegradation            -0.594310          0.298389   \n",
       "45   performanceDegradation            -0.257906          0.523555   \n",
       "54   performanceDegradation            -0.201825          0.616456   \n",
       "63   performanceDegradation            -0.118655          0.543880   \n",
       "72   performanceDegradation            -0.368818          0.455450   \n",
       "81   performanceDegradation            -0.241428          0.534357   \n",
       "90   performanceDegradation            -0.223964          0.519990   \n",
       "99   performanceDegradation            -0.368207          0.484245   \n",
       "108  performanceDegradation            -0.053974          0.460481   \n",
       "117  performanceDegradation            -0.023425          0.494354   \n",
       "126  performanceDegradation            -0.080916          0.560000   \n",
       "135  performanceDegradation            -0.725631          0.320000   \n",
       "144  performanceDegradation            -0.461969          0.553917   \n",
       "150  performanceDegradation             0.132353          0.519048   \n",
       "\n",
       "     PearsonCorrelation  p-value-pearson  \n",
       "0             -0.860720         0.299710  \n",
       "9             -0.839781         0.148267  \n",
       "18            -0.486999         0.202048  \n",
       "27            -0.739578         0.280458  \n",
       "36            -0.782848         0.262692  \n",
       "45            -0.714719         0.309511  \n",
       "54            -0.655634         0.478997  \n",
       "63            -0.412555         0.359112  \n",
       "72            -0.739509         0.382954  \n",
       "81            -0.720465         0.304173  \n",
       "90            -0.577770         0.181766  \n",
       "99            -0.722061         0.223588  \n",
       "108           -0.477469         0.187742  \n",
       "117           -0.558173         0.212005  \n",
       "126           -0.021178         0.550751  \n",
       "135           -0.999249         0.001033  \n",
       "144           -0.457121         0.551401  \n",
       "150            0.056933         0.412629  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_sv_distance_only_mavericks[correlation_sv_distance_only_mavericks[\"Distance\"] == \"performanceDegradation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Performance Degradation (I)",
         "type": "box",
         "y": [
          -0.860720468490259,
          -0.8397808925541382,
          -0.48699881288579067,
          -0.7395783948974589,
          -0.7828480997029419,
          -0.714719115106486,
          -0.6556339062716975,
          -0.4125551279637467,
          -0.7395093173640934,
          -0.7204652255222602,
          -0.5777701400099555,
          -0.7220613619738355,
          -0.47746897191959575,
          -0.5581727296576867,
          -0.02117811614719925,
          -0.9992489242869516,
          -0.45712087683731467,
          0.056932914557039006
         ]
        },
        {
         "name": "X->Y Shift (I)",
         "type": "box",
         "y": [
          -0.112463481482596,
          0.26720728304687746,
          0.010624764404130776,
          0.08390319750443963,
          0.09757500397076156,
          0.14427491226174458,
          -0.06851589543103878,
          -0.048412606762613525,
          0.06718732014525276,
          -0.32783616283215883,
          0.07755351865735338,
          -0.17087187972808296,
          -0.3281309799192527,
          -0.07193921093020676,
          0.07185267930034278,
          0.2610229072216012
         ]
        },
        {
         "name": "Relevance (D)",
         "type": "box",
         "y": [
          0.8855564517560233,
          0.7813808534242065,
          0.7236252524010833,
          0.5889580097968315,
          0.4228683486530428,
          0.6289298123023312,
          0.7364805793205094,
          0.4007618013966283,
          0.6920297210946502,
          -0.0007523773386801709,
          0.09612164011358265,
          0.006030961978410667,
          0.2899227126168447,
          0.41845592149058497,
          -0.028142375947970175,
          0.99846722698509,
          0.6847823596789568,
          -0.4096214630479249
         ]
        },
        {
         "name": "Diversity (D)",
         "type": "box",
         "y": [
          -0.8857285008830107,
          -0.8572573829066078,
          -0.7165883256528509,
          -0.6355994566823694,
          -0.5235782968534739,
          -0.6135683477871475,
          -0.644597347921074,
          -0.4144254003737963,
          -0.6228894161904578,
          -0.45505465166328224,
          -0.16760323253777754,
          -0.21663649483938294,
          -0.34627493500446316,
          -0.4482246992470378,
          -0.12609251230902144,
          -0.9997610748553825,
          -0.6785291195518186,
          -0.04506360329289912
         ]
        },
        {
         "name": "Hellinger Distance (I)",
         "type": "box",
         "y": [
          -0.819275851975691,
          -0.7556737084195664,
          -0.7708186811021968,
          -0.6477368732774152,
          -0.8024248315636371,
          -0.5027626830558364,
          -0.9319320697440344,
          -0.6747227668113155,
          -0.9156227963993826,
          -0.8744543571399408,
          -0.7756162005175992,
          -0.729176321598804,
          -0.8531726379937116,
          -0.896833461048736,
          -0.46355405148010087,
          -0.9999918375934651
         ]
        },
        {
         "name": "Wasserstein Distance (I)",
         "type": "box",
         "y": [
          -0.7221511725928396,
          -0.5609230400525919,
          -0.6064159515105518,
          -0.1841509046141856,
          -0.8272286510075479,
          -0.6773420811144789,
          -0.8452034574299482,
          -0.7385346493763615,
          -0.833663226360627,
          -0.7374363469366002,
          -0.6900517894893616,
          -0.5798772109351871,
          -0.7715974683214815,
          -0.7346575842661048,
          -0.28919578448982536,
          -0.9999903662769516,
          -0.6721713722638384,
          -0.04306339458108322
         ]
        },
        {
         "name": "MMD - Gaussian Kernel (I)",
         "type": "box",
         "y": [
          -0.7763531209426201,
          -0.6917121451791555,
          -0.36695838157081423,
          -0.6607222472174431,
          -0.7253470065178035,
          -0.6800477631614493,
          -0.6946606792778677,
          -0.7499967795278661,
          -0.6974531314763418,
          -0.6830182038203291,
          -0.6474305906850649,
          -0.5844058566235307,
          -0.7385050795327852,
          -0.7310177198992036,
          -0.4195623551502995,
          -0.9999035537270232,
          -0.6747193193091693,
          -0.004371285589789116
         ]
        },
        {
         "name": "Volume of data (D)",
         "type": "box",
         "y": [
          0.9984796720484961,
          0.9645196781601566,
          0.9372674124536785,
          0.9771163644968677,
          0.8399114606802965,
          0.8606283290594224,
          0.8309675289686376,
          0.8793165258124618,
          0.8159862672961831,
          0.7219482781666132,
          0.7505509405905877,
          0.4668553020901338,
          0.9098091182853213,
          0.8490511868917285,
          0.39588061075791486,
          0.9994610393041108,
          0.6881411157371031,
          -0.418775124922553
         ]
        }
       ],
       "layout": {
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Pearson Correlation between Distance and Value only Mavericks"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "distance_dictionary = {\n",
    "    \"performanceDegradation\": \"Performance Degradation (I)\",\n",
    "    \"yShiftDataframe\": \"X->Y Shift (I)\",\n",
    "    \"relevance\": \"Relevance (D)\",\n",
    "    \"diversity\": \"Diversity (D)\",\n",
    "    \"hellinger\": \"Hellinger Distance (I)\",\n",
    "    \"wasserstein\": \"Wasserstein Distance (I)\",\n",
    "    \"gaussian_mmd\": \"MMD - Gaussian Kernel (I)\",\n",
    "    \"volume\": \"Volume of data (D)\"\n",
    "}\n",
    "\n",
    "fig = go.Figure()\n",
    "for metric, name_of_metric in distance_dictionary.items():\n",
    "    sliced_df = correlation_sv_distance_only_mavericks[correlation_sv_distance_only_mavericks[\"Distance\"] == metric]\n",
    "    fig.add_trace(go.Box(y=sliced_df[\"PearsonCorrelation\"], name=name_of_metric))\n",
    "\n",
    "\n",
    "fig.update_layout(title_text=\"Pearson Correlation between Distance and Value only Mavericks\", showlegend=False)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(\"images/distance_value_only_mavericks_pearson_correlation.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation_sv_distance[correlation_sv_distance[\"Dataset\"] == \"electric-consumption\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation_sv_distance.groupby([\"Dataset\", \"Distance\"]).mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation_sv_distance.groupby([\"TypePartition\", \"Distance\"]).mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation_sv_distance.groupby([\"Dataset\", \"VarianceSV\"]).mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(correlation_sv_distance.groupby([\"Dataset\", \"TypePartition\", \"Distance\"]).mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_skew = spearman_rank_sv_distance[spearman_rank_sv_distance[\"Evaluator\"] == \"Centralized\"]\n",
    "\n",
    "# display(feature_skew)\n",
    "# display(feature_skew[feature_skew[\"Evaluator\"] == \"Centralized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(spearman_rank_sv_distance.groupby([\"Dataset\"]).mean(numeric_only=True))\n",
    "# display(spearman_rank_sv_distance.groupby([\"Dataset\", \"Distance\", \"Evaluator\"]).mean(numeric_only=True))\n",
    "# display(spearman_rank_sv_distance.groupby([\"Dataset\", \"AdditionalParameter\", \"Distance\", \"Evaluator\"]).mean(numeric_only=True))\n",
    "# display(spearman_rank_sv_distance.groupby([\"Dataset\", \"TypePartition\"]).mean(numeric_only=True))\n",
    "# display(spearman_rank_sv_distance.groupby([\"Metric\"]).mean(numeric_only=True))\n",
    "# display(spearman_rank_sv_distance.groupby([\"Distance\"]).mean(numeric_only=True))\n",
    "# display(spearman_rank_sv_distance.groupby([\"Dataset\", \"Distance\"]).mean(numeric_only=True))\n",
    "# display(spearman_rank_sv_distance.groupby(\"Dataset\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_configurations_mavericks = [\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Doctorate\", \"Maverick_Education_Doctorate\", 5, 4),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Masters\", \"Maverick_Education_Masters\", 5, 4),\n",
    "    # (\"adult\", \"manual\", \"Adult_FeatureSkew_Occupation_ExecManagerial\", \"Maverick_Occupation\", 5, 4),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_label_skew\", \"WalkingUpstairsNoBalance\", 6, 5),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Laying\", \"LayingNoBalance\", 6, 0),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_LessLabels\", \"OneClient4Classes\", 6, 5),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_MissingTwoLabels\", \"OneClient3Classes\", 6, 5),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_HellingerTrap\", \"HellingerTrap\", 6, 5),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_1\", \"Laying\", 6, 0),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_2\", \"Laying\", 6, 0),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_3\", \"Laying\", 6, 0),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_4\", \"Laying\", 6, 0),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_5\", \"Laying\", 6, 0),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs\", \"WalkingUpstairs\", 6, 5),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_2\", \"WalkingUpstairs\", 6, 5),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_3\", \"WalkingUpstairs\", 6, 5),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_4\", \"WalkingUpstairs\", 6, 5),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_5\", \"WalkingUpstairs\", 6, 5),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_Maverick_LeastNumerousClass\", \"LeastNumerous\", 4, 3),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_Maverick_MostNumerousClass\", \"MostNumerous\", 4, 3),\n",
    "    (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_LeastAttack\", \"LeastAttack\", 4, 3),\n",
    "    (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_OnlyNormal\", \"OnlyNormal\", 4, 3),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickMultifamilyUncategorized\", \"MultiFamily\", 5, 4),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickGroceryStore\", \"GroceryStore\", 5, 4)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_Mavericks(dataset_name, type_of_partition, additional_parameter, group_partitions, num_clients, maverick):\n",
    "    # distances = [\"wasserstein.csv\", \"gaussian_mmd.csv\", \"negativeConditionalEntropy.csv\", \"hellinger.csv\", \"performanceDegradation.csv\", \"yShiftDataframe.csv\", \"relevance.csv\", \"diversity.csv\"]\n",
    "    # singleValue = [\"volume.csv\"]\n",
    "    maverick_ranked = pd.DataFrame()\n",
    "\n",
    "    path_to_result_dataframes = get_results_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "\n",
    "    # spearman_rank_distance_sv = pd.DataFrame(columns=[\"Dataset\", \"TypePartition\", \"AdditionalParameter\", \"Metric\", \"Evaluator\", \"Distance\", \"SpearmanRank\", \"p-value\"])\n",
    "    ranked_sv_maverick = []\n",
    "    clients_sv = {k: [] for k in range(num_clients)}\n",
    "    sv_metric = []\n",
    "    sv_metric_c_a = []\n",
    "    # spearman_sv_distance_spearman_values = []\n",
    "    # spearman_sv_distance_p_values = []\n",
    "\n",
    "    for sv_file in os.listdir(path_to_result_dataframes + os.sep + \"Shapley_Value\"):\n",
    "        results_dataframe = pd.read_csv(path_to_result_dataframes + os.sep + \"Shapley_Value\" + os.sep + sv_file)\n",
    "        sv_metric_name = sv_file.split(\"_\")[1]\n",
    "\n",
    "        if sv_file == \"SV_F1Score\":\n",
    "            # For now, this one will not be used\n",
    "            grouped_sv = results_dataframe.groupby([\"Evaluator\", \"Classes\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Classes\", \"Round\"], axis=1)\n",
    "\n",
    "        elif sv_file == \"SV_CosineSimilarity\":\n",
    "            grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)\n",
    "            sv_metric.append(sv_metric_name)\n",
    "            sv_metric_c_a.append(\"C\")\n",
    "            for client in clients_sv.keys():\n",
    "                clients_sv[client].append(-1 * grouped_sv.loc[\"Centralized\", str(client)])\n",
    "        else:\n",
    "            grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)\n",
    "            sv_metric.append(sv_metric_name)\n",
    "            sv_metric.append(sv_metric_name)\n",
    "            sv_metric_c_a.append(\"C\")\n",
    "            sv_metric_c_a.append(\"A\")\n",
    "            for client in clients_sv.keys():\n",
    "                # The values are multiplied for -1 to prepare the data for a posterior sort.\n",
    "                clients_sv[client].append(-1 * grouped_sv.loc[\"Centralized\", str(client)])\n",
    "                clients_sv[client].append(-1 * grouped_sv.loc[\"Aggregated\", str(client)])\n",
    "\n",
    "    maverick_ranked[\"Dataset\"] = [dataset_name for _ in range(len(sv_metric))]\n",
    "    maverick_ranked[\"GroupPartitions\"] = [group_partitions for _ in range(len(sv_metric))]\n",
    "    maverick_ranked[\"Metric\"] = sv_metric\n",
    "    maverick_ranked[\"C/A\"] = sv_metric_c_a\n",
    "\n",
    "    for client in clients_sv.keys():\n",
    "        maverick_ranked[client] = clients_sv[client]\n",
    "\n",
    "    for index, row in maverick_ranked.iterrows():\n",
    "        sorted_clients = np.argsort(maverick_ranked.loc[index, [k for k in range(num_clients)]])\n",
    "        for client, position in zip(sorted_clients, range(1, 7)):\n",
    "            maverick_ranked.loc[index, client] = position\n",
    "\n",
    "    return maverick_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maverick_ranked = pd.DataFrame()\n",
    "\n",
    "for dataset_name, type_of_partition, additional_parameter, group_partitions, num_clients, maverick in training_configurations_mavericks:\n",
    "    maverick_ranked = pd.concat([maverick_ranked, ranking_Mavericks(dataset_name, type_of_partition, additional_parameter, group_partitions, num_clients, maverick)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(maverick_ranked[maverick_ranked[\"GroupPartitions\"] == \"GroceryStore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(maverick_ranked[maverick_ranked[\"Dataset\"] == \"edge-iot-coreset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(maverick_ranked[(maverick_ranked[\"Dataset\"] == \"electric-consumption\") & (maverick_ranked[\"C/A\"] == \"C\")].groupby([\"Dataset\", \"GroupPartitions\", \"Metric\"]).mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_configurations_mavericks = [\n",
    "    (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Doctorate\", \"Maverick_Education_Doctorate\", 5, 4, \"CrossEntropyLoss\"),\n",
    "    (\"adult\", \"manual\", \"Adult_FeatureSkew_Education_Masters\", \"Maverick_Education_Masters\", 5, 4, \"CrossEntropyLoss\"),\n",
    "    (\"adult\", \"manual\", \"Adult_FeatureSkew_Occupation_ExecManagerial\", \"Maverick_Occupation\", 5, 4, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_label_skew\", \"WalkingUpstairsNoBalance\", 6, 5, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Laying\", \"LayingNoBalance\", 6, 0, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_LessLabels\", \"OneClient4Classes\", 6, 5, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_MissingTwoLabels\", \"OneClient3Classes\", 6, 5, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_HellingerTrap\", \"HellingerTrap\", 6, 5, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_1\", \"Laying_1\", 6, 0, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_2\", \"Laying_2\", 6, 0, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_3\", \"Laying_3\", 6, 0, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_4\", \"Laying_4\", 6, 0, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_Balanced_Laying_5\", \"Laying_5\", 6, 0, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs\", \"WalkingUpstairs_1\", 6, 5, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_2\", \"WalkingUpstairs_2\", 6, 5, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_3\", \"WalkingUpstairs_3\", 6, 5, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_4\", \"WalkingUpstairs_4\", 6, 5, \"CrossEntropyLoss\"),\n",
    "    (\"har\", \"manual\", \"HAR_1_Maverick_1_Balanced_WalkingUpstairs_5\", \"WalkingUpstairs_5\", 6, 5, \"CrossEntropyLoss\"),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_Maverick_LeastNumerousClass\", \"LeastNumerous\", 4, 3),\n",
    "    # (\"covertype\", \"manual\", \"Covertype_Maverick_MostNumerousClass\", \"MostNumerous\", 4, 3),\n",
    "    (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_LeastAttack\", \"LeastAttack\", 4, 3, \"CrossEntropyLoss\"),\n",
    "    (\"edge-iot-coreset\", \"manual\", \"EdgeIIOT_Maverick_OnlyNormal\", \"OnlyNormal\", 4, 3, \"CrossEntropyLoss\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickMultifamilyUncategorized\", \"MultiFamily\", 5, 4, \"MAE\"),\n",
    "    (\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickGroceryStore\", \"GroceryStore\", 5, 4, \"MAE\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maverick_vs_distance(dataset_name, type_of_partition, additional_parameter, group_partitions, num_clients, maverick):\n",
    "    value_distance_dataframe = pd.DataFrame()\n",
    "\n",
    "    path_to_result_dataframes = get_results_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "    path_to_distance_dataframes = get_distances_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "\n",
    "    sv_value_centralized = []\n",
    "    clients_sv = {k: [] for k in range(num_clients)}\n",
    "    sv_metric = []\n",
    "\n",
    "    for sv_file in os.listdir(path_to_result_dataframes + os.sep + \"Shapley_Value\"):\n",
    "        results_dataframe = pd.read_csv(path_to_result_dataframes + os.sep + \"Shapley_Value\" + os.sep + sv_file)\n",
    "        sv_metric_name = sv_file.split(\"_\")[1]\n",
    "        if sv_file == \"SV_CosineSimilarity\":\n",
    "            grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)\n",
    "            sv_metric.append(sv_metric_name)\n",
    "            # sv_value_centralized.append(grouped_sv.loc[\"Centralized\"])\n",
    "            for client in clients_sv.keys():\n",
    "                clients_sv[client].append(grouped_sv.loc[\"Centralized\", str(client)])\n",
    "        elif sv_file == \"SV_CrossEntropyLoss\":\n",
    "            grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)\n",
    "            sv_metric.append(sv_metric_name)\n",
    "            for client in clients_sv.keys():\n",
    "                clients_sv[client].append(grouped_sv.loc[\"Centralized\", str(client)])\n",
    "        elif sv_file == \"SV_RMSE\":\n",
    "            grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)\n",
    "            sv_metric.append(sv_metric_name)\n",
    "            for client in clients_sv.keys():\n",
    "                clients_sv[client].append(grouped_sv.loc[\"Centralized\", str(client)])\n",
    "    \n",
    "    for distance_file in os.listdir(path_to_distance_dataframes):\n",
    "        distance_dataframe = pd.read_csv(path_to_distance_dataframes + os.sep + distance_file, index_col=0)\n",
    "        distance_metric_name = distance_file.split(\".\")[0]\n",
    "        sv_metric.append(distance_metric_name)\n",
    "        \n",
    "        if distance_file == \"volume.csv\":\n",
    "            for client in clients_sv.keys():\n",
    "                clients_sv[client].append(distance_dataframe.loc[str(client)].iloc[0])\n",
    "        \n",
    "        else:\n",
    "            for client in clients_sv.keys():\n",
    "                clients_sv[client].append(distance_dataframe.T.loc[\"Global\", client])\n",
    "\n",
    "    value_distance_dataframe[\"Dataset\"] = [dataset_name for _ in range(len(sv_metric))]\n",
    "    value_distance_dataframe[\"GroupPartitions\"] = [group_partitions for _ in range(len(sv_metric))]\n",
    "    value_distance_dataframe[\"Metric\"] = sv_metric\n",
    "    value_distance_dataframe[\"Maverick\"] = maverick\n",
    "    for client in clients_sv.keys():\n",
    "        value_distance_dataframe[str(client)] = clients_sv[client]\n",
    "\n",
    "    return value_distance_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_distance_maverick(dataset_name, type_of_partition, additional_parameter, group_partitions, num_clients, maverick, type_of_loss):\n",
    "    value_distance_dataframe = pd.DataFrame()\n",
    "\n",
    "    path_to_result_dataframes = get_results_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "\n",
    "    if type_of_loss == \"MAE\":\n",
    "        results_dataframe = pd.read_csv(path_to_result_dataframes + os.sep + \"Shapley_Value\" + os.sep + \"SV_MAE\")\n",
    "    else:\n",
    "        results_dataframe = pd.read_csv(path_to_result_dataframes + os.sep + \"Shapley_Value\" + os.sep + \"SV_CrossEntropyLoss\")\n",
    "\n",
    "    grouped_sv = results_dataframe.groupby([\"Evaluator\"]).sum().reindex(sorted(results_dataframe.columns), axis=1).drop([\"Evaluator\", \"Round\"], axis=1)\n",
    "\n",
    "    only_centralized_results = grouped_sv.loc[\"Centralized\"]\n",
    "    best_valued_index = int(only_centralized_results[only_centralized_results == max(only_centralized_results)].index[0])\n",
    "\n",
    "    path_to_distance_dataframes = get_distances_from_route(dataset_name, type_of_partition, additional_parameter)\n",
    "\n",
    "    distance_dictionary = {\n",
    "        \"performanceDegradation\": \"I\",\n",
    "        \"yShiftDataframe\": \"I\",\n",
    "        \"relevance\": \"D\",\n",
    "        \"diversity\": \"D\",\n",
    "        \"hellinger\": \"I\",\n",
    "        \"wasserstein\": \"I\",\n",
    "        \"gaussian_mmd\": \"I\",\n",
    "        \"negativeConditionalEntropy\": \"D\"\n",
    "        # \"volume\": \"D\"\n",
    "    }\n",
    "\n",
    "    distance = []\n",
    "    distance_theoretical_correct_rank = []\n",
    "    distance_sv_correct_rank = []\n",
    "    sv_correct_rank = []\n",
    "\n",
    "    # if best_valued_index == maverick:\n",
    "    #     sv_correct_rank.append(1)\n",
    "    # else:\n",
    "    #     sv_correct_rank.append(0)\n",
    "    \n",
    "    for distance_file in os.listdir(path_to_distance_dataframes):\n",
    "        distance_dataframe = pd.read_csv(path_to_distance_dataframes + os.sep + distance_file, index_col=0)\n",
    "        distance_metric_name = distance_file.split(\".\")[0]\n",
    "        distance.append(distance_metric_name)\n",
    "        \n",
    "        if distance_file == \"volume.csv\":\n",
    "            volumes = distance_dataframe.iloc[:, 0]\n",
    "            volumes.pop(\"Global\")\n",
    "            volumes.reset_index(inplace=True, drop=True)\n",
    "            if volumes[volumes == max(volumes)].index[0] == maverick:\n",
    "                distance_theoretical_correct_rank.append(1)\n",
    "            else:\n",
    "                distance_theoretical_correct_rank.append(0)\n",
    "            \n",
    "            if volumes[volumes == max(volumes)].index[0] == best_valued_index:\n",
    "                distance_sv_correct_rank.append(1)\n",
    "            else:\n",
    "                distance_sv_correct_rank.append(0)\n",
    "        \n",
    "        else:\n",
    "            distance_values = distance_dataframe.loc[:, \"Global\"]\n",
    "            if distance_dictionary[distance_metric_name] == \"D\":\n",
    "                best_distance_index = int(distance_values[distance_values == max(distance_values)].index[0])\n",
    "                if best_distance_index == maverick:\n",
    "                    distance_theoretical_correct_rank.append(1)\n",
    "                else:\n",
    "                    distance_theoretical_correct_rank.append(0)\n",
    "\n",
    "                if best_distance_index == best_valued_index:\n",
    "                    distance_sv_correct_rank.append(1)\n",
    "                else:\n",
    "                    distance_sv_correct_rank.append(0)\n",
    "            \n",
    "            else:\n",
    "                best_distance_index = int(distance_values[distance_values == min(distance_values)].index[0])\n",
    "                if best_distance_index == maverick:\n",
    "                    distance_theoretical_correct_rank.append(1)\n",
    "                else:\n",
    "                    distance_theoretical_correct_rank.append(0)\n",
    "                \n",
    "                if best_distance_index == best_valued_index:\n",
    "                    distance_sv_correct_rank.append(1)\n",
    "                else:\n",
    "                    distance_sv_correct_rank.append(0)\n",
    "\n",
    "    value_distance_dataframe[\"Dataset\"] = [dataset_name for _ in range(len(distance))]\n",
    "    value_distance_dataframe[\"GroupPartitions\"] = [group_partitions for _ in range(len(distance))]\n",
    "    value_distance_dataframe[\"Distance\"] = distance\n",
    "    value_distance_dataframe[\"Maverick\"] = maverick\n",
    "    value_distance_dataframe[\"Correct_Theoretical\"] = distance_theoretical_correct_rank\n",
    "    value_distance_dataframe[\"Correct_SV\"] = distance_sv_correct_rank\n",
    "\n",
    "    return value_distance_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_rank = pd.DataFrame()\n",
    "\n",
    "for dataset_name, type_of_partition, additional_parameter, group_partitions, num_clients, maverick, type_of_loss in training_configurations_mavericks:\n",
    "    distance_and_rank = pd.concat([distance_and_rank, ranking_distance_maverick(dataset_name, type_of_partition, additional_parameter, group_partitions, num_clients, maverick, type_of_loss)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(distance_and_rank[distance_and_rank[\"Distance\"] == \"gaussian_mmd\"])\n",
    "display(distance_and_rank[distance_and_rank[\"Distance\"] == \"wasserstein\"])\n",
    "display(distance_and_rank[distance_and_rank[\"Distance\"] == \"hellinger\"])\n",
    "display(distance_and_rank[distance_and_rank[\"Distance\"] == \"volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(distance_and_rank.groupby([\"Distance\"]).sum())\n",
    "display(distance_and_rank.groupby([\"Distance\"]).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_loss = \"MAE\"\n",
    "# type_of_loss = \"CrossEntropyLoss\"\n",
    "\n",
    "path_to_results_dataframes = get_results_from_route(\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickGroceryStore\")\n",
    "\n",
    "if type_of_loss == \"MAE\":\n",
    "    results_dataframe = pd.read_csv(path_to_results_dataframes + os.sep + \"Shapley_Value\" + os.sep + \"SV_MAE\")\n",
    "else:\n",
    "    results_dataframe = pd.read_csv(path_to_results_dataframes + os.sep + \"Shapley_Value\" + os.sep + \"SV_CrossEntropyLoss\")\n",
    "\n",
    "display(results_dataframe.groupby(\"Evaluator\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "path_to_dataframes = get_data_from_route(\"electric-consumption\", \"manual\", \"ElectricConsumption_FeatureSkew_MaverickGroceryStore\")\n",
    "\n",
    "for source_client in range(5):\n",
    "    src_train_x = pd.read_csv(path_to_dataframes + os.sep + \"client_\" + str(source_client) + \"_X_training.csv\", index_col=0)\n",
    "    src_train_y = pd.read_csv(path_to_dataframes + os.sep + \"client_\" + str(source_client) + \"_y_training.csv\", index_col=0)\n",
    "    src_test_x = pd.read_csv(path_to_dataframes + os.sep + \"client_\" + str(source_client) + \"_X_test.csv\", index_col=0)\n",
    "    src_test_y = pd.read_csv(path_to_dataframes + os.sep + \"client_\" + str(source_client) + \"_y_test.csv\", index_col=0)\n",
    "\n",
    "    column_names_of_interest:list = [column for column in src_train_x.columns if \"facility_type\" in column]\n",
    "\n",
    "    sliced_df_train = src_train_x.loc[:, column_names_of_interest]\n",
    "    extract_categories = np.argmax(sliced_df_train, axis=1).astype(int)\n",
    "    facilities = [column_names_of_interest[ind] for ind in extract_categories]\n",
    "\n",
    "    fig = px.histogram(facilities, title=f\"Train y client {source_client}\")\n",
    "    fig.show()\n",
    "\n",
    "    sliced_df_test = src_test_x.loc[:, column_names_of_interest]\n",
    "    extract_categories = np.argmax(sliced_df_test, axis=1).astype(int)\n",
    "    facilities = [column_names_of_interest[ind] for ind in extract_categories]\n",
    "\n",
    "    fig = px.histogram(facilities, title=f\"Test y client {source_client}\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_dataframe = value_distance.loc[:, \"0\":\"5\"]\n",
    "sliced_dataframe = sliced_dataframe.apply(lambda row: (row - row.mean()) / row.std(), axis=1)\n",
    "display(sliced_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_distance.loc[:, \"0\":\"5\"] = value_distance.loc[:, \"0\":\"5\"].apply(lambda row: (row - row.mean()) / row.std(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create random data with numpy\n",
    "import numpy as np\n",
    "\n",
    "partitions = np.unique(value_distance[\"GroupPartitions\"])\n",
    "\n",
    "for partition in partitions:\n",
    "    fig = go.Figure()\n",
    "    sliced_dataframe = value_distance[value_distance[\"GroupPartitions\"] == partition]\n",
    "    metrics = np.unique(sliced_dataframe[\"Metric\"])\n",
    "    for metric in metrics:\n",
    "        metric_row = sliced_dataframe[sliced_dataframe[\"Metric\"] == metric]\n",
    "        fig.add_trace(go.Scatter(y=metric_row.loc[:, \"0\":\"5\"].columns, x=metric_row.loc[:, \"0\":\"5\"].values[0], name=metric, mode=\"markers\"))\n",
    "    \n",
    "    fig.update_layout(title=\"Values for metric \" + partition)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create random data with numpy\n",
    "import numpy as np\n",
    "\n",
    "# path_to_results = distance_values_results + os.sep + \"wine\" + os.sep + \"manual\" + os.sep + \"Wine_Maverick\"\n",
    "path_to_results = \"..\" + os.sep + \"..\" + os.sep + distance_values_results + os.sep + \"adult\" + os.sep + \"manual\" + os.sep + \"Adult_FeatureSkew_Occupation\"\n",
    "\n",
    "# Wasserstein distance\n",
    "wasserstein = pd.read_csv(path_to_results + os.sep + \"wasserstein.csv\", index_col=0)\n",
    "fig = go.Figure(data=[go.Bar(name=\"0\", x=['0', '1', '2'], y=wasserstein.loc[:, \"0\"]),\n",
    "                      go.Bar(name=\"1\" , x=['0', '1', '2'], y=wasserstein.loc[:, \"1\"]),\n",
    "                      go.Bar(name=\"2\" , x=['0', '1', '2'], y=wasserstein.loc[:, \"2\"]),\n",
    "                      go.Bar(name=\"Global\" , x=['0', '1', '2'], y=wasserstein.loc[:, \"Global\"])\n",
    "                      ])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(text='Wasserstein Distance among datasets'))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Conditional Entropy\n",
    "conditionalEntropy = pd.read_csv(path_to_results + os.sep + \"conditionalEntropy.csv\", index_col=0)\n",
    "fig = go.Figure(data=[go.Bar(name=\"0\", x=['0', '1', '2'], y=conditionalEntropy.loc[:, \"0\"]),\n",
    "                      go.Bar(name=\"1\" , x=['0', '1', '2'], y=conditionalEntropy.loc[:, \"1\"]),\n",
    "                      go.Bar(name=\"2\" , x=['0', '1', '2'], y=conditionalEntropy.loc[:, \"2\"]),\n",
    "                      go.Bar(name=\"Global\" , x=['0', '1', '2'], y=conditionalEntropy.loc[:, \"Global\"])\n",
    "                      ])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(text='Conditional Entropy among datasets'))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Volume\n",
    "volume = pd.read_csv(path_to_results + os.sep + \"volume.csv\", index_col=0)\n",
    "fig = go.Figure(data=go.Bar(x=[\"Global\", \"0\", \"1\", \"2\"], y=volume.loc[[\"Global\", \"0\", \"1\", \"2\"], \"0\"]))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(text='Volume of the datasets'))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley values visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"electric-consumption\"\n",
    "type_of_partition = \"manual\"\n",
    "additional_parameter = \"ElectricConsumption_FeatureSkew_MaverickMultifamilyUncategorized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hellinger = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/hellinger.csv\", index_col=0)\n",
    "\n",
    "# print(\"Hellinger\")\n",
    "# display(hellinger)\n",
    "\n",
    "# # wasserstein = pd.read_csv(\"../../results/distances_values/adult/manual/Adult_FeatureSkew_Occupation/wasserstein.csv\", index_col=0)\n",
    "\n",
    "# # display(wasserstein)\n",
    "\n",
    "# negativeConditionalEntropy = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/negativeConditionalEntropy.csv\", index_col=0)\n",
    "\n",
    "# print(\"Negative Conditional Entropy\")\n",
    "# display(negativeConditionalEntropy)\n",
    "\n",
    "# yShiftDataframe = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/yShiftDataframe.csv\", index_col=0)\n",
    "\n",
    "# print(\"YShift\")\n",
    "# display(yShiftDataframe)\n",
    "\n",
    "# performanceDegradation = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/performanceDegradation.csv\", index_col=0)\n",
    "\n",
    "# print(\"Performance Degradation\")\n",
    "# display(performanceDegradation)\n",
    "\n",
    "# relevance = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/relevance.csv\", index_col=0)\n",
    "\n",
    "# print(\"Relevance\")\n",
    "# display(relevance)\n",
    "\n",
    "# diversity = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/diversity.csv\", index_col=0)\n",
    "\n",
    "# print(\"Diversity\")\n",
    "# display(diversity)\n",
    "\n",
    "# volume = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/volume.csv\", index_col=0)\n",
    "\n",
    "# print(\"Volume\")\n",
    "# display(volume)\n",
    "\n",
    "# # sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/adult/manual/Adult_FeatureSkew_Occupation/mlp/Shapley_Value/SV_CrossEntropyLoss\", index_col=0)\n",
    "\n",
    "# # display(sv_results.groupby([\"Evaluator\"]).sum())\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/new_adult/manual/Demographic_New_Adult/mlp/Shapley_Value/SV_Accuracy\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\"]).sum())\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/new_adult/manual/Demographic_New_Adult/mlp/Shapley_Value/SV_F1Score\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\", \"Classes\"]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hellinger = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/hellinger.csv\", index_col=0)\n",
    "\n",
    "print(\"Hellinger\")\n",
    "display(hellinger)\n",
    "\n",
    "wasserstein = pd.read_csv(\"../../results/distances_values/adult/manual/Adult_FeatureSkew_Occupation/wasserstein.csv\", index_col=0)\n",
    "\n",
    "display(wasserstein)\n",
    "\n",
    "negativeConditionalEntropy = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/negativeConditionalEntropy.csv\", index_col=0)\n",
    "\n",
    "print(\"Negative Conditional Entropy\")\n",
    "display(negativeConditionalEntropy)\n",
    "\n",
    "yShiftDataframe = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/yShiftDataframe.csv\", index_col=0)\n",
    "\n",
    "print(\"YShift\")\n",
    "display(yShiftDataframe)\n",
    "\n",
    "performanceDegradation = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/performanceDegradation.csv\", index_col=0)\n",
    "\n",
    "print(\"Performance Degradation\")\n",
    "display(performanceDegradation)\n",
    "\n",
    "relevance = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/relevance.csv\", index_col=0)\n",
    "\n",
    "print(\"Relevance\")\n",
    "display(relevance)\n",
    "\n",
    "diversity = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/diversity.csv\", index_col=0)\n",
    "\n",
    "print(\"Diversity\")\n",
    "display(diversity)\n",
    "\n",
    "volume = pd.read_csv(\"../../results/distances_values/new_adult/manual/Demographic_New_Adult/volume.csv\", index_col=0)\n",
    "\n",
    "print(\"Volume\")\n",
    "display(volume)\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/adult/manual/Adult_FeatureSkew_Occupation/mlp/Shapley_Value/SV_CrossEntropyLoss\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\"]).sum())\n",
    "\n",
    "sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/new_adult/manual/Demographic_New_Adult/mlp/Shapley_Value/SV_Accuracy\", index_col=0)\n",
    "\n",
    "display(sv_results.groupby([\"Evaluator\"]).sum())\n",
    "\n",
    "sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/new_adult/manual/Demographic_New_Adult/mlp/Shapley_Value/SV_F1Score\", index_col=0)\n",
    "\n",
    "display(sv_results.groupby([\"Evaluator\", \"Classes\"]).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/har/manual/HAR_1_Maverick_1_label_skew/mlp/Shapley_Value/SV_CrossEntropyLoss\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\"]).sum())\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/har/manual/HAR_1_Maverick_1_label_skew/mlp/Shapley_Value/SV_Accuracy\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\"]).sum())\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/har/manual/HAR_1_Maverick_1_label_skew/mlp/Shapley_Value/SV_F1Score\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\", \"Classes\"]).sum())\n",
    "\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/wine/manual/Wine_Maverick/mlp/Shapley_Value/SV_CrossEntropyLoss\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\"]).sum())\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/wine/manual/Wine_Maverick/mlp/Shapley_Value/SV_Accuracy\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\"]).sum())\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/wine/manual/Wine_Maverick/mlp/Shapley_Value/SV_F1Score\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\", \"Classes\"]).sum())\n",
    "\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/adult/manual/Adult_FeatureSkew_Occupation/mlp/Shapley_Value/SV_CrossEntropyLoss\", index_col=0)\n",
    "\n",
    "display((sv_results.groupby([\"Evaluator\"]).sum()).reindex(sorted(sv_results.columns), axis=1))\n",
    "\n",
    "sv_results = pd.read_csv(\"../../results/old_results/manual/Adult_FeatureSkew_Occupation/mlp/Shapley_Value/SV_CrossEntropyLoss\", index_col=0)\n",
    "\n",
    "display((sv_results.groupby([\"Evaluator\"]).sum()).reindex(sorted(sv_results.columns), axis=1))\n",
    "\n",
    "sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/adult/manual/Adult_FeatureSkew_Occupation/mlp/Shapley_Value/SV_Accuracy\", index_col=0)\n",
    "\n",
    "display((sv_results.groupby([\"Evaluator\"]).sum()).reindex(sorted(sv_results.columns), axis=1))\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/adult/manual/Adult_FeatureSkew_Occupation/mlp/Shapley_Value/SV_F1Score\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\", \"Classes\"]).sum())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sv_results = pd.read_csv(\"../../results/old_results/manual/Adult_FeatureSkew_Occupation/mlp/Shapley_Value/SV_Accuracy\", index_col=0)\n",
    "\n",
    "grouped_sv = sv_results.groupby([\"Evaluator\"]).sum().reindex(sorted(sv_results.columns), axis=1).drop([\"Evaluator\"], axis=1)\n",
    "\n",
    "display(grouped_sv)\n",
    "\n",
    "display(scipy.stats.spearmanr(grouped_sv.loc[\"Centralized\"], grouped_sv.loc[\"Aggregated\"]))\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/old_results/manual/Adult_FeatureSkew_Occupation/mlp/Shapley_Value/SV_F1Score\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\", \"Classes\"]).sum())\n",
    "\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/new_adult/manual/Demographic_New_Adult/mlp/Shapley_Value/SV_CrossEntropyLoss\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\"]).sum())\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/new_adult/manual/Demographic_New_Adult/mlp/Shapley_Value/SV_Accuracy\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\"]).sum())\n",
    "\n",
    "# sv_results = pd.read_csv(\"../../results/dataframes/FedAvg/new_adult/manual/Demographic_New_Adult/mlp/Shapley_Value/SV_F1Score\", index_col=0)\n",
    "\n",
    "# display(sv_results.groupby([\"Evaluator\", \"Classes\"]).sum())\n",
    "\n",
    "# fig = go.Figure(data=[go.Bar(name=\"0\", x=['0', '1', '2'], y=sv_results.loc[:, \"0\"]),\n",
    "#                       go.Bar(name=\"1\" , x=['0', '1', '2'], y=sv_results.loc[:, \"1\"]),\n",
    "#                       go.Bar(name=\"2\" , x=['0', '1', '2'], y=sv_results.loc[:, \"2\"]),\n",
    "#                       go.Bar(name=\"Global\" , x=['0', '1', '2'], y=sv_results.loc[:, \"Global\"])\n",
    "#                       ])\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=dict(text='Wasserstein Distance among datasets'))\n",
    "\n",
    "# fig.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H1 Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URI_partitioned_data = \"\\\\data\\\\partitioned_training_data\" + \\\n",
    "                        \"\\\\manually_partitioned\" + \\\n",
    "                        \"\\\\HAR_1_Maverick_1_MissingTwoLabels\"\n",
    "\n",
    "source_dataset_X = pd.read_csv(URI_partitioned_data + \"\\\\\" + \"client_\" + str(0) + \"_X\" + \".csv\", index_col=0).to_numpy()\n",
    "display(source_dataset_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_h1_score(source_dataset, target_labels):\n",
    "    dim_red = False\n",
    "    n_components = 8\n",
    "    not_normalized = False\n",
    "    if dim_red:\n",
    "        dataset = PCA()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HAR_1_Maverick_Less_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "for client_source_number in range(6):\n",
    "    for client_target_number in range(6):\n",
    "        source_dataset_X = pd.read_csv(URI_partitioned_data + \"\\\\\" + \"client_\" + str(client_source_number) + \"_X\" + \".csv\", index_col=0).to_numpy()\n",
    "        target_dataset_y = pd.read_csv(URI_partitioned_data + \"\\\\\" + \"client_\" + str(client_target_number) + \"_y\" + \".csv\", index_col=0).to_numpy()\n",
    "        dataframe.loc[\"Client \" + str(client_source_number), \"Client \" + str(client_target_number)] = get_h1_score(source_dataset_X, target_dataset_y)\n",
    "    \n",
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "for client_source_number in range(6):\n",
    "    for client_target_number in range(6):\n",
    "        source_dataset_X = pd.read_csv(URI_partitioned_data + \"\\\\\" + \"client_\" + str(client_source_number) + \"_X\" + \".csv\", index_col=0).to_numpy()\n",
    "        target_dataset_y = pd.read_csv(URI_partitioned_data + \"\\\\\" + \"client_\" + str(client_target_number) + \"_y\" + \".csv\", index_col=0).to_numpy()\n",
    "        dataframe.loc[\"Client \" + str(client_source_number), \"Client \" + str(client_target_number)] = get_h1_score(source_dataset_X, target_dataset_y)\n",
    "    \n",
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for client_source_number in range(6):\n",
    "    source_dataset_y = pd.read_csv(URI_partitioned_data + \"\\\\\" + \"client_\" + str(client_source_number) + \"_y\" + \".csv\", index_col=0).to_numpy()\n",
    "    source_dataset_y = np.array(np.argmax(np.asarray(source_dataset_y), axis=1))\n",
    "    if client_source_number == 0:\n",
    "        source_dataset_y[source_dataset_y==2] = 3\n",
    "    for client_target_number in range(6):\n",
    "        target_dataset_y = pd.read_csv(URI_partitioned_data + \"\\\\\" + \"client_\" + str(client_target_number) + \"_y\" + \".csv\", index_col=0).to_numpy()\n",
    "        target_dataset_y = np.array(np.argmax(np.asarray(target_dataset_y), axis=1))\n",
    "        h_score_value = negative_conditional_entropy(source_dataset_y, target_dataset_y)\n",
    "        h_score_value *= 1e18\n",
    "        dataframe.loc[\"Client \" + str(client_source_number), \"Client \" + str(client_target_number)] = h_score_value\n",
    "    \n",
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tllib.ranking.logme import log_maximum_evidence\n",
    "# pd.options.display.float_format = '{:,.2f}'.format\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "for client_source_number in range(1, 6):\n",
    "    for client_target_number in range(1, 6):\n",
    "        source_dataset_X = pd.read_csv(URI_partitioned_data + \"\\\\\" + \"client_\" + str(client_source_number) + \"_X\" + \".csv\", index_col=0).to_numpy()\n",
    "        print(len(source_dataset_X))\n",
    "        target_dataset_y = pd.read_csv(URI_partitioned_data + \"\\\\\" + \"client_\" + str(client_target_number) + \"_y\" + \".csv\", index_col=0).to_numpy()\n",
    "        print(len(target_dataset_y))\n",
    "        target_dataset_y = target_dataset_y[:, np.any(target_dataset_y > 0, axis=0)]\n",
    "        log_me = log_maximum_evidence(source_dataset_X, target_dataset_y, regression=True)\n",
    "        display(log_me)\n",
    "        dataframe.loc[\"Client \" + str(client_source_number), \"Client \" + str(client_target_number)] = log_me\n",
    "    \n",
    "display(dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower_py3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
