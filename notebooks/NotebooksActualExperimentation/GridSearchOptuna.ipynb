{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..' + os.sep + '..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 13:26:26.070016: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-07 13:26:26.097655: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-07 13:26:26.491489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_parameters.model_builder.ModelBuilder import Director, get_training_configuration\n",
    "from metrics.Metrics import DictOfMetrics\n",
    "from metrics.Evaluator import evaluator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "director = Director()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(trial, model_type):\n",
    "    parameters = get_training_configuration(trial=trial, model_type=model_type)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp(input_dim, num_classes, parameters):\n",
    "    return director.create_mlp(input_parameters=input_dim, num_classes=num_classes, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tabnet(input_dim, num_classes, parameters):\n",
    "    return director.create_tabnet(input_parameters=input_dim, num_classes=num_classes, parameters=parameters).get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgboost_tree(input_dim, num_classes, parameters):\n",
    "    return director.create_xgboost(input_parameters=input_dim, num_classes=num_classes, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [\"CrossEntropyLoss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP with Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from experiment_parameters.model_builder.Model import NeuralNetworkWine\n",
    "\n",
    "dataset_factory = dataset_model_dictionary[\"wine\"]()\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()\n",
    "#model = NeuralNetworkWine().get_model()\n",
    "\n",
    "# tf_history = model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), batch_size=1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine_mlp_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"CrossEntropyLoss\")\n",
    "    \n",
    "    # y_pred = ml_model.predict(X_test)\n",
    "    # mcc_metric = MatthewsCorrelationCoefficient(y_train.shape[1])\n",
    "    # mcc_metric.update_state(y_test, y_pred)\n",
    "    # mcc_result = mcc_metric.result().numpy().tolist()\n",
    "    \n",
    "    # return loss, accuracy # , mcc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"mlp_wine\", direction=['minimize'])\n",
    "study.optimize(wine_mlp_optimization, n_trials=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"xgboost\")\n",
    "    dmatrix = xgb.DMatrix(X_train, label=np.argmax(y_train, axis=1))\n",
    "    dmatrix_test = xgb.DMatrix(X_test, label=np.argmax(y_test, axis=1))\n",
    "    xgboost_hyperparameters = get_xgboost_tree(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    bst = xgb.train(xgboost_hyperparameters, dmatrix, evals=[(dmatrix_test, \"validate\"), (dmatrix, \"train\")], num_boost_round=500, verbose_eval=0) \n",
    "    eval_results = bst.eval(dmatrix_test)\n",
    "    # print(f\"Feature names: {bst.feature_names}\")\n",
    "    # print(f\"Feature types: {bst.feature_types}\")\n",
    "    # log(INFO, f\"Results: {eval_results}\")\n",
    "    loss = round(float(eval_results.split(\"\\t\")[1].split(\":\")[1]), 4)\n",
    "    \n",
    "    # y_pred = bst.predict(X_test)\n",
    "    # mcc_metric = MatthewsCorrelationCoefficient(y_train.shape[1])\n",
    "    # mcc_metric.update_state(y_test, y_pred)\n",
    "    # mcc_result = mcc_metric.result().numpy().tolist()\n",
    "    \n",
    "    return loss#, accuracy#, mcc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"xgboost_wine\", direction=['minimize'])\n",
    "study.optimize(wine_optimization, n_trials=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import load_study\n",
    "\n",
    "study = load_study(\"xgboost_wine\")\n",
    "trial_with_highest_accuracy = max(study.best_trials, key=lambda t: t.values[0])\n",
    "parameters_dict = get_training_configuration(trial_with_highest_accuracy, \"xgboost\")\n",
    "dmatrix = xgb.DMatrix(X_train, label=np.argmax(y_train, axis=1))\n",
    "dmatrix_test = xgb.DMatrix(X_test, label=np.argmax(y_test, axis=1))\n",
    "xgboost_hyperparameters = get_xgboost_tree(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters_dict)\n",
    "bst = xgb.train(xgboost_hyperparameters, dmatrix, evals=[(dmatrix_test, \"validate\"), (dmatrix, \"train\")], num_boost_round=500)\n",
    "\n",
    "xgb.plot_tree(bst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from experiment_parameters.model_builder.TFModel import NeuralNetworkWine\n",
    "\n",
    "dataset_factory = dataset_model_dictionary[\"wine\"]\n",
    "x_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "x_test, y_test = dataset_factory.get_dataset().get_test_data()\n",
    "model = NeuralNetworkWine().get_model()\n",
    "\n",
    "tf_history = model.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=1, epochs=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_factory = dataset_model_dictionary[\"har\"]()\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def har_xgboost_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"xgboost\")\n",
    "    dmatrix = xgb.DMatrix(X_train, label=np.argmax(y_train, axis=1))\n",
    "    dmatrix_test = xgb.DMatrix(X_test, label=np.argmax(y_test, axis=1))\n",
    "    xgboost_hyperparameters = get_xgboost_tree(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    bst = xgb.train(xgboost_hyperparameters, dmatrix, evals=[(dmatrix_test, \"validate\"), (dmatrix, \"train\")], num_boost_round=500) \n",
    "    eval_results = bst.eval(dmatrix_test)\n",
    "    loss = round(float(eval_results.split(\"\\t\")[1].split(\":\")[1]), 4)\n",
    "#     y_pred = ml_model.predict(X_test)\n",
    "#     mcc_metric = MatthewsCorrelationCoefficient(y_train.shape[1])\n",
    "#     mcc_metric.update_state(y_test, y_pred)\n",
    "#     mcc_result = mcc_metric.result().numpy().tolist()\n",
    "    \n",
    "    return loss #, accuracy, mcc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"tabnet_har\", direction=['minimize'])\n",
    "study.optimize(har_xgboost_optimization, n_trials=60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search MLP HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def har_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, epochs=20, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"mlp_har\", direction=['minimize'])\n",
    "study.optimize(har_optimization, n_trials=60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search XGBoost Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "\n",
    "dataset_factory = dataset_model_dictionary[\"adult\"]()\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adult_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"xgboost\")\n",
    "    dmatrix = xgb.DMatrix(X_train, label=np.argmax(y_train, axis=1))\n",
    "    dmatrix_test = xgb.DMatrix(X_test, label=np.argmax(y_test, axis=1))\n",
    "    xgboost_hyperparameters = get_xgboost_tree(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    bst = xgb.train(xgboost_hyperparameters, dmatrix, evals=[(dmatrix_test, \"validate\"), (dmatrix, \"train\")], num_boost_round=500) \n",
    "    eval_results = bst.eval(dmatrix_test)\n",
    "    loss = round(float(eval_results.split(\"\\t\")[1].split(\":\")[1]), 4)\n",
    "#     y_pred = ml_model.predict(X_test)\n",
    "#     mcc_metric = MatthewsCorrelationCoefficient(y_train.shape[1])\n",
    "#     mcc_metric.update_state(y_test, y_pred)\n",
    "#     mcc_result = mcc_metric.result().numpy().tolist()\n",
    "    \n",
    "    return loss #, accuracy, mcc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"xgboost_adult\", direction=['minimize'])\n",
    "study.optimize(adult_optimization, n_trials=60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search MLP Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adult_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, epochs=20, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"mlp_adult\", direction=['minimize'])\n",
    "study.optimize(adult_optimization, n_trials=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Adult XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CoverType XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search MLP Covertype\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "\n",
    "dataset_factory = dataset_model_dictionary[\"covertype\"]()\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covertype_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"xgboost\")\n",
    "    dmatrix = xgb.DMatrix(X_train, label=np.argmax(y_train, axis=1))\n",
    "    dmatrix_test = xgb.DMatrix(X_test, label=np.argmax(y_test, axis=1))\n",
    "    xgboost_hyperparameters = get_xgboost_tree(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    bst = xgb.train(xgboost_hyperparameters, dmatrix, evals=[(dmatrix_test, \"validate\"), (dmatrix, \"train\")], num_boost_round=500, early_stopping_rounds=10) \n",
    "    eval_results = bst.eval(dmatrix_test)\n",
    "    loss = round(float(eval_results.split(\"\\t\")[1].split(\":\")[1]), 4)\n",
    "    \n",
    "    return loss #, accuracy, mcc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"xgboost_covertype\", direction=['minimize'])\n",
    "study.optimize(covertype_optimization, n_trials=60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CoverType Dataset MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covertype_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, epochs=20, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"mlp_covertype\", direction=['minimize'])\n",
    "study.optimize(covertype_optimization, n_trials=60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Heart TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search MLP HAR\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "\n",
    "dataset_factory = dataset_model_dictionary[\"heart\"]\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heart_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"tabnet\")\n",
    "    ml_model = get_tabnet(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, epochs=20, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"tabnet_heart\", direction='minimize')\n",
    "study.optimize(heart_optimization, n_trials=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Heart MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heart_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, epochs=20, batch_size=parameters[\"batch_size\"]) \n",
    "    loss, accuracy = ml_model.evaluate(X_test, y_test)\n",
    "    \n",
    "    y_pred = ml_model.predict(X_test)\n",
    "    mcc_metric = MatthewsCorrelationCoefficient(y_train.shape[1])\n",
    "    mcc_metric.update_state(y_test, y_pred)\n",
    "    mcc_result = mcc_metric.result().numpy().tolist()\n",
    "    \n",
    "    return loss #, accuracy, mcc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(name=\"mlp_heart\", direction='minimize')\n",
    "study.optimize(heart_optimization, n_trials=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Binary Heart Tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search MLP HAR\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "\n",
    "dataset_factory = dataset_model_dictionary[\"binary_heart\"]\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_heart_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"tabnet\")\n",
    "    ml_model = get_tabnet(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, epochs=20, batch_size=parameters[\"batch_size\"]) \n",
    "    loss, accuracy = ml_model.evaluate(X_test, y_test)\n",
    "    \n",
    "    y_pred = ml_model.predict(X_test)\n",
    "    mcc_metric = MatthewsCorrelationCoefficient(y_train.shape[1])\n",
    "    mcc_metric.update_state(y_test, y_pred)\n",
    "    mcc_result = mcc_metric.result().numpy().tolist()\n",
    "    \n",
    "    return loss , accuracy#, mcc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"tabnet_binary_heart\", direction=['minimize', 'maximize'])\n",
    "study.optimize(binary_heart_optimization, n_trials=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Binary Heart MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_heart_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, epochs=20, batch_size=parameters[\"batch_size\"]) \n",
    "    loss, accuracy = ml_model.evaluate(X_test, y_test)\n",
    "    \n",
    "    y_pred = ml_model.predict(X_test)\n",
    "    mcc_metric = MatthewsCorrelationCoefficient(y_train.shape[1])\n",
    "    mcc_metric.update_state(y_test, y_pred)\n",
    "    mcc_result = mcc_metric.result().numpy().tolist()\n",
    "    \n",
    "    return loss, accuracy#, mcc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"mlp_binary_heart\", direction=['minimize', 'maximize'])\n",
    "study.optimize(binary_heart_optimization, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search MLP HAR\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "dataset_factory = dataset_model_dictionary[\"new_adult\"]()\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_adult_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"mlp_new_adult\", direction=['minimize'])\n",
    "study.optimize(new_adult_optimization, n_trials=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_adult_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"xgboost\")\n",
    "    dmatrix = xgb.DMatrix(X_train, label=np.argmax(y_train, axis=1))\n",
    "    dmatrix_test = xgb.DMatrix(X_test, label=np.argmax(y_test, axis=1))\n",
    "    xgboost_hyperparameters = get_xgboost_tree(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    bst = xgb.train(xgboost_hyperparameters, dmatrix, evals=[(dmatrix_test, \"validate\"), (dmatrix, \"train\")], num_boost_round=500, early_stopping_rounds=10) \n",
    "    eval_results = bst.eval(dmatrix_test)\n",
    "    loss = round(float(eval_results.split(\"\\t\")[1].split(\":\")[1]), 4)\n",
    "    \n",
    "    return loss #, accuracy, mcc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna_create_study(\"xgboost_new_adult\", direction=['minimize'])\n",
    "study.optimize(new_adult_optimization, n_trials=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge-IIOT-Coreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search MLP HAR\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "dataset_factory = dataset_model_dictionary[\"edge-iot-coreset\"]()\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_iiot_coreset_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, epochs=30, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-07 13:26:36,717] A new study created in RDB with name: mlp_edge_iiot_coreset\n",
      "2025-11-07 13:26:36.830067: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 13:26:36.857490: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-07 13:26:36.858936: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-07 13:26:36.861253: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-07 13:26:36.862620: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-07 13:26:36.863806: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-07 13:26:36.963423: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-07 13:26:36.964740: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-07 13:26:36.965891: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-07 13:26:36.967042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1084 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762518397.521620  452874 service.cc:145] XLA service 0x7674a40046c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762518397.521643  452874 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti SUPER, Compute Capability 8.9\n",
      "2025-11-07 13:26:37.534082: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-07 13:26:37.590042: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m295/589\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 512us/step - categorical_accuracy: 0.2326 - loss: 2.4840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518399.044981  452874 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - categorical_accuracy: 0.4023 - loss: 2.0270 - val_categorical_accuracy: 0.8343 - val_loss: 0.7764\n",
      "Epoch 2/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - categorical_accuracy: 0.8460 - loss: 0.7310 - val_categorical_accuracy: 0.8616 - val_loss: 0.6291\n",
      "Epoch 3/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - categorical_accuracy: 0.8632 - loss: 0.6185 - val_categorical_accuracy: 0.8642 - val_loss: 0.5809\n",
      "Epoch 4/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - categorical_accuracy: 0.8673 - loss: 0.5786 - val_categorical_accuracy: 0.8738 - val_loss: 0.5553\n",
      "Epoch 5/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - categorical_accuracy: 0.8733 - loss: 0.5563 - val_categorical_accuracy: 0.8754 - val_loss: 0.5402\n",
      "Epoch 6/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - categorical_accuracy: 0.8755 - loss: 0.5436 - val_categorical_accuracy: 0.8759 - val_loss: 0.5303\n",
      "Epoch 7/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - categorical_accuracy: 0.8767 - loss: 0.5321 - val_categorical_accuracy: 0.8763 - val_loss: 0.5228\n",
      "Epoch 8/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - categorical_accuracy: 0.8762 - loss: 0.5280 - val_categorical_accuracy: 0.8767 - val_loss: 0.5171\n",
      "Epoch 9/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - categorical_accuracy: 0.8785 - loss: 0.5175 - val_categorical_accuracy: 0.8771 - val_loss: 0.5123\n",
      "Epoch 10/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - categorical_accuracy: 0.8779 - loss: 0.5153 - val_categorical_accuracy: 0.8773 - val_loss: 0.5082\n",
      "Epoch 11/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - categorical_accuracy: 0.8789 - loss: 0.5107 - val_categorical_accuracy: 0.8776 - val_loss: 0.5047\n",
      "Epoch 12/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - categorical_accuracy: 0.8779 - loss: 0.5089 - val_categorical_accuracy: 0.8781 - val_loss: 0.5017\n",
      "Epoch 13/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - categorical_accuracy: 0.8782 - loss: 0.5062 - val_categorical_accuracy: 0.8784 - val_loss: 0.4991\n",
      "Epoch 14/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - categorical_accuracy: 0.8798 - loss: 0.4985 - val_categorical_accuracy: 0.8784 - val_loss: 0.4969\n",
      "Epoch 15/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - categorical_accuracy: 0.8790 - loss: 0.4998 - val_categorical_accuracy: 0.8788 - val_loss: 0.4947\n",
      "Epoch 16/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - categorical_accuracy: 0.8793 - loss: 0.4968 - val_categorical_accuracy: 0.8789 - val_loss: 0.4929\n",
      "Epoch 17/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - categorical_accuracy: 0.8802 - loss: 0.4933 - val_categorical_accuracy: 0.8791 - val_loss: 0.4911\n",
      "Epoch 18/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - categorical_accuracy: 0.8790 - loss: 0.4949 - val_categorical_accuracy: 0.8792 - val_loss: 0.4898\n",
      "Epoch 19/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - categorical_accuracy: 0.8797 - loss: 0.4924 - val_categorical_accuracy: 0.8792 - val_loss: 0.4883\n",
      "Epoch 20/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - categorical_accuracy: 0.8795 - loss: 0.4921 - val_categorical_accuracy: 0.8794 - val_loss: 0.4870\n",
      "Epoch 21/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - categorical_accuracy: 0.8796 - loss: 0.4911 - val_categorical_accuracy: 0.8795 - val_loss: 0.4858\n",
      "Epoch 22/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - categorical_accuracy: 0.8811 - loss: 0.4850 - val_categorical_accuracy: 0.8795 - val_loss: 0.4848\n",
      "Epoch 23/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - categorical_accuracy: 0.8802 - loss: 0.4874 - val_categorical_accuracy: 0.8796 - val_loss: 0.4838\n",
      "Epoch 24/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - categorical_accuracy: 0.8812 - loss: 0.4844 - val_categorical_accuracy: 0.8797 - val_loss: 0.4830\n",
      "Epoch 25/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - categorical_accuracy: 0.8812 - loss: 0.4826 - val_categorical_accuracy: 0.8798 - val_loss: 0.4821\n",
      "Epoch 26/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - categorical_accuracy: 0.8808 - loss: 0.4828 - val_categorical_accuracy: 0.8798 - val_loss: 0.4814\n",
      "Epoch 27/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - categorical_accuracy: 0.8795 - loss: 0.4864 - val_categorical_accuracy: 0.8798 - val_loss: 0.4807\n",
      "Epoch 28/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - categorical_accuracy: 0.8812 - loss: 0.4829 - val_categorical_accuracy: 0.8799 - val_loss: 0.4799\n",
      "Epoch 29/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - categorical_accuracy: 0.8797 - loss: 0.4843 - val_categorical_accuracy: 0.8799 - val_loss: 0.4796\n",
      "Epoch 30/30\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - categorical_accuracy: 0.8806 - loss: 0.4830 - val_categorical_accuracy: 0.8799 - val_loss: 0.4789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:26:59,661] Trial 0 finished with value: 0.4757000375413659 and parameters: {'activation_l1': 'relu', 'batch_size': 454, 'decay_rate': 0.8500000000000001, 'decay_steps': 2000, 'dropout_l1': 0.1, 'learning_rate_init': 0.0001952764276606329, 'n_units_l1': 120, 'num_layers': 1}. Best is trial 0 with value: 0.4757000375413659.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762518422.034325  454525 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1185', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518423.020094  454529 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_229', 668 bytes spill stores, 820 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518423.140891  454534 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_229', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518423.165861  454536 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_229', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - categorical_accuracy: 0.4939 - loss: 1.8630  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518429.049489  454755 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518429.174259  454759 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 416 bytes spill stores, 504 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518429.457536  454762 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 108 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518429.487539  454753 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 172 bytes spill stores, 172 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518429.628618  454759 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518431.240896  454829 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 604 bytes spill stores, 700 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518431.326669  454833 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518431.424560  454828 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518431.520701  454835 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518431.946847  454837 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 140 bytes spill stores, 140 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518432.406612  454829 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 100 bytes spill stores, 180 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518432.863650  454832 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 572 bytes spill stores, 556 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - categorical_accuracy: 0.4940 - loss: 1.8628 - val_categorical_accuracy: 0.8217 - val_loss: 0.9209\n",
      "Epoch 2/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 707us/step - categorical_accuracy: 0.8033 - loss: 0.9352 - val_categorical_accuracy: 0.8298 - val_loss: 0.7962\n",
      "Epoch 3/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 735us/step - categorical_accuracy: 0.8210 - loss: 0.8270 - val_categorical_accuracy: 0.8299 - val_loss: 0.7409\n",
      "Epoch 4/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676us/step - categorical_accuracy: 0.8285 - loss: 0.7795 - val_categorical_accuracy: 0.8370 - val_loss: 0.7166\n",
      "Epoch 5/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 713us/step - categorical_accuracy: 0.8309 - loss: 0.7632 - val_categorical_accuracy: 0.8410 - val_loss: 0.7048\n",
      "Epoch 6/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 699us/step - categorical_accuracy: 0.8336 - loss: 0.7492 - val_categorical_accuracy: 0.8419 - val_loss: 0.6976\n",
      "Epoch 7/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step - categorical_accuracy: 0.8353 - loss: 0.7442 - val_categorical_accuracy: 0.8422 - val_loss: 0.6942\n",
      "Epoch 8/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 657us/step - categorical_accuracy: 0.8372 - loss: 0.7359 - val_categorical_accuracy: 0.8422 - val_loss: 0.6921\n",
      "Epoch 9/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676us/step - categorical_accuracy: 0.8354 - loss: 0.7401 - val_categorical_accuracy: 0.8422 - val_loss: 0.6910\n",
      "Epoch 10/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 729us/step - categorical_accuracy: 0.8356 - loss: 0.7390 - val_categorical_accuracy: 0.8422 - val_loss: 0.6904\n",
      "Epoch 11/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 636us/step - categorical_accuracy: 0.8371 - loss: 0.7340 - val_categorical_accuracy: 0.8422 - val_loss: 0.6900\n",
      "Epoch 12/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 625us/step - categorical_accuracy: 0.8375 - loss: 0.7317 - val_categorical_accuracy: 0.8422 - val_loss: 0.6898\n",
      "Epoch 13/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 619us/step - categorical_accuracy: 0.8363 - loss: 0.7372 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 14/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 684us/step - categorical_accuracy: 0.8357 - loss: 0.7371 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 15/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 680us/step - categorical_accuracy: 0.8350 - loss: 0.7384 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 16/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - categorical_accuracy: 0.8390 - loss: 0.7292 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 17/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 632us/step - categorical_accuracy: 0.8368 - loss: 0.7347 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 18/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 633us/step - categorical_accuracy: 0.8367 - loss: 0.7362 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 19/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - categorical_accuracy: 0.8360 - loss: 0.7334 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 20/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 681us/step - categorical_accuracy: 0.8368 - loss: 0.7356 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 21/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 633us/step - categorical_accuracy: 0.8365 - loss: 0.7368 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 22/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 639us/step - categorical_accuracy: 0.8362 - loss: 0.7380 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 23/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 636us/step - categorical_accuracy: 0.8374 - loss: 0.7355 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 24/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - categorical_accuracy: 0.8366 - loss: 0.7354 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 25/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671us/step - categorical_accuracy: 0.8371 - loss: 0.7350 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 26/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - categorical_accuracy: 0.8367 - loss: 0.7369 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 27/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 639us/step - categorical_accuracy: 0.8377 - loss: 0.7344 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 28/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step - categorical_accuracy: 0.8357 - loss: 0.7369 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 29/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - categorical_accuracy: 0.8363 - loss: 0.7405 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n",
      "Epoch 30/30\n",
      "\u001b[1m2648/2648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 679us/step - categorical_accuracy: 0.8359 - loss: 0.7369 - val_categorical_accuracy: 0.8422 - val_loss: 0.6897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-07 13:28:13,206] Trial 1 finished with value: 0.6850530106831333 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'activation_l3': 'tanh', 'activation_l4': 'tanh', 'batch_size': 101, 'decay_rate': 0.9, 'decay_steps': 500, 'dropout_l1': 0.0, 'dropout_l2': 0.30000000000000004, 'dropout_l3': 0.4, 'dropout_l4': 0.0, 'learning_rate_init': 1.0915604348808666e-05, 'n_units_l1': 107, 'n_units_l2': 91, 'n_units_l3': 127, 'n_units_l4': 96, 'num_layers': 4}. Best is trial 0 with value: 0.4757000375413659.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.8584 - loss: 0.6091  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518499.119953  457310 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 268 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518499.228373  457304 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518499.575016  457314 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 232 bytes spill stores, 232 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518499.984837  457306 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 392 bytes spill stores, 392 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518500.021148  457302 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518500.049335  457303 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 420 bytes spill stores, 448 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518500.376191  457308 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 244 bytes spill stores, 244 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518500.725184  457314 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 496 bytes spill stores, 564 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518501.640328  457401 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 52 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518501.727679  457398 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518502.469688  457393 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 244 bytes spill stores, 244 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518502.521379  457400 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 232 bytes spill stores, 232 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518502.545524  457396 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518502.556851  457391 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 392 bytes spill stores, 392 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518502.675034  457405 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 428 bytes spill stores, 460 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518502.974522  457404 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 496 bytes spill stores, 564 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - categorical_accuracy: 0.8585 - loss: 0.6091 - val_categorical_accuracy: 0.8865 - val_loss: 0.4522\n",
      "Epoch 2/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - categorical_accuracy: 0.8857 - loss: 0.4542 - val_categorical_accuracy: 0.8896 - val_loss: 0.4327\n",
      "Epoch 3/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - categorical_accuracy: 0.8870 - loss: 0.4443 - val_categorical_accuracy: 0.8898 - val_loss: 0.4341\n",
      "Epoch 4/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - categorical_accuracy: 0.8891 - loss: 0.4377 - val_categorical_accuracy: 0.8918 - val_loss: 0.4286\n",
      "Epoch 5/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - categorical_accuracy: 0.8896 - loss: 0.4344 - val_categorical_accuracy: 0.8905 - val_loss: 0.4254\n",
      "Epoch 6/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - categorical_accuracy: 0.8901 - loss: 0.4299 - val_categorical_accuracy: 0.8894 - val_loss: 0.4316\n",
      "Epoch 7/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - categorical_accuracy: 0.8909 - loss: 0.4258 - val_categorical_accuracy: 0.8941 - val_loss: 0.4143\n",
      "Epoch 8/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - categorical_accuracy: 0.8912 - loss: 0.4213 - val_categorical_accuracy: 0.8928 - val_loss: 0.4101\n",
      "Epoch 9/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - categorical_accuracy: 0.8924 - loss: 0.4164 - val_categorical_accuracy: 0.8948 - val_loss: 0.4134\n",
      "Epoch 10/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - categorical_accuracy: 0.8938 - loss: 0.4091 - val_categorical_accuracy: 0.8921 - val_loss: 0.4050\n",
      "Epoch 11/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - categorical_accuracy: 0.8946 - loss: 0.4086 - val_categorical_accuracy: 0.8981 - val_loss: 0.3950\n",
      "Epoch 12/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - categorical_accuracy: 0.8969 - loss: 0.4002 - val_categorical_accuracy: 0.8980 - val_loss: 0.3929\n",
      "Epoch 13/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - categorical_accuracy: 0.8964 - loss: 0.4015 - val_categorical_accuracy: 0.8987 - val_loss: 0.3926\n",
      "Epoch 14/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - categorical_accuracy: 0.8965 - loss: 0.4008 - val_categorical_accuracy: 0.8947 - val_loss: 0.4043\n",
      "Epoch 15/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - categorical_accuracy: 0.8975 - loss: 0.3977 - val_categorical_accuracy: 0.8990 - val_loss: 0.3919\n",
      "Epoch 16/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - categorical_accuracy: 0.8972 - loss: 0.3963 - val_categorical_accuracy: 0.9009 - val_loss: 0.3881\n",
      "Epoch 17/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - categorical_accuracy: 0.8979 - loss: 0.3943 - val_categorical_accuracy: 0.9007 - val_loss: 0.3901\n",
      "Epoch 18/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - categorical_accuracy: 0.8966 - loss: 0.3994 - val_categorical_accuracy: 0.8997 - val_loss: 0.3847\n",
      "Epoch 19/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - categorical_accuracy: 0.8981 - loss: 0.3932 - val_categorical_accuracy: 0.8998 - val_loss: 0.3858\n",
      "Epoch 20/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - categorical_accuracy: 0.8967 - loss: 0.3985 - val_categorical_accuracy: 0.9012 - val_loss: 0.3817\n",
      "Epoch 21/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - categorical_accuracy: 0.8994 - loss: 0.3892 - val_categorical_accuracy: 0.9045 - val_loss: 0.3828\n",
      "Epoch 22/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - categorical_accuracy: 0.8992 - loss: 0.3896 - val_categorical_accuracy: 0.8946 - val_loss: 0.3873\n",
      "Epoch 23/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - categorical_accuracy: 0.9007 - loss: 0.3848 - val_categorical_accuracy: 0.9005 - val_loss: 0.3850\n",
      "Epoch 24/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - categorical_accuracy: 0.9006 - loss: 0.3878 - val_categorical_accuracy: 0.9028 - val_loss: 0.3787\n",
      "Epoch 25/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - categorical_accuracy: 0.9003 - loss: 0.3873 - val_categorical_accuracy: 0.9047 - val_loss: 0.3813\n",
      "Epoch 26/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - categorical_accuracy: 0.9019 - loss: 0.3831 - val_categorical_accuracy: 0.9048 - val_loss: 0.3780\n",
      "Epoch 27/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - categorical_accuracy: 0.9009 - loss: 0.3854 - val_categorical_accuracy: 0.9047 - val_loss: 0.3748\n",
      "Epoch 28/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - categorical_accuracy: 0.9026 - loss: 0.3805 - val_categorical_accuracy: 0.9045 - val_loss: 0.3756\n",
      "Epoch 29/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - categorical_accuracy: 0.9028 - loss: 0.3794 - val_categorical_accuracy: 0.9049 - val_loss: 0.3742\n",
      "Epoch 30/30\n",
      "\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - categorical_accuracy: 0.9026 - loss: 0.3814 - val_categorical_accuracy: 0.9051 - val_loss: 0.3728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:28:59,340] Trial 2 finished with value: 0.368867228042209 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'activation_l3': 'relu', 'batch_size': 176, 'decay_rate': 0.9, 'decay_steps': 2000, 'dropout_l1': 0.1, 'dropout_l2': 0.2, 'dropout_l3': 0.2, 'learning_rate_init': 0.0036040324146397874, 'n_units_l1': 67, 'n_units_l2': 82, 'n_units_l3': 84, 'num_layers': 3}. Best is trial 2 with value: 0.368867228042209.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - categorical_accuracy: 0.3518 - loss: 2.2876 - val_categorical_accuracy: 0.7047 - val_loss: 1.3677\n",
      "Epoch 2/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - categorical_accuracy: 0.7064 - loss: 1.2718 - val_categorical_accuracy: 0.7047 - val_loss: 1.1209\n",
      "Epoch 3/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - categorical_accuracy: 0.7060 - loss: 1.0899 - val_categorical_accuracy: 0.7158 - val_loss: 1.0290\n",
      "Epoch 4/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - categorical_accuracy: 0.7279 - loss: 1.0050 - val_categorical_accuracy: 0.7609 - val_loss: 0.9696\n",
      "Epoch 5/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - categorical_accuracy: 0.7713 - loss: 0.9502 - val_categorical_accuracy: 0.7866 - val_loss: 0.9294\n",
      "Epoch 6/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - categorical_accuracy: 0.7910 - loss: 0.9167 - val_categorical_accuracy: 0.7981 - val_loss: 0.9019\n",
      "Epoch 7/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - categorical_accuracy: 0.8020 - loss: 0.8893 - val_categorical_accuracy: 0.8047 - val_loss: 0.8825\n",
      "Epoch 8/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - categorical_accuracy: 0.8076 - loss: 0.8749 - val_categorical_accuracy: 0.8087 - val_loss: 0.8687\n",
      "Epoch 9/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - categorical_accuracy: 0.8127 - loss: 0.8553 - val_categorical_accuracy: 0.8116 - val_loss: 0.8587\n",
      "Epoch 10/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - categorical_accuracy: 0.8140 - loss: 0.8529 - val_categorical_accuracy: 0.8137 - val_loss: 0.8513\n",
      "Epoch 11/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - categorical_accuracy: 0.8155 - loss: 0.8465 - val_categorical_accuracy: 0.8153 - val_loss: 0.8459\n",
      "Epoch 12/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - categorical_accuracy: 0.8166 - loss: 0.8409 - val_categorical_accuracy: 0.8161 - val_loss: 0.8419\n",
      "Epoch 13/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - categorical_accuracy: 0.8195 - loss: 0.8306 - val_categorical_accuracy: 0.8168 - val_loss: 0.8389\n",
      "Epoch 14/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - categorical_accuracy: 0.8188 - loss: 0.8346 - val_categorical_accuracy: 0.8175 - val_loss: 0.8366\n",
      "Epoch 15/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - categorical_accuracy: 0.8183 - loss: 0.8336 - val_categorical_accuracy: 0.8178 - val_loss: 0.8349\n",
      "Epoch 16/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - categorical_accuracy: 0.8195 - loss: 0.8307 - val_categorical_accuracy: 0.8181 - val_loss: 0.8337\n",
      "Epoch 17/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - categorical_accuracy: 0.8208 - loss: 0.8254 - val_categorical_accuracy: 0.8182 - val_loss: 0.8327\n",
      "Epoch 18/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - categorical_accuracy: 0.8199 - loss: 0.8276 - val_categorical_accuracy: 0.8183 - val_loss: 0.8320\n",
      "Epoch 19/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - categorical_accuracy: 0.8207 - loss: 0.8269 - val_categorical_accuracy: 0.8184 - val_loss: 0.8315\n",
      "Epoch 20/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - categorical_accuracy: 0.8194 - loss: 0.8279 - val_categorical_accuracy: 0.8185 - val_loss: 0.8311\n",
      "Epoch 21/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - categorical_accuracy: 0.8206 - loss: 0.8260 - val_categorical_accuracy: 0.8185 - val_loss: 0.8308\n",
      "Epoch 22/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - categorical_accuracy: 0.8211 - loss: 0.8229 - val_categorical_accuracy: 0.8186 - val_loss: 0.8305\n",
      "Epoch 23/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - categorical_accuracy: 0.8185 - loss: 0.8295 - val_categorical_accuracy: 0.8186 - val_loss: 0.8303\n",
      "Epoch 24/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - categorical_accuracy: 0.8207 - loss: 0.8235 - val_categorical_accuracy: 0.8187 - val_loss: 0.8302\n",
      "Epoch 25/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - categorical_accuracy: 0.8212 - loss: 0.8235 - val_categorical_accuracy: 0.8187 - val_loss: 0.8301\n",
      "Epoch 26/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - categorical_accuracy: 0.8213 - loss: 0.8229 - val_categorical_accuracy: 0.8187 - val_loss: 0.8300\n",
      "Epoch 27/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - categorical_accuracy: 0.8205 - loss: 0.8265 - val_categorical_accuracy: 0.8187 - val_loss: 0.8300\n",
      "Epoch 28/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - categorical_accuracy: 0.8207 - loss: 0.8246 - val_categorical_accuracy: 0.8187 - val_loss: 0.8300\n",
      "Epoch 29/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - categorical_accuracy: 0.8208 - loss: 0.8241 - val_categorical_accuracy: 0.8187 - val_loss: 0.8299\n",
      "Epoch 30/30\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - categorical_accuracy: 0.8198 - loss: 0.8266 - val_categorical_accuracy: 0.8187 - val_loss: 0.8299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-07 13:29:40,481] Trial 3 finished with value: 0.8260546543652938 and parameters: {'activation_l1': 'tanh', 'batch_size': 142, 'decay_rate': 0.8, 'decay_steps': 1500, 'dropout_l1': 0.0, 'learning_rate_init': 2.18586631273931e-05, 'n_units_l1': 54, 'num_layers': 1}. Best is trial 2 with value: 0.368867228042209.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518582.744504  460863 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1203', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - categorical_accuracy: 0.6907 - loss: 1.3350 - val_categorical_accuracy: 0.8536 - val_loss: 0.7049\n",
      "Epoch 2/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 697us/step - categorical_accuracy: 0.8379 - loss: 0.8216 - val_categorical_accuracy: 0.8598 - val_loss: 0.6629\n",
      "Epoch 3/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662us/step - categorical_accuracy: 0.8461 - loss: 0.7755 - val_categorical_accuracy: 0.8610 - val_loss: 0.6501\n",
      "Epoch 4/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652us/step - categorical_accuracy: 0.8474 - loss: 0.7631 - val_categorical_accuracy: 0.8613 - val_loss: 0.6469\n",
      "Epoch 5/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 637us/step - categorical_accuracy: 0.8488 - loss: 0.7584 - val_categorical_accuracy: 0.8613 - val_loss: 0.6454\n",
      "Epoch 6/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 641us/step - categorical_accuracy: 0.8479 - loss: 0.7610 - val_categorical_accuracy: 0.8614 - val_loss: 0.6449\n",
      "Epoch 7/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 629us/step - categorical_accuracy: 0.8478 - loss: 0.7629 - val_categorical_accuracy: 0.8614 - val_loss: 0.6448\n",
      "Epoch 8/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 667us/step - categorical_accuracy: 0.8486 - loss: 0.7588 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 9/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 675us/step - categorical_accuracy: 0.8486 - loss: 0.7578 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 10/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640us/step - categorical_accuracy: 0.8468 - loss: 0.7660 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 11/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 649us/step - categorical_accuracy: 0.8472 - loss: 0.7642 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 12/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640us/step - categorical_accuracy: 0.8485 - loss: 0.7560 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 13/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676us/step - categorical_accuracy: 0.8475 - loss: 0.7656 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 14/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642us/step - categorical_accuracy: 0.8485 - loss: 0.7600 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 15/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 703us/step - categorical_accuracy: 0.8479 - loss: 0.7598 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 16/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 639us/step - categorical_accuracy: 0.8493 - loss: 0.7575 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 17/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642us/step - categorical_accuracy: 0.8479 - loss: 0.7623 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 18/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 636us/step - categorical_accuracy: 0.8485 - loss: 0.7586 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 19/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 633us/step - categorical_accuracy: 0.8477 - loss: 0.7618 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 20/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 645us/step - categorical_accuracy: 0.8489 - loss: 0.7579 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 21/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 638us/step - categorical_accuracy: 0.8491 - loss: 0.7598 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 22/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 660us/step - categorical_accuracy: 0.8482 - loss: 0.7622 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 23/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - categorical_accuracy: 0.8496 - loss: 0.7572 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 24/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 655us/step - categorical_accuracy: 0.8483 - loss: 0.7587 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 25/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 685us/step - categorical_accuracy: 0.8472 - loss: 0.7637 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 26/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step - categorical_accuracy: 0.8487 - loss: 0.7591 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 27/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - categorical_accuracy: 0.8489 - loss: 0.7565 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 28/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 675us/step - categorical_accuracy: 0.8492 - loss: 0.7556 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 29/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 638us/step - categorical_accuracy: 0.8473 - loss: 0.7645 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n",
      "Epoch 30/30\n",
      "\u001b[1m3473/3473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - categorical_accuracy: 0.8478 - loss: 0.7605 - val_categorical_accuracy: 0.8614 - val_loss: 0.6447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-07 13:31:04,488] Trial 4 finished with value: 0.6404504729762855 and parameters: {'activation_l1': 'relu', 'activation_l2': 'tanh', 'activation_l3': 'tanh', 'activation_l4': 'tanh', 'batch_size': 77, 'decay_rate': 0.8500000000000001, 'decay_steps': 500, 'dropout_l1': 0.2, 'dropout_l2': 0.4, 'dropout_l3': 0.0, 'dropout_l4': 0.4, 'learning_rate_init': 0.00014564811865952262, 'n_units_l1': 25, 'n_units_l2': 56, 'n_units_l3': 95, 'n_units_l4': 18, 'num_layers': 4}. Best is trial 2 with value: 0.368867228042209.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.6404 - loss: 1.4680  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518673.668236  463182 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_64', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518673.839767  463186 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 16 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518673.973748  463178 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518674.157556  463187 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 456 bytes spill stores, 644 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - categorical_accuracy: 0.6405 - loss: 1.4679 - val_categorical_accuracy: 0.8414 - val_loss: 0.7551\n",
      "Epoch 2/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 733us/step - categorical_accuracy: 0.8048 - loss: 0.8872 - val_categorical_accuracy: 0.8563 - val_loss: 0.6623\n",
      "Epoch 3/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 728us/step - categorical_accuracy: 0.8298 - loss: 0.7944 - val_categorical_accuracy: 0.8617 - val_loss: 0.6319\n",
      "Epoch 4/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 737us/step - categorical_accuracy: 0.8383 - loss: 0.7651 - val_categorical_accuracy: 0.8636 - val_loss: 0.6202\n",
      "Epoch 5/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 736us/step - categorical_accuracy: 0.8419 - loss: 0.7497 - val_categorical_accuracy: 0.8709 - val_loss: 0.6151\n",
      "Epoch 6/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 719us/step - categorical_accuracy: 0.8448 - loss: 0.7403 - val_categorical_accuracy: 0.8715 - val_loss: 0.6122\n",
      "Epoch 7/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - categorical_accuracy: 0.8447 - loss: 0.7420 - val_categorical_accuracy: 0.8716 - val_loss: 0.6109\n",
      "Epoch 8/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 711us/step - categorical_accuracy: 0.8441 - loss: 0.7420 - val_categorical_accuracy: 0.8716 - val_loss: 0.6104\n",
      "Epoch 9/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - categorical_accuracy: 0.8460 - loss: 0.7355 - val_categorical_accuracy: 0.8717 - val_loss: 0.6101\n",
      "Epoch 10/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - categorical_accuracy: 0.8453 - loss: 0.7386 - val_categorical_accuracy: 0.8717 - val_loss: 0.6100\n",
      "Epoch 11/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.8455 - loss: 0.7331 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 12/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - categorical_accuracy: 0.8441 - loss: 0.7416 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 13/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - categorical_accuracy: 0.8467 - loss: 0.7330 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 14/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - categorical_accuracy: 0.8436 - loss: 0.7429 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 15/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - categorical_accuracy: 0.8464 - loss: 0.7337 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 16/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - categorical_accuracy: 0.8458 - loss: 0.7354 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 17/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - categorical_accuracy: 0.8449 - loss: 0.7378 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 18/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - categorical_accuracy: 0.8455 - loss: 0.7380 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 19/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - categorical_accuracy: 0.8452 - loss: 0.7384 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 20/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - categorical_accuracy: 0.8458 - loss: 0.7365 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 21/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - categorical_accuracy: 0.8438 - loss: 0.7423 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 22/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - categorical_accuracy: 0.8456 - loss: 0.7362 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 23/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.8451 - loss: 0.7410 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 24/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - categorical_accuracy: 0.8465 - loss: 0.7323 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 25/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - categorical_accuracy: 0.8446 - loss: 0.7399 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 26/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - categorical_accuracy: 0.8449 - loss: 0.7389 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 27/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - categorical_accuracy: 0.8472 - loss: 0.7300 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 28/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - categorical_accuracy: 0.8456 - loss: 0.7362 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 29/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 682us/step - categorical_accuracy: 0.8447 - loss: 0.7381 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n",
      "Epoch 30/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - categorical_accuracy: 0.8449 - loss: 0.7413 - val_categorical_accuracy: 0.8717 - val_loss: 0.6099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518724.997027  465016 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_32', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "[I 2025-11-07 13:32:06,838] Trial 5 finished with value: 0.6056836276810001 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'activation_l3': 'relu', 'activation_l4': 'tanh', 'batch_size': 123, 'decay_rate': 0.8500000000000001, 'decay_steps': 500, 'dropout_l1': 0.1, 'dropout_l2': 0.30000000000000004, 'dropout_l3': 0.30000000000000004, 'dropout_l4': 0.4, 'learning_rate_init': 8.214466817422305e-05, 'n_units_l1': 73, 'n_units_l2': 47, 'n_units_l3': 65, 'n_units_l4': 30, 'num_layers': 4}. Best is trial 2 with value: 0.368867228042209.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.8011 - loss: 0.8523  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518733.584662  465235 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 648 bytes spill stores, 624 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518734.366067  465245 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 680 bytes spill stores, 688 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - categorical_accuracy: 0.8012 - loss: 0.8522 - val_categorical_accuracy: 0.8795 - val_loss: 0.4775\n",
      "Epoch 2/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - categorical_accuracy: 0.8799 - loss: 0.5000 - val_categorical_accuracy: 0.8873 - val_loss: 0.4540\n",
      "Epoch 3/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - categorical_accuracy: 0.8830 - loss: 0.4715 - val_categorical_accuracy: 0.8884 - val_loss: 0.4458\n",
      "Epoch 4/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - categorical_accuracy: 0.8845 - loss: 0.4616 - val_categorical_accuracy: 0.8894 - val_loss: 0.4360\n",
      "Epoch 5/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - categorical_accuracy: 0.8861 - loss: 0.4540 - val_categorical_accuracy: 0.8880 - val_loss: 0.4337\n",
      "Epoch 6/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - categorical_accuracy: 0.8870 - loss: 0.4485 - val_categorical_accuracy: 0.8891 - val_loss: 0.4316\n",
      "Epoch 7/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - categorical_accuracy: 0.8874 - loss: 0.4452 - val_categorical_accuracy: 0.8907 - val_loss: 0.4282\n",
      "Epoch 8/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - categorical_accuracy: 0.8888 - loss: 0.4412 - val_categorical_accuracy: 0.8851 - val_loss: 0.4337\n",
      "Epoch 9/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - categorical_accuracy: 0.8884 - loss: 0.4401 - val_categorical_accuracy: 0.8903 - val_loss: 0.4265\n",
      "Epoch 10/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - categorical_accuracy: 0.8880 - loss: 0.4400 - val_categorical_accuracy: 0.8905 - val_loss: 0.4267\n",
      "Epoch 11/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - categorical_accuracy: 0.8895 - loss: 0.4368 - val_categorical_accuracy: 0.8907 - val_loss: 0.4279\n",
      "Epoch 12/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - categorical_accuracy: 0.8901 - loss: 0.4362 - val_categorical_accuracy: 0.8913 - val_loss: 0.4245\n",
      "Epoch 13/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - categorical_accuracy: 0.8899 - loss: 0.4343 - val_categorical_accuracy: 0.8928 - val_loss: 0.4226\n",
      "Epoch 14/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - categorical_accuracy: 0.8900 - loss: 0.4337 - val_categorical_accuracy: 0.8922 - val_loss: 0.4212\n",
      "Epoch 15/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - categorical_accuracy: 0.8894 - loss: 0.4327 - val_categorical_accuracy: 0.8917 - val_loss: 0.4211\n",
      "Epoch 16/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686us/step - categorical_accuracy: 0.8908 - loss: 0.4308 - val_categorical_accuracy: 0.8913 - val_loss: 0.4226\n",
      "Epoch 17/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - categorical_accuracy: 0.8905 - loss: 0.4291 - val_categorical_accuracy: 0.8924 - val_loss: 0.4201\n",
      "Epoch 18/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - categorical_accuracy: 0.8906 - loss: 0.4287 - val_categorical_accuracy: 0.8930 - val_loss: 0.4182\n",
      "Epoch 19/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - categorical_accuracy: 0.8912 - loss: 0.4279 - val_categorical_accuracy: 0.8924 - val_loss: 0.4185\n",
      "Epoch 20/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - categorical_accuracy: 0.8918 - loss: 0.4262 - val_categorical_accuracy: 0.8922 - val_loss: 0.4189\n",
      "Epoch 21/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - categorical_accuracy: 0.8910 - loss: 0.4278 - val_categorical_accuracy: 0.8931 - val_loss: 0.4170\n",
      "Epoch 22/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - categorical_accuracy: 0.8921 - loss: 0.4255 - val_categorical_accuracy: 0.8920 - val_loss: 0.4184\n",
      "Epoch 23/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - categorical_accuracy: 0.8917 - loss: 0.4247 - val_categorical_accuracy: 0.8932 - val_loss: 0.4165\n",
      "Epoch 24/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - categorical_accuracy: 0.8917 - loss: 0.4255 - val_categorical_accuracy: 0.8934 - val_loss: 0.4175\n",
      "Epoch 25/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - categorical_accuracy: 0.8913 - loss: 0.4280 - val_categorical_accuracy: 0.8923 - val_loss: 0.4183\n",
      "Epoch 26/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - categorical_accuracy: 0.8916 - loss: 0.4252 - val_categorical_accuracy: 0.8938 - val_loss: 0.4151\n",
      "Epoch 27/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - categorical_accuracy: 0.8924 - loss: 0.4229 - val_categorical_accuracy: 0.8938 - val_loss: 0.4151\n",
      "Epoch 28/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - categorical_accuracy: 0.8918 - loss: 0.4248 - val_categorical_accuracy: 0.8940 - val_loss: 0.4153\n",
      "Epoch 29/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - categorical_accuracy: 0.8924 - loss: 0.4238 - val_categorical_accuracy: 0.8940 - val_loss: 0.4147\n",
      "Epoch 30/30\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - categorical_accuracy: 0.8926 - loss: 0.4217 - val_categorical_accuracy: 0.8939 - val_loss: 0.4147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:32:48,499] Trial 6 finished with value: 0.4085713523293846 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'activation_l3': 'relu', 'batch_size': 214, 'decay_rate': 0.8500000000000001, 'decay_steps': 2000, 'dropout_l1': 0.1, 'dropout_l2': 0.2, 'dropout_l3': 0.4, 'learning_rate_init': 0.00267611652870371, 'n_units_l1': 47, 'n_units_l2': 41, 'n_units_l3': 40, 'num_layers': 3}. Best is trial 2 with value: 0.368867228042209.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518770.121781  466917 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_667', 596 bytes spill stores, 596 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518770.361668  466908 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_510', 248 bytes spill stores, 244 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518770.548721  466917 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_667', 592 bytes spill stores, 592 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518770.569746  466907 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_510', 184 bytes spill stores, 184 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.8349 - loss: 0.6885  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518773.077752  467060 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 144 bytes spill stores, 144 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518773.088351  467067 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518773.188292  467073 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518773.297334  467062 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 524 bytes spill stores, 524 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518773.330625  467064 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - categorical_accuracy: 0.8350 - loss: 0.6883 - val_categorical_accuracy: 0.8749 - val_loss: 0.4827\n",
      "Epoch 2/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - categorical_accuracy: 0.8833 - loss: 0.4640 - val_categorical_accuracy: 0.8867 - val_loss: 0.4520\n",
      "Epoch 3/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - categorical_accuracy: 0.8865 - loss: 0.4492 - val_categorical_accuracy: 0.8854 - val_loss: 0.4462\n",
      "Epoch 4/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - categorical_accuracy: 0.8884 - loss: 0.4344 - val_categorical_accuracy: 0.8818 - val_loss: 0.4612\n",
      "Epoch 5/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - categorical_accuracy: 0.8886 - loss: 0.4386 - val_categorical_accuracy: 0.8909 - val_loss: 0.4273\n",
      "Epoch 6/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - categorical_accuracy: 0.8918 - loss: 0.4232 - val_categorical_accuracy: 0.8914 - val_loss: 0.4207\n",
      "Epoch 7/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - categorical_accuracy: 0.8921 - loss: 0.4198 - val_categorical_accuracy: 0.8913 - val_loss: 0.4207\n",
      "Epoch 8/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - categorical_accuracy: 0.8913 - loss: 0.4203 - val_categorical_accuracy: 0.8912 - val_loss: 0.4161\n",
      "Epoch 9/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - categorical_accuracy: 0.8924 - loss: 0.4159 - val_categorical_accuracy: 0.8937 - val_loss: 0.4105\n",
      "Epoch 10/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - categorical_accuracy: 0.8948 - loss: 0.4090 - val_categorical_accuracy: 0.8951 - val_loss: 0.4131\n",
      "Epoch 11/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - categorical_accuracy: 0.8948 - loss: 0.4072 - val_categorical_accuracy: 0.8941 - val_loss: 0.4075\n",
      "Epoch 12/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - categorical_accuracy: 0.8947 - loss: 0.4073 - val_categorical_accuracy: 0.8949 - val_loss: 0.4043\n",
      "Epoch 13/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - categorical_accuracy: 0.8937 - loss: 0.4112 - val_categorical_accuracy: 0.8947 - val_loss: 0.4060\n",
      "Epoch 14/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - categorical_accuracy: 0.8951 - loss: 0.4050 - val_categorical_accuracy: 0.8967 - val_loss: 0.4023\n",
      "Epoch 15/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - categorical_accuracy: 0.8953 - loss: 0.4066 - val_categorical_accuracy: 0.8971 - val_loss: 0.4009\n",
      "Epoch 16/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - categorical_accuracy: 0.8961 - loss: 0.4020 - val_categorical_accuracy: 0.8974 - val_loss: 0.3993\n",
      "Epoch 17/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - categorical_accuracy: 0.8960 - loss: 0.4021 - val_categorical_accuracy: 0.8975 - val_loss: 0.3990\n",
      "Epoch 18/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - categorical_accuracy: 0.8966 - loss: 0.4009 - val_categorical_accuracy: 0.8979 - val_loss: 0.3981\n",
      "Epoch 19/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - categorical_accuracy: 0.8974 - loss: 0.3966 - val_categorical_accuracy: 0.8973 - val_loss: 0.3975\n",
      "Epoch 20/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - categorical_accuracy: 0.8981 - loss: 0.3952 - val_categorical_accuracy: 0.8979 - val_loss: 0.3973\n",
      "Epoch 21/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - categorical_accuracy: 0.8969 - loss: 0.3985 - val_categorical_accuracy: 0.8983 - val_loss: 0.3956\n",
      "Epoch 22/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - categorical_accuracy: 0.8971 - loss: 0.3970 - val_categorical_accuracy: 0.8981 - val_loss: 0.3946\n",
      "Epoch 23/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - categorical_accuracy: 0.8984 - loss: 0.3923 - val_categorical_accuracy: 0.8982 - val_loss: 0.3952\n",
      "Epoch 24/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - categorical_accuracy: 0.8983 - loss: 0.3920 - val_categorical_accuracy: 0.8982 - val_loss: 0.3936\n",
      "Epoch 25/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - categorical_accuracy: 0.8979 - loss: 0.3938 - val_categorical_accuracy: 0.8984 - val_loss: 0.3939\n",
      "Epoch 26/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - categorical_accuracy: 0.8971 - loss: 0.3967 - val_categorical_accuracy: 0.8983 - val_loss: 0.3930\n",
      "Epoch 27/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - categorical_accuracy: 0.8976 - loss: 0.3964 - val_categorical_accuracy: 0.8984 - val_loss: 0.3935\n",
      "Epoch 28/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - categorical_accuracy: 0.8974 - loss: 0.3957 - val_categorical_accuracy: 0.8983 - val_loss: 0.3926\n",
      "Epoch 29/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - categorical_accuracy: 0.8979 - loss: 0.3930 - val_categorical_accuracy: 0.8985 - val_loss: 0.3923\n",
      "Epoch 30/30\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - categorical_accuracy: 0.8978 - loss: 0.3922 - val_categorical_accuracy: 0.8985 - val_loss: 0.3918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:33:15,127] Trial 7 finished with value: 0.38802694093249374 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'batch_size': 457, 'decay_rate': 0.9, 'decay_steps': 500, 'dropout_l1': 0.1, 'dropout_l2': 0.0, 'learning_rate_init': 0.00574831415110009, 'n_units_l1': 32, 'n_units_l2': 93, 'num_layers': 2}. Best is trial 2 with value: 0.368867228042209.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 918us/step - categorical_accuracy: 0.1056 - loss: 2.7243 - val_categorical_accuracy: 0.7054 - val_loss: 1.7315\n",
      "Epoch 2/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 604us/step - categorical_accuracy: 0.6210 - loss: 1.6983 - val_categorical_accuracy: 0.7047 - val_loss: 1.3048\n",
      "Epoch 3/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 620us/step - categorical_accuracy: 0.6759 - loss: 1.4228 - val_categorical_accuracy: 0.7047 - val_loss: 1.1801\n",
      "Epoch 4/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 621us/step - categorical_accuracy: 0.6902 - loss: 1.3261 - val_categorical_accuracy: 0.7047 - val_loss: 1.1359\n",
      "Epoch 5/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 606us/step - categorical_accuracy: 0.7025 - loss: 1.2891 - val_categorical_accuracy: 0.7047 - val_loss: 1.1122\n",
      "Epoch 6/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 615us/step - categorical_accuracy: 0.7112 - loss: 1.2579 - val_categorical_accuracy: 0.7058 - val_loss: 1.0970\n",
      "Epoch 7/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 624us/step - categorical_accuracy: 0.7133 - loss: 1.2419 - val_categorical_accuracy: 0.7079 - val_loss: 1.0866\n",
      "Epoch 8/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 650us/step - categorical_accuracy: 0.7178 - loss: 1.2229 - val_categorical_accuracy: 0.7098 - val_loss: 1.0794\n",
      "Epoch 9/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 550us/step - categorical_accuracy: 0.7172 - loss: 1.2222 - val_categorical_accuracy: 0.7114 - val_loss: 1.0743\n",
      "Epoch 10/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 594us/step - categorical_accuracy: 0.7189 - loss: 1.2177 - val_categorical_accuracy: 0.7127 - val_loss: 1.0707\n",
      "Epoch 11/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610us/step - categorical_accuracy: 0.7192 - loss: 1.2072 - val_categorical_accuracy: 0.7137 - val_loss: 1.0681\n",
      "Epoch 12/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 606us/step - categorical_accuracy: 0.7197 - loss: 1.2073 - val_categorical_accuracy: 0.7146 - val_loss: 1.0662\n",
      "Epoch 13/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 595us/step - categorical_accuracy: 0.7212 - loss: 1.2017 - val_categorical_accuracy: 0.7153 - val_loss: 1.0648\n",
      "Epoch 14/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 619us/step - categorical_accuracy: 0.7215 - loss: 1.2003 - val_categorical_accuracy: 0.7158 - val_loss: 1.0639\n",
      "Epoch 15/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 600us/step - categorical_accuracy: 0.7216 - loss: 1.2018 - val_categorical_accuracy: 0.7163 - val_loss: 1.0631\n",
      "Epoch 16/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 598us/step - categorical_accuracy: 0.7220 - loss: 1.1979 - val_categorical_accuracy: 0.7165 - val_loss: 1.0626\n",
      "Epoch 17/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 591us/step - categorical_accuracy: 0.7213 - loss: 1.1981 - val_categorical_accuracy: 0.7167 - val_loss: 1.0623\n",
      "Epoch 18/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 595us/step - categorical_accuracy: 0.7215 - loss: 1.2013 - val_categorical_accuracy: 0.7168 - val_loss: 1.0620\n",
      "Epoch 19/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 596us/step - categorical_accuracy: 0.7219 - loss: 1.1985 - val_categorical_accuracy: 0.7169 - val_loss: 1.0618\n",
      "Epoch 20/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 652us/step - categorical_accuracy: 0.7204 - loss: 1.2057 - val_categorical_accuracy: 0.7169 - val_loss: 1.0617\n",
      "Epoch 21/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 608us/step - categorical_accuracy: 0.7220 - loss: 1.2005 - val_categorical_accuracy: 0.7170 - val_loss: 1.0615\n",
      "Epoch 22/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 608us/step - categorical_accuracy: 0.7222 - loss: 1.1991 - val_categorical_accuracy: 0.7170 - val_loss: 1.0615\n",
      "Epoch 23/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 605us/step - categorical_accuracy: 0.7230 - loss: 1.1954 - val_categorical_accuracy: 0.7170 - val_loss: 1.0614\n",
      "Epoch 24/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 596us/step - categorical_accuracy: 0.7228 - loss: 1.1965 - val_categorical_accuracy: 0.7170 - val_loss: 1.0614\n",
      "Epoch 25/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 585us/step - categorical_accuracy: 0.7221 - loss: 1.2034 - val_categorical_accuracy: 0.7170 - val_loss: 1.0614\n",
      "Epoch 26/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 605us/step - categorical_accuracy: 0.7216 - loss: 1.2003 - val_categorical_accuracy: 0.7170 - val_loss: 1.0614\n",
      "Epoch 27/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 590us/step - categorical_accuracy: 0.7220 - loss: 1.1997 - val_categorical_accuracy: 0.7170 - val_loss: 1.0614\n",
      "Epoch 28/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 587us/step - categorical_accuracy: 0.7229 - loss: 1.1956 - val_categorical_accuracy: 0.7170 - val_loss: 1.0614\n",
      "Epoch 29/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 612us/step - categorical_accuracy: 0.7222 - loss: 1.1981 - val_categorical_accuracy: 0.7170 - val_loss: 1.0614\n",
      "Epoch 30/30\n",
      "\u001b[1m3932/3932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 595us/step - categorical_accuracy: 0.7234 - loss: 1.1921 - val_categorical_accuracy: 0.7170 - val_loss: 1.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-07 13:34:35,535] Trial 8 finished with value: 1.059624622472574 and parameters: {'activation_l1': 'relu', 'batch_size': 68, 'decay_rate': 0.8500000000000001, 'decay_steps': 2000, 'dropout_l1': 0.30000000000000004, 'learning_rate_init': 2.1576545014514877e-05, 'n_units_l1': 18, 'num_layers': 1}. Best is trial 2 with value: 0.368867228042209.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - categorical_accuracy: 0.7808 - loss: 0.9066 - val_categorical_accuracy: 0.8761 - val_loss: 0.5260\n",
      "Epoch 2/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 607us/step - categorical_accuracy: 0.8773 - loss: 0.5315 - val_categorical_accuracy: 0.8776 - val_loss: 0.5048\n",
      "Epoch 3/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 624us/step - categorical_accuracy: 0.8788 - loss: 0.5112 - val_categorical_accuracy: 0.8781 - val_loss: 0.4967\n",
      "Epoch 4/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 617us/step - categorical_accuracy: 0.8770 - loss: 0.5127 - val_categorical_accuracy: 0.8782 - val_loss: 0.4931\n",
      "Epoch 5/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642us/step - categorical_accuracy: 0.8794 - loss: 0.5016 - val_categorical_accuracy: 0.8782 - val_loss: 0.4910\n",
      "Epoch 6/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658us/step - categorical_accuracy: 0.8783 - loss: 0.5049 - val_categorical_accuracy: 0.8783 - val_loss: 0.4897\n",
      "Epoch 7/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 630us/step - categorical_accuracy: 0.8795 - loss: 0.4994 - val_categorical_accuracy: 0.8783 - val_loss: 0.4888\n",
      "Epoch 8/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 620us/step - categorical_accuracy: 0.8797 - loss: 0.4976 - val_categorical_accuracy: 0.8783 - val_loss: 0.4885\n",
      "Epoch 9/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 619us/step - categorical_accuracy: 0.8792 - loss: 0.4992 - val_categorical_accuracy: 0.8783 - val_loss: 0.4884\n",
      "Epoch 10/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 624us/step - categorical_accuracy: 0.8791 - loss: 0.5002 - val_categorical_accuracy: 0.8783 - val_loss: 0.4882\n",
      "Epoch 11/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 630us/step - categorical_accuracy: 0.8797 - loss: 0.4953 - val_categorical_accuracy: 0.8783 - val_loss: 0.4881\n",
      "Epoch 12/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 611us/step - categorical_accuracy: 0.8802 - loss: 0.4977 - val_categorical_accuracy: 0.8783 - val_loss: 0.4881\n",
      "Epoch 13/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 608us/step - categorical_accuracy: 0.8784 - loss: 0.5014 - val_categorical_accuracy: 0.8783 - val_loss: 0.4881\n",
      "Epoch 14/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 621us/step - categorical_accuracy: 0.8798 - loss: 0.4976 - val_categorical_accuracy: 0.8783 - val_loss: 0.4881\n",
      "Epoch 15/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 602us/step - categorical_accuracy: 0.8788 - loss: 0.4995 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 16/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 628us/step - categorical_accuracy: 0.8802 - loss: 0.4958 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 17/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610us/step - categorical_accuracy: 0.8789 - loss: 0.4987 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 18/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 609us/step - categorical_accuracy: 0.8799 - loss: 0.4965 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 19/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 624us/step - categorical_accuracy: 0.8796 - loss: 0.4980 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 20/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610us/step - categorical_accuracy: 0.8798 - loss: 0.4966 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 21/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 624us/step - categorical_accuracy: 0.8784 - loss: 0.5016 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 22/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 623us/step - categorical_accuracy: 0.8792 - loss: 0.4990 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 23/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 602us/step - categorical_accuracy: 0.8792 - loss: 0.4988 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 24/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610us/step - categorical_accuracy: 0.8797 - loss: 0.4971 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 25/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 606us/step - categorical_accuracy: 0.8795 - loss: 0.4978 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 26/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 608us/step - categorical_accuracy: 0.8789 - loss: 0.4996 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 27/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 607us/step - categorical_accuracy: 0.8804 - loss: 0.4955 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 28/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 606us/step - categorical_accuracy: 0.8797 - loss: 0.4989 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 29/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 612us/step - categorical_accuracy: 0.8781 - loss: 0.5031 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n",
      "Epoch 30/30\n",
      "\u001b[1m3613/3613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 604us/step - categorical_accuracy: 0.8792 - loss: 0.4999 - val_categorical_accuracy: 0.8783 - val_loss: 0.4880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:35:52,796] Trial 9 finished with value: 0.4851114194736433 and parameters: {'activation_l1': 'relu', 'batch_size': 74, 'decay_rate': 0.8, 'decay_steps': 1500, 'dropout_l1': 0.30000000000000004, 'learning_rate_init': 0.0005305167581776204, 'n_units_l1': 82, 'num_layers': 1}. Best is trial 2 with value: 0.368867228042209.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.8109 - loss: 0.8625  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518959.506246  472358 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518960.423250  472405 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - categorical_accuracy: 0.8110 - loss: 0.8624 - val_categorical_accuracy: 0.8696 - val_loss: 0.6196\n",
      "Epoch 2/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - categorical_accuracy: 0.8611 - loss: 0.6287 - val_categorical_accuracy: 0.8699 - val_loss: 0.5409\n",
      "Epoch 3/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8652 - loss: 0.5792 - val_categorical_accuracy: 0.8783 - val_loss: 0.5125\n",
      "Epoch 4/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8702 - loss: 0.5546 - val_categorical_accuracy: 0.8797 - val_loss: 0.4900\n",
      "Epoch 5/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - categorical_accuracy: 0.8712 - loss: 0.5408 - val_categorical_accuracy: 0.8797 - val_loss: 0.4844\n",
      "Epoch 6/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - categorical_accuracy: 0.8721 - loss: 0.5336 - val_categorical_accuracy: 0.8795 - val_loss: 0.4809\n",
      "Epoch 7/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - categorical_accuracy: 0.8730 - loss: 0.5267 - val_categorical_accuracy: 0.8795 - val_loss: 0.4785\n",
      "Epoch 8/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - categorical_accuracy: 0.8746 - loss: 0.5187 - val_categorical_accuracy: 0.8845 - val_loss: 0.4695\n",
      "Epoch 9/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - categorical_accuracy: 0.8745 - loss: 0.5168 - val_categorical_accuracy: 0.8853 - val_loss: 0.4688\n",
      "Epoch 10/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - categorical_accuracy: 0.8752 - loss: 0.5102 - val_categorical_accuracy: 0.8840 - val_loss: 0.4662\n",
      "Epoch 11/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - categorical_accuracy: 0.8754 - loss: 0.5088 - val_categorical_accuracy: 0.8856 - val_loss: 0.4632\n",
      "Epoch 12/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - categorical_accuracy: 0.8758 - loss: 0.5033 - val_categorical_accuracy: 0.8855 - val_loss: 0.4636\n",
      "Epoch 13/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - categorical_accuracy: 0.8767 - loss: 0.5019 - val_categorical_accuracy: 0.8850 - val_loss: 0.4641\n",
      "Epoch 14/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - categorical_accuracy: 0.8754 - loss: 0.5061 - val_categorical_accuracy: 0.8859 - val_loss: 0.4626\n",
      "Epoch 15/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - categorical_accuracy: 0.8761 - loss: 0.5037 - val_categorical_accuracy: 0.8853 - val_loss: 0.4628\n",
      "Epoch 16/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - categorical_accuracy: 0.8765 - loss: 0.5019 - val_categorical_accuracy: 0.8822 - val_loss: 0.4640\n",
      "Epoch 17/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - categorical_accuracy: 0.8761 - loss: 0.5022 - val_categorical_accuracy: 0.8861 - val_loss: 0.4618\n",
      "Epoch 18/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - categorical_accuracy: 0.8772 - loss: 0.4987 - val_categorical_accuracy: 0.8849 - val_loss: 0.4607\n",
      "Epoch 19/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - categorical_accuracy: 0.8755 - loss: 0.5028 - val_categorical_accuracy: 0.8852 - val_loss: 0.4616\n",
      "Epoch 20/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - categorical_accuracy: 0.8765 - loss: 0.5002 - val_categorical_accuracy: 0.8858 - val_loss: 0.4597\n",
      "Epoch 21/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - categorical_accuracy: 0.8770 - loss: 0.4961 - val_categorical_accuracy: 0.8857 - val_loss: 0.4606\n",
      "Epoch 22/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - categorical_accuracy: 0.8771 - loss: 0.4963 - val_categorical_accuracy: 0.8864 - val_loss: 0.4617\n",
      "Epoch 23/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8784 - loss: 0.4940 - val_categorical_accuracy: 0.8865 - val_loss: 0.4623\n",
      "Epoch 24/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8782 - loss: 0.4954 - val_categorical_accuracy: 0.8876 - val_loss: 0.4619\n",
      "Epoch 25/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - categorical_accuracy: 0.8787 - loss: 0.4946 - val_categorical_accuracy: 0.8863 - val_loss: 0.4587\n",
      "Epoch 26/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8771 - loss: 0.4975 - val_categorical_accuracy: 0.8865 - val_loss: 0.4601\n",
      "Epoch 27/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - categorical_accuracy: 0.8768 - loss: 0.4988 - val_categorical_accuracy: 0.8860 - val_loss: 0.4593\n",
      "Epoch 28/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - categorical_accuracy: 0.8780 - loss: 0.4943 - val_categorical_accuracy: 0.8867 - val_loss: 0.4613\n",
      "Epoch 29/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8785 - loss: 0.4926 - val_categorical_accuracy: 0.8866 - val_loss: 0.4584\n",
      "Epoch 30/30\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - categorical_accuracy: 0.8794 - loss: 0.4895 - val_categorical_accuracy: 0.8813 - val_loss: 0.4643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:36:34,032] Trial 10 finished with value: 0.4612043780975297 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'tanh', 'activation_l3': 'relu', 'batch_size': 209, 'decay_rate': 0.95, 'decay_steps': 1000, 'dropout_l1': 0.4, 'dropout_l2': 0.1, 'dropout_l3': 0.1, 'learning_rate_init': 0.008945829492092518, 'n_units_l1': 93, 'n_units_l2': 4, 'n_units_l3': 11, 'num_layers': 3}. Best is trial 2 with value: 0.368867228042209.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518995.509741  473902 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_667', 596 bytes spill stores, 596 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518995.794504  473901 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_667', 592 bytes spill stores, 592 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518996.029676  473898 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_510', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518996.235838  473896 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_510', 180 bytes spill stores, 180 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m812/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 557us/step - categorical_accuracy: 0.8557 - loss: 0.6133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762518998.527471  473989 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_510', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518998.606348  473985 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_667', 108 bytes spill stores, 108 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762518998.723094  473987 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_667', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.8557 - loss: 0.6132  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519000.400183  474090 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519000.426423  474095 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 68 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519000.432552  474085 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 528 bytes spill stores, 532 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519000.519336  474089 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 1072 bytes spill stores, 1076 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519000.614642  474093 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 540 bytes spill stores, 548 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - categorical_accuracy: 0.8557 - loss: 0.6131 - val_categorical_accuracy: 0.8794 - val_loss: 0.4606\n",
      "Epoch 2/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - categorical_accuracy: 0.8845 - loss: 0.4538 - val_categorical_accuracy: 0.8876 - val_loss: 0.4417\n",
      "Epoch 3/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - categorical_accuracy: 0.8875 - loss: 0.4406 - val_categorical_accuracy: 0.8870 - val_loss: 0.4312\n",
      "Epoch 4/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - categorical_accuracy: 0.8904 - loss: 0.4298 - val_categorical_accuracy: 0.8913 - val_loss: 0.4232\n",
      "Epoch 5/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - categorical_accuracy: 0.8915 - loss: 0.4261 - val_categorical_accuracy: 0.8884 - val_loss: 0.4168\n",
      "Epoch 6/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - categorical_accuracy: 0.8908 - loss: 0.4231 - val_categorical_accuracy: 0.8950 - val_loss: 0.4126\n",
      "Epoch 7/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - categorical_accuracy: 0.8928 - loss: 0.4158 - val_categorical_accuracy: 0.8935 - val_loss: 0.4106\n",
      "Epoch 8/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - categorical_accuracy: 0.8925 - loss: 0.4171 - val_categorical_accuracy: 0.8964 - val_loss: 0.4051\n",
      "Epoch 9/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - categorical_accuracy: 0.8944 - loss: 0.4116 - val_categorical_accuracy: 0.8958 - val_loss: 0.4051\n",
      "Epoch 10/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - categorical_accuracy: 0.8944 - loss: 0.4077 - val_categorical_accuracy: 0.8942 - val_loss: 0.4164\n",
      "Epoch 11/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - categorical_accuracy: 0.8947 - loss: 0.4093 - val_categorical_accuracy: 0.8987 - val_loss: 0.3986\n",
      "Epoch 12/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - categorical_accuracy: 0.8964 - loss: 0.4030 - val_categorical_accuracy: 0.8985 - val_loss: 0.3950\n",
      "Epoch 13/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - categorical_accuracy: 0.8968 - loss: 0.3995 - val_categorical_accuracy: 0.8987 - val_loss: 0.3952\n",
      "Epoch 14/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - categorical_accuracy: 0.8978 - loss: 0.3966 - val_categorical_accuracy: 0.8993 - val_loss: 0.3943\n",
      "Epoch 15/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - categorical_accuracy: 0.8983 - loss: 0.3966 - val_categorical_accuracy: 0.8997 - val_loss: 0.3915\n",
      "Epoch 16/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - categorical_accuracy: 0.8982 - loss: 0.3927 - val_categorical_accuracy: 0.8999 - val_loss: 0.3903\n",
      "Epoch 17/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - categorical_accuracy: 0.8993 - loss: 0.3925 - val_categorical_accuracy: 0.8961 - val_loss: 0.3991\n",
      "Epoch 18/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - categorical_accuracy: 0.8993 - loss: 0.3917 - val_categorical_accuracy: 0.8998 - val_loss: 0.3907\n",
      "Epoch 19/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - categorical_accuracy: 0.8991 - loss: 0.3912 - val_categorical_accuracy: 0.9005 - val_loss: 0.3852\n",
      "Epoch 20/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - categorical_accuracy: 0.8987 - loss: 0.3914 - val_categorical_accuracy: 0.8991 - val_loss: 0.3896\n",
      "Epoch 21/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - categorical_accuracy: 0.9000 - loss: 0.3885 - val_categorical_accuracy: 0.8984 - val_loss: 0.3905\n",
      "Epoch 22/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - categorical_accuracy: 0.9004 - loss: 0.3872 - val_categorical_accuracy: 0.9019 - val_loss: 0.3820\n",
      "Epoch 23/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - categorical_accuracy: 0.9001 - loss: 0.3862 - val_categorical_accuracy: 0.9002 - val_loss: 0.3894\n",
      "Epoch 24/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - categorical_accuracy: 0.9021 - loss: 0.3816 - val_categorical_accuracy: 0.9033 - val_loss: 0.3806\n",
      "Epoch 25/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - categorical_accuracy: 0.9029 - loss: 0.3798 - val_categorical_accuracy: 0.9020 - val_loss: 0.3789\n",
      "Epoch 26/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - categorical_accuracy: 0.9046 - loss: 0.3756 - val_categorical_accuracy: 0.9092 - val_loss: 0.3713\n",
      "Epoch 27/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - categorical_accuracy: 0.9040 - loss: 0.3798 - val_categorical_accuracy: 0.9095 - val_loss: 0.3715\n",
      "Epoch 28/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - categorical_accuracy: 0.9061 - loss: 0.3758 - val_categorical_accuracy: 0.9110 - val_loss: 0.3674\n",
      "Epoch 29/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - categorical_accuracy: 0.9081 - loss: 0.3708 - val_categorical_accuracy: 0.9083 - val_loss: 0.3701\n",
      "Epoch 30/30\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - categorical_accuracy: 0.9088 - loss: 0.3693 - val_categorical_accuracy: 0.9101 - val_loss: 0.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:37:05,257] Trial 11 finished with value: 0.36115995079696805 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'batch_size': 329, 'decay_rate': 0.95, 'decay_steps': 1000, 'dropout_l1': 0.2, 'dropout_l2': 0.0, 'learning_rate_init': 0.00960044620787299, 'n_units_l1': 38, 'n_units_l2': 127, 'num_layers': 2}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519027.086947  475598 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_667', 592 bytes spill stores, 592 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519027.099931  475605 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_510', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519027.217889  475613 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_667', 596 bytes spill stores, 596 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519027.352969  475610 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_510', 180 bytes spill stores, 180 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m861/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 526us/step - categorical_accuracy: 0.8246 - loss: 0.7356"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519029.646725  475697 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_510', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.8269 - loss: 0.7260  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519031.413487  475800 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 500 bytes spill stores, 504 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519031.419230  475810 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 68 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519031.508428  475803 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 752 bytes spill stores, 756 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519031.652570  475802 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 520 bytes spill stores, 528 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - categorical_accuracy: 0.8269 - loss: 0.7258 - val_categorical_accuracy: 0.8797 - val_loss: 0.4794\n",
      "Epoch 2/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - categorical_accuracy: 0.8814 - loss: 0.4749 - val_categorical_accuracy: 0.8851 - val_loss: 0.4526\n",
      "Epoch 3/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - categorical_accuracy: 0.8858 - loss: 0.4522 - val_categorical_accuracy: 0.8868 - val_loss: 0.4459\n",
      "Epoch 4/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - categorical_accuracy: 0.8871 - loss: 0.4442 - val_categorical_accuracy: 0.8878 - val_loss: 0.4368\n",
      "Epoch 5/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686us/step - categorical_accuracy: 0.8894 - loss: 0.4357 - val_categorical_accuracy: 0.8890 - val_loss: 0.4337\n",
      "Epoch 6/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - categorical_accuracy: 0.8890 - loss: 0.4338 - val_categorical_accuracy: 0.8902 - val_loss: 0.4299\n",
      "Epoch 7/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - categorical_accuracy: 0.8902 - loss: 0.4272 - val_categorical_accuracy: 0.8896 - val_loss: 0.4269\n",
      "Epoch 8/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - categorical_accuracy: 0.8902 - loss: 0.4267 - val_categorical_accuracy: 0.8901 - val_loss: 0.4245\n",
      "Epoch 9/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - categorical_accuracy: 0.8903 - loss: 0.4231 - val_categorical_accuracy: 0.8911 - val_loss: 0.4260\n",
      "Epoch 10/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - categorical_accuracy: 0.8921 - loss: 0.4186 - val_categorical_accuracy: 0.8923 - val_loss: 0.4188\n",
      "Epoch 11/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - categorical_accuracy: 0.8927 - loss: 0.4158 - val_categorical_accuracy: 0.8922 - val_loss: 0.4177\n",
      "Epoch 12/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - categorical_accuracy: 0.8927 - loss: 0.4157 - val_categorical_accuracy: 0.8930 - val_loss: 0.4130\n",
      "Epoch 13/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - categorical_accuracy: 0.8932 - loss: 0.4124 - val_categorical_accuracy: 0.8930 - val_loss: 0.4089\n",
      "Epoch 14/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - categorical_accuracy: 0.8932 - loss: 0.4114 - val_categorical_accuracy: 0.8920 - val_loss: 0.4082\n",
      "Epoch 15/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - categorical_accuracy: 0.8936 - loss: 0.4095 - val_categorical_accuracy: 0.8954 - val_loss: 0.4054\n",
      "Epoch 16/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - categorical_accuracy: 0.8954 - loss: 0.4052 - val_categorical_accuracy: 0.8955 - val_loss: 0.4055\n",
      "Epoch 17/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - categorical_accuracy: 0.8960 - loss: 0.4020 - val_categorical_accuracy: 0.8957 - val_loss: 0.4012\n",
      "Epoch 18/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - categorical_accuracy: 0.8974 - loss: 0.3985 - val_categorical_accuracy: 0.8972 - val_loss: 0.3983\n",
      "Epoch 19/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - categorical_accuracy: 0.8964 - loss: 0.4005 - val_categorical_accuracy: 0.8975 - val_loss: 0.3990\n",
      "Epoch 20/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - categorical_accuracy: 0.8972 - loss: 0.3975 - val_categorical_accuracy: 0.8984 - val_loss: 0.3962\n",
      "Epoch 21/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - categorical_accuracy: 0.8985 - loss: 0.3932 - val_categorical_accuracy: 0.8983 - val_loss: 0.3937\n",
      "Epoch 22/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - categorical_accuracy: 0.8973 - loss: 0.3957 - val_categorical_accuracy: 0.8987 - val_loss: 0.3929\n",
      "Epoch 23/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.8981 - loss: 0.3941 - val_categorical_accuracy: 0.8986 - val_loss: 0.3923\n",
      "Epoch 24/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - categorical_accuracy: 0.8990 - loss: 0.3910 - val_categorical_accuracy: 0.8993 - val_loss: 0.3913\n",
      "Epoch 25/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - categorical_accuracy: 0.8985 - loss: 0.3916 - val_categorical_accuracy: 0.8993 - val_loss: 0.3888\n",
      "Epoch 26/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - categorical_accuracy: 0.9004 - loss: 0.3874 - val_categorical_accuracy: 0.9007 - val_loss: 0.3876\n",
      "Epoch 27/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - categorical_accuracy: 0.9002 - loss: 0.3844 - val_categorical_accuracy: 0.8994 - val_loss: 0.3888\n",
      "Epoch 28/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - categorical_accuracy: 0.8994 - loss: 0.3882 - val_categorical_accuracy: 0.8995 - val_loss: 0.3868\n",
      "Epoch 29/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - categorical_accuracy: 0.8998 - loss: 0.3876 - val_categorical_accuracy: 0.9022 - val_loss: 0.3866\n",
      "Epoch 30/30\n",
      "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - categorical_accuracy: 0.9011 - loss: 0.3843 - val_categorical_accuracy: 0.9005 - val_loss: 0.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:37:38,616] Trial 12 finished with value: 0.3807588065068204 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'batch_size': 293, 'decay_rate': 0.95, 'decay_steps': 1000, 'dropout_l1': 0.2, 'dropout_l2': 0.0, 'learning_rate_init': 0.001990572476217005, 'n_units_l1': 56, 'n_units_l2': 127, 'num_layers': 2}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.8521 - loss: 0.6416  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519066.054753  477500 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 240 bytes spill stores, 236 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519066.124705  477486 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 1552 bytes spill stores, 1088 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519066.136900  477490 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 68 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519066.191872  477495 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519066.232732  477494 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 520 bytes spill stores, 464 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519066.290445  477496 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 528 bytes spill stores, 532 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519066.501691  477487 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519066.527700  477492 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 1072 bytes spill stores, 1076 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519066.638092  477487 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519066.766506  477485 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 1208 bytes spill stores, 912 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519066.821730  477491 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 540 bytes spill stores, 548 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519066.958320  477496 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519067.164450  477500 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 484 bytes spill stores, 448 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519067.222281  477490 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519067.304189  477489 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 592 bytes spill stores, 592 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519068.652412  477581 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519068.868420  477577 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 68 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.056113  477579 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.089289  477590 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.115066  477587 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 176 bytes spill stores, 176 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.383385  477580 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 1208 bytes spill stores, 912 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.423509  477588 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.437869  477579 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.543491  477586 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.543492  477590 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 520 bytes spill stores, 464 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.576636  477577 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.624437  477581 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 528 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.701604  477583 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 484 bytes spill stores, 448 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519069.788411  477587 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 592 bytes spill stores, 592 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - categorical_accuracy: 0.8521 - loss: 0.6414 - val_categorical_accuracy: 0.8846 - val_loss: 0.4565\n",
      "Epoch 2/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - categorical_accuracy: 0.8816 - loss: 0.4709 - val_categorical_accuracy: 0.8872 - val_loss: 0.4414\n",
      "Epoch 3/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - categorical_accuracy: 0.8862 - loss: 0.4521 - val_categorical_accuracy: 0.8865 - val_loss: 0.4366\n",
      "Epoch 4/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - categorical_accuracy: 0.8864 - loss: 0.4514 - val_categorical_accuracy: 0.8893 - val_loss: 0.4420\n",
      "Epoch 5/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - categorical_accuracy: 0.8859 - loss: 0.4478 - val_categorical_accuracy: 0.8867 - val_loss: 0.4433\n",
      "Epoch 6/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - categorical_accuracy: 0.8864 - loss: 0.4460 - val_categorical_accuracy: 0.8903 - val_loss: 0.4292\n",
      "Epoch 7/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - categorical_accuracy: 0.8878 - loss: 0.4401 - val_categorical_accuracy: 0.8897 - val_loss: 0.4241\n",
      "Epoch 8/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - categorical_accuracy: 0.8878 - loss: 0.4406 - val_categorical_accuracy: 0.8922 - val_loss: 0.4267\n",
      "Epoch 9/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - categorical_accuracy: 0.8900 - loss: 0.4333 - val_categorical_accuracy: 0.8919 - val_loss: 0.4234\n",
      "Epoch 10/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - categorical_accuracy: 0.8901 - loss: 0.4306 - val_categorical_accuracy: 0.8920 - val_loss: 0.4234\n",
      "Epoch 11/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - categorical_accuracy: 0.8895 - loss: 0.4334 - val_categorical_accuracy: 0.8946 - val_loss: 0.4175\n",
      "Epoch 12/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - categorical_accuracy: 0.8909 - loss: 0.4295 - val_categorical_accuracy: 0.8883 - val_loss: 0.4264\n",
      "Epoch 13/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - categorical_accuracy: 0.8905 - loss: 0.4285 - val_categorical_accuracy: 0.8902 - val_loss: 0.4206\n",
      "Epoch 14/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - categorical_accuracy: 0.8902 - loss: 0.4270 - val_categorical_accuracy: 0.8883 - val_loss: 0.4202\n",
      "Epoch 15/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - categorical_accuracy: 0.8911 - loss: 0.4272 - val_categorical_accuracy: 0.8941 - val_loss: 0.4135\n",
      "Epoch 16/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - categorical_accuracy: 0.8924 - loss: 0.4193 - val_categorical_accuracy: 0.8943 - val_loss: 0.4101\n",
      "Epoch 17/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - categorical_accuracy: 0.8912 - loss: 0.4233 - val_categorical_accuracy: 0.8961 - val_loss: 0.4073\n",
      "Epoch 18/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - categorical_accuracy: 0.8926 - loss: 0.4205 - val_categorical_accuracy: 0.8964 - val_loss: 0.4009\n",
      "Epoch 19/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - categorical_accuracy: 0.8932 - loss: 0.4150 - val_categorical_accuracy: 0.8967 - val_loss: 0.4008\n",
      "Epoch 20/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - categorical_accuracy: 0.8943 - loss: 0.4118 - val_categorical_accuracy: 0.8968 - val_loss: 0.4028\n",
      "Epoch 21/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - categorical_accuracy: 0.8942 - loss: 0.4127 - val_categorical_accuracy: 0.8961 - val_loss: 0.4021\n",
      "Epoch 22/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - categorical_accuracy: 0.8929 - loss: 0.4169 - val_categorical_accuracy: 0.8978 - val_loss: 0.3967\n",
      "Epoch 23/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - categorical_accuracy: 0.8940 - loss: 0.4116 - val_categorical_accuracy: 0.8983 - val_loss: 0.3961\n",
      "Epoch 24/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - categorical_accuracy: 0.8942 - loss: 0.4131 - val_categorical_accuracy: 0.8992 - val_loss: 0.3945\n",
      "Epoch 25/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - categorical_accuracy: 0.8947 - loss: 0.4096 - val_categorical_accuracy: 0.8977 - val_loss: 0.3944\n",
      "Epoch 26/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - categorical_accuracy: 0.8957 - loss: 0.4077 - val_categorical_accuracy: 0.8993 - val_loss: 0.3917\n",
      "Epoch 27/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - categorical_accuracy: 0.8965 - loss: 0.4022 - val_categorical_accuracy: 0.8948 - val_loss: 0.3970\n",
      "Epoch 28/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - categorical_accuracy: 0.8963 - loss: 0.4034 - val_categorical_accuracy: 0.8994 - val_loss: 0.3874\n",
      "Epoch 29/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - categorical_accuracy: 0.8965 - loss: 0.4017 - val_categorical_accuracy: 0.8997 - val_loss: 0.3877\n",
      "Epoch 30/30\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - categorical_accuracy: 0.8967 - loss: 0.4010 - val_categorical_accuracy: 0.8993 - val_loss: 0.3879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:38:18,046] Trial 13 finished with value: 0.3853713263389045 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'activation_l3': 'relu', 'batch_size': 285, 'decay_rate': 0.95, 'decay_steps': 1500, 'dropout_l1': 0.30000000000000004, 'dropout_l2': 0.1, 'dropout_l3': 0.2, 'learning_rate_init': 0.008869021640484778, 'n_units_l1': 38, 'n_units_l2': 113, 'n_units_l3': 86, 'num_layers': 3}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - categorical_accuracy: 0.8079 - loss: 0.8146 - val_categorical_accuracy: 0.8779 - val_loss: 0.4977\n",
      "Epoch 2/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - categorical_accuracy: 0.8774 - loss: 0.5067 - val_categorical_accuracy: 0.8792 - val_loss: 0.4725\n",
      "Epoch 3/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - categorical_accuracy: 0.8800 - loss: 0.4823 - val_categorical_accuracy: 0.8811 - val_loss: 0.4599\n",
      "Epoch 4/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.8821 - loss: 0.4712 - val_categorical_accuracy: 0.8855 - val_loss: 0.4528\n",
      "Epoch 5/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - categorical_accuracy: 0.8840 - loss: 0.4619 - val_categorical_accuracy: 0.8870 - val_loss: 0.4463\n",
      "Epoch 6/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - categorical_accuracy: 0.8852 - loss: 0.4561 - val_categorical_accuracy: 0.8859 - val_loss: 0.4450\n",
      "Epoch 7/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - categorical_accuracy: 0.8861 - loss: 0.4513 - val_categorical_accuracy: 0.8873 - val_loss: 0.4459\n",
      "Epoch 8/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - categorical_accuracy: 0.8853 - loss: 0.4517 - val_categorical_accuracy: 0.8880 - val_loss: 0.4406\n",
      "Epoch 9/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - categorical_accuracy: 0.8859 - loss: 0.4501 - val_categorical_accuracy: 0.8881 - val_loss: 0.4398\n",
      "Epoch 10/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.8863 - loss: 0.4476 - val_categorical_accuracy: 0.8882 - val_loss: 0.4405\n",
      "Epoch 11/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - categorical_accuracy: 0.8874 - loss: 0.4440 - val_categorical_accuracy: 0.8880 - val_loss: 0.4399\n",
      "Epoch 12/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - categorical_accuracy: 0.8863 - loss: 0.4489 - val_categorical_accuracy: 0.8887 - val_loss: 0.4382\n",
      "Epoch 13/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - categorical_accuracy: 0.8875 - loss: 0.4420 - val_categorical_accuracy: 0.8887 - val_loss: 0.4374\n",
      "Epoch 14/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - categorical_accuracy: 0.8867 - loss: 0.4476 - val_categorical_accuracy: 0.8889 - val_loss: 0.4373\n",
      "Epoch 15/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - categorical_accuracy: 0.8872 - loss: 0.4468 - val_categorical_accuracy: 0.8892 - val_loss: 0.4371\n",
      "Epoch 16/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - categorical_accuracy: 0.8873 - loss: 0.4436 - val_categorical_accuracy: 0.8892 - val_loss: 0.4367\n",
      "Epoch 17/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - categorical_accuracy: 0.8868 - loss: 0.4456 - val_categorical_accuracy: 0.8893 - val_loss: 0.4367\n",
      "Epoch 18/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - categorical_accuracy: 0.8867 - loss: 0.4436 - val_categorical_accuracy: 0.8893 - val_loss: 0.4357\n",
      "Epoch 19/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - categorical_accuracy: 0.8872 - loss: 0.4434 - val_categorical_accuracy: 0.8893 - val_loss: 0.4358\n",
      "Epoch 20/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - categorical_accuracy: 0.8874 - loss: 0.4449 - val_categorical_accuracy: 0.8895 - val_loss: 0.4356\n",
      "Epoch 21/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - categorical_accuracy: 0.8867 - loss: 0.4442 - val_categorical_accuracy: 0.8891 - val_loss: 0.4359\n",
      "Epoch 22/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.8868 - loss: 0.4447 - val_categorical_accuracy: 0.8893 - val_loss: 0.4352\n",
      "Epoch 23/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - categorical_accuracy: 0.8869 - loss: 0.4438 - val_categorical_accuracy: 0.8892 - val_loss: 0.4356\n",
      "Epoch 24/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - categorical_accuracy: 0.8872 - loss: 0.4431 - val_categorical_accuracy: 0.8892 - val_loss: 0.4356\n",
      "Epoch 25/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - categorical_accuracy: 0.8876 - loss: 0.4411 - val_categorical_accuracy: 0.8893 - val_loss: 0.4354\n",
      "Epoch 26/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - categorical_accuracy: 0.8866 - loss: 0.4438 - val_categorical_accuracy: 0.8893 - val_loss: 0.4351\n",
      "Epoch 27/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - categorical_accuracy: 0.8868 - loss: 0.4439 - val_categorical_accuracy: 0.8892 - val_loss: 0.4352\n",
      "Epoch 28/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - categorical_accuracy: 0.8875 - loss: 0.4413 - val_categorical_accuracy: 0.8894 - val_loss: 0.4350\n",
      "Epoch 29/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - categorical_accuracy: 0.8875 - loss: 0.4423 - val_categorical_accuracy: 0.8894 - val_loss: 0.4352\n",
      "Epoch 30/30\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - categorical_accuracy: 0.8877 - loss: 0.4424 - val_categorical_accuracy: 0.8893 - val_loss: 0.4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:39:02,283] Trial 14 finished with value: 0.4318401894659191 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'batch_size': 167, 'decay_rate': 0.9, 'decay_steps': 1000, 'dropout_l1': 0.2, 'dropout_l2': 0.1, 'learning_rate_init': 0.0014865159419283438, 'n_units_l1': 13, 'n_units_l2': 84, 'num_layers': 2}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519143.837445  480896 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519144.103846  480892 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 688 bytes spill stores, 816 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519144.232902  480894 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 424 bytes spill stores, 548 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519144.406027  480898 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 276 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519144.536130  480896 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 52 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519144.760779  480897 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 1176 bytes spill stores, 1176 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519144.844108  480890 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519145.983370  480902 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1121', 108 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519146.014063  480888 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1121', 552 bytes spill stores, 556 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519146.282226  480899 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1121', 268 bytes spill stores, 280 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m895/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 563us/step - categorical_accuracy: 0.8584 - loss: 0.6076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519148.888946  481029 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519149.263072  481034 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 424 bytes spill stores, 548 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519149.653506  481033 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 52 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519149.713742  481031 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519149.970270  481026 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1121', 552 bytes spill stores, 556 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519150.191231  481024 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 1176 bytes spill stores, 1176 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519150.218984  481028 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 688 bytes spill stores, 816 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519150.399184  481031 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 276 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519150.517083  481027 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1121', 76 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519151.387565  481032 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1121', 344 bytes spill stores, 356 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - categorical_accuracy: 0.8590 - loss: 0.6049  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519153.250905  481171 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519154.224629  481254 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519154.455714  481250 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 32 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519154.584132  481240 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 276 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519154.654729  481249 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 484 bytes spill stores, 484 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519154.667809  481241 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 52 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519154.752375  481247 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 688 bytes spill stores, 816 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519154.851689  481244 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - categorical_accuracy: 0.8590 - loss: 0.6048 - val_categorical_accuracy: 0.8863 - val_loss: 0.4470\n",
      "Epoch 2/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - categorical_accuracy: 0.8855 - loss: 0.4562 - val_categorical_accuracy: 0.8858 - val_loss: 0.4403\n",
      "Epoch 3/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - categorical_accuracy: 0.8878 - loss: 0.4434 - val_categorical_accuracy: 0.8905 - val_loss: 0.4271\n",
      "Epoch 4/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - categorical_accuracy: 0.8882 - loss: 0.4411 - val_categorical_accuracy: 0.8839 - val_loss: 0.4356\n",
      "Epoch 5/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - categorical_accuracy: 0.8897 - loss: 0.4322 - val_categorical_accuracy: 0.8940 - val_loss: 0.4135\n",
      "Epoch 6/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - categorical_accuracy: 0.8916 - loss: 0.4222 - val_categorical_accuracy: 0.8931 - val_loss: 0.4118\n",
      "Epoch 7/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - categorical_accuracy: 0.8931 - loss: 0.4191 - val_categorical_accuracy: 0.8920 - val_loss: 0.4121\n",
      "Epoch 8/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - categorical_accuracy: 0.8931 - loss: 0.4159 - val_categorical_accuracy: 0.8931 - val_loss: 0.4122\n",
      "Epoch 9/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - categorical_accuracy: 0.8943 - loss: 0.4110 - val_categorical_accuracy: 0.8972 - val_loss: 0.4017\n",
      "Epoch 10/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - categorical_accuracy: 0.8951 - loss: 0.4081 - val_categorical_accuracy: 0.8957 - val_loss: 0.4065\n",
      "Epoch 11/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - categorical_accuracy: 0.8961 - loss: 0.4065 - val_categorical_accuracy: 0.8968 - val_loss: 0.3985\n",
      "Epoch 12/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - categorical_accuracy: 0.8956 - loss: 0.4060 - val_categorical_accuracy: 0.8974 - val_loss: 0.4043\n",
      "Epoch 13/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - categorical_accuracy: 0.8962 - loss: 0.4031 - val_categorical_accuracy: 0.8986 - val_loss: 0.3924\n",
      "Epoch 14/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - categorical_accuracy: 0.8968 - loss: 0.3991 - val_categorical_accuracy: 0.8984 - val_loss: 0.3931\n",
      "Epoch 15/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - categorical_accuracy: 0.8968 - loss: 0.4004 - val_categorical_accuracy: 0.8985 - val_loss: 0.3912\n",
      "Epoch 16/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - categorical_accuracy: 0.8980 - loss: 0.3954 - val_categorical_accuracy: 0.8988 - val_loss: 0.3928\n",
      "Epoch 17/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - categorical_accuracy: 0.8982 - loss: 0.3948 - val_categorical_accuracy: 0.8990 - val_loss: 0.3905\n",
      "Epoch 18/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - categorical_accuracy: 0.8985 - loss: 0.3937 - val_categorical_accuracy: 0.8991 - val_loss: 0.3854\n",
      "Epoch 19/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - categorical_accuracy: 0.8968 - loss: 0.3979 - val_categorical_accuracy: 0.8995 - val_loss: 0.3923\n",
      "Epoch 20/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - categorical_accuracy: 0.8986 - loss: 0.3944 - val_categorical_accuracy: 0.9005 - val_loss: 0.3937\n",
      "Epoch 21/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - categorical_accuracy: 0.9001 - loss: 0.3896 - val_categorical_accuracy: 0.9014 - val_loss: 0.3838\n",
      "Epoch 22/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - categorical_accuracy: 0.9013 - loss: 0.3868 - val_categorical_accuracy: 0.9057 - val_loss: 0.3797\n",
      "Epoch 23/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.9019 - loss: 0.3855 - val_categorical_accuracy: 0.9006 - val_loss: 0.3823\n",
      "Epoch 24/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - categorical_accuracy: 0.9024 - loss: 0.3839 - val_categorical_accuracy: 0.9045 - val_loss: 0.3820\n",
      "Epoch 25/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.9040 - loss: 0.3803 - val_categorical_accuracy: 0.9090 - val_loss: 0.3716\n",
      "Epoch 26/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - categorical_accuracy: 0.9049 - loss: 0.3789 - val_categorical_accuracy: 0.9102 - val_loss: 0.3651\n",
      "Epoch 27/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - categorical_accuracy: 0.9057 - loss: 0.3764 - val_categorical_accuracy: 0.9102 - val_loss: 0.3616\n",
      "Epoch 28/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - categorical_accuracy: 0.9070 - loss: 0.3743 - val_categorical_accuracy: 0.9117 - val_loss: 0.3601\n",
      "Epoch 29/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - categorical_accuracy: 0.9072 - loss: 0.3725 - val_categorical_accuracy: 0.9100 - val_loss: 0.3643\n",
      "Epoch 30/30\n",
      "\u001b[1m922/922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - categorical_accuracy: 0.9082 - loss: 0.3700 - val_categorical_accuracy: 0.9081 - val_loss: 0.3762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519174.469240  482622 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_16', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:39:41,109] Trial 15 finished with value: 0.37182866959188166 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'tanh', 'activation_l3': 'relu', 'batch_size': 290, 'decay_rate': 0.95, 'decay_steps': 1500, 'dropout_l1': 0.0, 'dropout_l2': 0.2, 'dropout_l3': 0.2, 'learning_rate_init': 0.003436908564399907, 'n_units_l1': 65, 'n_units_l2': 128, 'n_units_l3': 116, 'num_layers': 3}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519183.065742  482888 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_667', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - categorical_accuracy: 0.8223 - loss: 0.7581  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519186.768447  483042 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 436 bytes spill stores, 476 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519186.849432  483044 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519186.883517  483048 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 524 bytes spill stores, 524 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519186.884472  483049 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519186.998616  483051 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 244 bytes spill stores, 244 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519187.437320  483045 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 552 bytes spill stores, 612 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519188.305554  483081 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519188.626050  483086 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 428 bytes spill stores, 460 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519188.784570  483083 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519188.791614  483085 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 244 bytes spill stores, 244 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519188.974828  483089 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 524 bytes spill stores, 524 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519189.213653  483088 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 552 bytes spill stores, 612 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - categorical_accuracy: 0.8223 - loss: 0.7580 - val_categorical_accuracy: 0.8778 - val_loss: 0.4970\n",
      "Epoch 2/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - categorical_accuracy: 0.8788 - loss: 0.4995 - val_categorical_accuracy: 0.8797 - val_loss: 0.4721\n",
      "Epoch 3/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - categorical_accuracy: 0.8807 - loss: 0.4775 - val_categorical_accuracy: 0.8823 - val_loss: 0.4562\n",
      "Epoch 4/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - categorical_accuracy: 0.8848 - loss: 0.4575 - val_categorical_accuracy: 0.8859 - val_loss: 0.4457\n",
      "Epoch 5/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - categorical_accuracy: 0.8857 - loss: 0.4503 - val_categorical_accuracy: 0.8865 - val_loss: 0.4410\n",
      "Epoch 6/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - categorical_accuracy: 0.8864 - loss: 0.4458 - val_categorical_accuracy: 0.8894 - val_loss: 0.4393\n",
      "Epoch 7/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - categorical_accuracy: 0.8882 - loss: 0.4388 - val_categorical_accuracy: 0.8875 - val_loss: 0.4351\n",
      "Epoch 8/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - categorical_accuracy: 0.8885 - loss: 0.4380 - val_categorical_accuracy: 0.8905 - val_loss: 0.4342\n",
      "Epoch 9/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - categorical_accuracy: 0.8881 - loss: 0.4379 - val_categorical_accuracy: 0.8877 - val_loss: 0.4354\n",
      "Epoch 10/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - categorical_accuracy: 0.8882 - loss: 0.4366 - val_categorical_accuracy: 0.8905 - val_loss: 0.4315\n",
      "Epoch 11/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - categorical_accuracy: 0.8891 - loss: 0.4324 - val_categorical_accuracy: 0.8907 - val_loss: 0.4300\n",
      "Epoch 12/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - categorical_accuracy: 0.8891 - loss: 0.4323 - val_categorical_accuracy: 0.8908 - val_loss: 0.4291\n",
      "Epoch 13/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - categorical_accuracy: 0.8890 - loss: 0.4322 - val_categorical_accuracy: 0.8909 - val_loss: 0.4287\n",
      "Epoch 14/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - categorical_accuracy: 0.8881 - loss: 0.4348 - val_categorical_accuracy: 0.8907 - val_loss: 0.4282\n",
      "Epoch 15/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - categorical_accuracy: 0.8896 - loss: 0.4298 - val_categorical_accuracy: 0.8907 - val_loss: 0.4280\n",
      "Epoch 16/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - categorical_accuracy: 0.8901 - loss: 0.4291 - val_categorical_accuracy: 0.8902 - val_loss: 0.4277\n",
      "Epoch 17/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - categorical_accuracy: 0.8891 - loss: 0.4311 - val_categorical_accuracy: 0.8911 - val_loss: 0.4274\n",
      "Epoch 18/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - categorical_accuracy: 0.8898 - loss: 0.4287 - val_categorical_accuracy: 0.8907 - val_loss: 0.4276\n",
      "Epoch 19/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - categorical_accuracy: 0.8904 - loss: 0.4273 - val_categorical_accuracy: 0.8903 - val_loss: 0.4274\n",
      "Epoch 20/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - categorical_accuracy: 0.8904 - loss: 0.4261 - val_categorical_accuracy: 0.8909 - val_loss: 0.4270\n",
      "Epoch 21/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8902 - loss: 0.4288 - val_categorical_accuracy: 0.8909 - val_loss: 0.4266\n",
      "Epoch 22/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - categorical_accuracy: 0.8904 - loss: 0.4265 - val_categorical_accuracy: 0.8907 - val_loss: 0.4268\n",
      "Epoch 23/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - categorical_accuracy: 0.8895 - loss: 0.4298 - val_categorical_accuracy: 0.8907 - val_loss: 0.4266\n",
      "Epoch 24/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - categorical_accuracy: 0.8898 - loss: 0.4284 - val_categorical_accuracy: 0.8906 - val_loss: 0.4266\n",
      "Epoch 25/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - categorical_accuracy: 0.8911 - loss: 0.4252 - val_categorical_accuracy: 0.8909 - val_loss: 0.4263\n",
      "Epoch 26/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - categorical_accuracy: 0.8899 - loss: 0.4282 - val_categorical_accuracy: 0.8909 - val_loss: 0.4262\n",
      "Epoch 27/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - categorical_accuracy: 0.8899 - loss: 0.4281 - val_categorical_accuracy: 0.8907 - val_loss: 0.4263\n",
      "Epoch 28/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - categorical_accuracy: 0.8897 - loss: 0.4270 - val_categorical_accuracy: 0.8909 - val_loss: 0.4261\n",
      "Epoch 29/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - categorical_accuracy: 0.8907 - loss: 0.4252 - val_categorical_accuracy: 0.8908 - val_loss: 0.4262\n",
      "Epoch 30/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - categorical_accuracy: 0.8905 - loss: 0.4272 - val_categorical_accuracy: 0.8909 - val_loss: 0.4261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:40:25,662] Trial 16 finished with value: 0.42235913169074485 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'batch_size': 190, 'decay_rate': 0.9, 'decay_steps': 1000, 'dropout_l1': 0.4, 'dropout_l2': 0.0, 'learning_rate_init': 0.00107368674340075, 'n_units_l1': 87, 'n_units_l2': 70, 'num_layers': 2}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519227.601191  484760 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_895', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519227.793359  484762 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1052', 592 bytes spill stores, 592 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m662/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 845us/step - categorical_accuracy: 0.8103 - loss: 0.7956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519230.767698  484900 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1052', 592 bytes spill stores, 592 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519231.170171  484903 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_895', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.8158 - loss: 0.7737  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519232.726201  485001 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519232.810337  484994 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 536 bytes spill stores, 536 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519233.829762  485066 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_60', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - categorical_accuracy: 0.8159 - loss: 0.7735 - val_categorical_accuracy: 0.8786 - val_loss: 0.4937\n",
      "Epoch 2/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8776 - loss: 0.5014 - val_categorical_accuracy: 0.8833 - val_loss: 0.4585\n",
      "Epoch 3/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - categorical_accuracy: 0.8802 - loss: 0.4793 - val_categorical_accuracy: 0.8870 - val_loss: 0.4443\n",
      "Epoch 4/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - categorical_accuracy: 0.8807 - loss: 0.4733 - val_categorical_accuracy: 0.8874 - val_loss: 0.4430\n",
      "Epoch 5/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - categorical_accuracy: 0.8838 - loss: 0.4584 - val_categorical_accuracy: 0.8888 - val_loss: 0.4395\n",
      "Epoch 6/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - categorical_accuracy: 0.8840 - loss: 0.4581 - val_categorical_accuracy: 0.8886 - val_loss: 0.4345\n",
      "Epoch 7/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - categorical_accuracy: 0.8858 - loss: 0.4503 - val_categorical_accuracy: 0.8906 - val_loss: 0.4296\n",
      "Epoch 8/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - categorical_accuracy: 0.8867 - loss: 0.4448 - val_categorical_accuracy: 0.8906 - val_loss: 0.4290\n",
      "Epoch 9/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - categorical_accuracy: 0.8882 - loss: 0.4422 - val_categorical_accuracy: 0.8902 - val_loss: 0.4313\n",
      "Epoch 10/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - categorical_accuracy: 0.8867 - loss: 0.4447 - val_categorical_accuracy: 0.8894 - val_loss: 0.4305\n",
      "Epoch 11/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - categorical_accuracy: 0.8886 - loss: 0.4371 - val_categorical_accuracy: 0.8857 - val_loss: 0.4324\n",
      "Epoch 12/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - categorical_accuracy: 0.8887 - loss: 0.4376 - val_categorical_accuracy: 0.8898 - val_loss: 0.4296\n",
      "Epoch 13/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - categorical_accuracy: 0.8877 - loss: 0.4385 - val_categorical_accuracy: 0.8897 - val_loss: 0.4303\n",
      "Epoch 14/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - categorical_accuracy: 0.8889 - loss: 0.4345 - val_categorical_accuracy: 0.8868 - val_loss: 0.4221\n",
      "Epoch 15/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.8884 - loss: 0.4352 - val_categorical_accuracy: 0.8896 - val_loss: 0.4257\n",
      "Epoch 16/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - categorical_accuracy: 0.8897 - loss: 0.4320 - val_categorical_accuracy: 0.8911 - val_loss: 0.4224\n",
      "Epoch 17/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - categorical_accuracy: 0.8890 - loss: 0.4343 - val_categorical_accuracy: 0.8910 - val_loss: 0.4214\n",
      "Epoch 18/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - categorical_accuracy: 0.8901 - loss: 0.4287 - val_categorical_accuracy: 0.8914 - val_loss: 0.4243\n",
      "Epoch 19/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - categorical_accuracy: 0.8900 - loss: 0.4305 - val_categorical_accuracy: 0.8912 - val_loss: 0.4190\n",
      "Epoch 20/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step - categorical_accuracy: 0.8895 - loss: 0.4302 - val_categorical_accuracy: 0.8877 - val_loss: 0.4367\n",
      "Epoch 21/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - categorical_accuracy: 0.8906 - loss: 0.4291 - val_categorical_accuracy: 0.8925 - val_loss: 0.4163\n",
      "Epoch 22/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - categorical_accuracy: 0.8908 - loss: 0.4267 - val_categorical_accuracy: 0.8906 - val_loss: 0.4209\n",
      "Epoch 23/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - categorical_accuracy: 0.8909 - loss: 0.4272 - val_categorical_accuracy: 0.8919 - val_loss: 0.4210\n",
      "Epoch 24/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - categorical_accuracy: 0.8906 - loss: 0.4277 - val_categorical_accuracy: 0.8942 - val_loss: 0.4191\n",
      "Epoch 25/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1000us/step - categorical_accuracy: 0.8910 - loss: 0.4252 - val_categorical_accuracy: 0.8940 - val_loss: 0.4189\n",
      "Epoch 26/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - categorical_accuracy: 0.8906 - loss: 0.4240 - val_categorical_accuracy: 0.8931 - val_loss: 0.4185\n",
      "Epoch 27/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - categorical_accuracy: 0.8904 - loss: 0.4264 - val_categorical_accuracy: 0.8882 - val_loss: 0.4225\n",
      "Epoch 28/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - categorical_accuracy: 0.8915 - loss: 0.4249 - val_categorical_accuracy: 0.8950 - val_loss: 0.4126\n",
      "Epoch 29/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - categorical_accuracy: 0.8905 - loss: 0.4264 - val_categorical_accuracy: 0.8945 - val_loss: 0.4132\n",
      "Epoch 30/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - categorical_accuracy: 0.8921 - loss: 0.4202 - val_categorical_accuracy: 0.8936 - val_loss: 0.4171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:40:58,922] Trial 17 finished with value: 0.41421862547337257 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'activation_l3': 'tanh', 'batch_size': 357, 'decay_rate': 0.95, 'decay_steps': 2000, 'dropout_l1': 0.1, 'dropout_l2': 0.4, 'dropout_l3': 0.0, 'learning_rate_init': 0.0036857034803454785, 'n_units_l1': 42, 'n_units_l2': 26, 'n_units_l3': 57, 'num_layers': 3}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519260.541671  486544 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1008', 584 bytes spill stores, 584 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519260.574252  486549 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1008', 588 bytes spill stores, 588 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.7919 - loss: 0.8749  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519264.870624  486684 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519264.923664  486689 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519264.999357  486688 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 436 bytes spill stores, 440 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519265.070915  486694 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 476 bytes spill stores, 476 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519265.299479  486689 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 228 bytes spill stores, 228 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519265.336267  486699 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 292 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519265.357749  486698 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 1644 bytes spill stores, 1132 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519265.419415  486685 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 316 bytes spill stores, 308 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - categorical_accuracy: 0.7920 - loss: 0.8747 - val_categorical_accuracy: 0.8772 - val_loss: 0.5113\n",
      "Epoch 2/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - categorical_accuracy: 0.8775 - loss: 0.5245 - val_categorical_accuracy: 0.8786 - val_loss: 0.4855\n",
      "Epoch 3/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - categorical_accuracy: 0.8790 - loss: 0.5002 - val_categorical_accuracy: 0.8799 - val_loss: 0.4682\n",
      "Epoch 4/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - categorical_accuracy: 0.8807 - loss: 0.4823 - val_categorical_accuracy: 0.8805 - val_loss: 0.4581\n",
      "Epoch 5/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - categorical_accuracy: 0.8835 - loss: 0.4697 - val_categorical_accuracy: 0.8865 - val_loss: 0.4507\n",
      "Epoch 6/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - categorical_accuracy: 0.8848 - loss: 0.4629 - val_categorical_accuracy: 0.8886 - val_loss: 0.4444\n",
      "Epoch 7/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - categorical_accuracy: 0.8851 - loss: 0.4589 - val_categorical_accuracy: 0.8888 - val_loss: 0.4396\n",
      "Epoch 8/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - categorical_accuracy: 0.8863 - loss: 0.4541 - val_categorical_accuracy: 0.8885 - val_loss: 0.4387\n",
      "Epoch 9/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - categorical_accuracy: 0.8870 - loss: 0.4482 - val_categorical_accuracy: 0.8900 - val_loss: 0.4344\n",
      "Epoch 10/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - categorical_accuracy: 0.8877 - loss: 0.4459 - val_categorical_accuracy: 0.8901 - val_loss: 0.4330\n",
      "Epoch 11/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - categorical_accuracy: 0.8878 - loss: 0.4426 - val_categorical_accuracy: 0.8889 - val_loss: 0.4333\n",
      "Epoch 12/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - categorical_accuracy: 0.8880 - loss: 0.4415 - val_categorical_accuracy: 0.8898 - val_loss: 0.4307\n",
      "Epoch 13/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - categorical_accuracy: 0.8894 - loss: 0.4352 - val_categorical_accuracy: 0.8898 - val_loss: 0.4295\n",
      "Epoch 14/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - categorical_accuracy: 0.8893 - loss: 0.4367 - val_categorical_accuracy: 0.8905 - val_loss: 0.4288\n",
      "Epoch 15/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - categorical_accuracy: 0.8897 - loss: 0.4354 - val_categorical_accuracy: 0.8909 - val_loss: 0.4285\n",
      "Epoch 16/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - categorical_accuracy: 0.8892 - loss: 0.4392 - val_categorical_accuracy: 0.8903 - val_loss: 0.4279\n",
      "Epoch 17/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - categorical_accuracy: 0.8888 - loss: 0.4351 - val_categorical_accuracy: 0.8910 - val_loss: 0.4269\n",
      "Epoch 18/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - categorical_accuracy: 0.8900 - loss: 0.4338 - val_categorical_accuracy: 0.8909 - val_loss: 0.4260\n",
      "Epoch 19/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - categorical_accuracy: 0.8906 - loss: 0.4312 - val_categorical_accuracy: 0.8902 - val_loss: 0.4260\n",
      "Epoch 20/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8902 - loss: 0.4308 - val_categorical_accuracy: 0.8900 - val_loss: 0.4259\n",
      "Epoch 21/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - categorical_accuracy: 0.8898 - loss: 0.4318 - val_categorical_accuracy: 0.8912 - val_loss: 0.4249\n",
      "Epoch 22/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - categorical_accuracy: 0.8896 - loss: 0.4322 - val_categorical_accuracy: 0.8911 - val_loss: 0.4251\n",
      "Epoch 23/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - categorical_accuracy: 0.8910 - loss: 0.4298 - val_categorical_accuracy: 0.8903 - val_loss: 0.4253\n",
      "Epoch 24/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - categorical_accuracy: 0.8899 - loss: 0.4311 - val_categorical_accuracy: 0.8909 - val_loss: 0.4246\n",
      "Epoch 25/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - categorical_accuracy: 0.8908 - loss: 0.4280 - val_categorical_accuracy: 0.8910 - val_loss: 0.4239\n",
      "Epoch 26/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - categorical_accuracy: 0.8908 - loss: 0.4266 - val_categorical_accuracy: 0.8910 - val_loss: 0.4238\n",
      "Epoch 27/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756us/step - categorical_accuracy: 0.8901 - loss: 0.4297 - val_categorical_accuracy: 0.8912 - val_loss: 0.4236\n",
      "Epoch 28/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - categorical_accuracy: 0.8904 - loss: 0.4278 - val_categorical_accuracy: 0.8907 - val_loss: 0.4234\n",
      "Epoch 29/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - categorical_accuracy: 0.8907 - loss: 0.4286 - val_categorical_accuracy: 0.8910 - val_loss: 0.4232\n",
      "Epoch 30/30\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - categorical_accuracy: 0.8905 - loss: 0.4284 - val_categorical_accuracy: 0.8913 - val_loss: 0.4226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:41:36,617] Trial 18 finished with value: 0.4191395470716851 and parameters: {'activation_l1': 'relu', 'activation_l2': 'relu', 'batch_size': 253, 'decay_rate': 0.9, 'decay_steps': 1500, 'dropout_l1': 0.2, 'dropout_l2': 0.30000000000000004, 'learning_rate_init': 0.000853799657394685, 'n_units_l1': 67, 'n_units_l2': 109, 'num_layers': 2}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.8474 - loss: 0.6610  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519303.475851  488429 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519303.518970  488433 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_60', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519303.619870  488434 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 408 bytes spill stores, 420 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519303.830706  488436 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 244 bytes spill stores, 244 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519303.891428  488426 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519303.954893  488430 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 532 bytes spill stores, 532 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519304.281448  488439 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 512 bytes spill stores, 580 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - categorical_accuracy: 0.8474 - loss: 0.6609 - val_categorical_accuracy: 0.8788 - val_loss: 0.4774\n",
      "Epoch 2/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - categorical_accuracy: 0.8768 - loss: 0.5002 - val_categorical_accuracy: 0.8853 - val_loss: 0.4559\n",
      "Epoch 3/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - categorical_accuracy: 0.8797 - loss: 0.4813 - val_categorical_accuracy: 0.8852 - val_loss: 0.4555\n",
      "Epoch 4/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - categorical_accuracy: 0.8805 - loss: 0.4745 - val_categorical_accuracy: 0.8865 - val_loss: 0.4468\n",
      "Epoch 5/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - categorical_accuracy: 0.8821 - loss: 0.4677 - val_categorical_accuracy: 0.8885 - val_loss: 0.4399\n",
      "Epoch 6/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - categorical_accuracy: 0.8845 - loss: 0.4574 - val_categorical_accuracy: 0.8888 - val_loss: 0.4371\n",
      "Epoch 7/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - categorical_accuracy: 0.8843 - loss: 0.4591 - val_categorical_accuracy: 0.8842 - val_loss: 0.4468\n",
      "Epoch 8/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - categorical_accuracy: 0.8831 - loss: 0.4598 - val_categorical_accuracy: 0.8883 - val_loss: 0.4382\n",
      "Epoch 9/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - categorical_accuracy: 0.8860 - loss: 0.4501 - val_categorical_accuracy: 0.8894 - val_loss: 0.4377\n",
      "Epoch 10/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - categorical_accuracy: 0.8849 - loss: 0.4529 - val_categorical_accuracy: 0.8901 - val_loss: 0.4287\n",
      "Epoch 11/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - categorical_accuracy: 0.8868 - loss: 0.4455 - val_categorical_accuracy: 0.8897 - val_loss: 0.4270\n",
      "Epoch 12/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - categorical_accuracy: 0.8872 - loss: 0.4449 - val_categorical_accuracy: 0.8909 - val_loss: 0.4300\n",
      "Epoch 13/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - categorical_accuracy: 0.8875 - loss: 0.4440 - val_categorical_accuracy: 0.8898 - val_loss: 0.4264\n",
      "Epoch 14/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - categorical_accuracy: 0.8890 - loss: 0.4386 - val_categorical_accuracy: 0.8909 - val_loss: 0.4268\n",
      "Epoch 15/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - categorical_accuracy: 0.8874 - loss: 0.4425 - val_categorical_accuracy: 0.8891 - val_loss: 0.4286\n",
      "Epoch 16/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - categorical_accuracy: 0.8877 - loss: 0.4412 - val_categorical_accuracy: 0.8905 - val_loss: 0.4220\n",
      "Epoch 17/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - categorical_accuracy: 0.8899 - loss: 0.4344 - val_categorical_accuracy: 0.8896 - val_loss: 0.4240\n",
      "Epoch 18/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - categorical_accuracy: 0.8895 - loss: 0.4335 - val_categorical_accuracy: 0.8906 - val_loss: 0.4215\n",
      "Epoch 19/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - categorical_accuracy: 0.8897 - loss: 0.4347 - val_categorical_accuracy: 0.8867 - val_loss: 0.4299\n",
      "Epoch 20/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - categorical_accuracy: 0.8891 - loss: 0.4342 - val_categorical_accuracy: 0.8905 - val_loss: 0.4259\n",
      "Epoch 21/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - categorical_accuracy: 0.8898 - loss: 0.4357 - val_categorical_accuracy: 0.8898 - val_loss: 0.4251\n",
      "Epoch 22/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - categorical_accuracy: 0.8907 - loss: 0.4301 - val_categorical_accuracy: 0.8931 - val_loss: 0.4207\n",
      "Epoch 23/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - categorical_accuracy: 0.8909 - loss: 0.4277 - val_categorical_accuracy: 0.8931 - val_loss: 0.4170\n",
      "Epoch 24/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - categorical_accuracy: 0.8905 - loss: 0.4292 - val_categorical_accuracy: 0.8905 - val_loss: 0.4231\n",
      "Epoch 25/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - categorical_accuracy: 0.8919 - loss: 0.4273 - val_categorical_accuracy: 0.8917 - val_loss: 0.4181\n",
      "Epoch 26/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - categorical_accuracy: 0.8901 - loss: 0.4302 - val_categorical_accuracy: 0.8932 - val_loss: 0.4191\n",
      "Epoch 27/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - categorical_accuracy: 0.8908 - loss: 0.4279 - val_categorical_accuracy: 0.8922 - val_loss: 0.4184\n",
      "Epoch 28/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - categorical_accuracy: 0.8910 - loss: 0.4292 - val_categorical_accuracy: 0.8934 - val_loss: 0.4175\n",
      "Epoch 29/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - categorical_accuracy: 0.8915 - loss: 0.4256 - val_categorical_accuracy: 0.8913 - val_loss: 0.4233\n",
      "Epoch 30/30\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - categorical_accuracy: 0.8909 - loss: 0.4257 - val_categorical_accuracy: 0.8926 - val_loss: 0.4190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:42:23,235] Trial 19 finished with value: 0.41566431128295156 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'tanh', 'activation_l3': 'relu', 'batch_size': 163, 'decay_rate': 0.95, 'decay_steps': 1000, 'dropout_l1': 0.2, 'dropout_l2': 0.1, 'dropout_l3': 0.1, 'learning_rate_init': 0.00458490122660523, 'n_units_l1': 5, 'n_units_l2': 75, 'n_units_l3': 90, 'num_layers': 3}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.8563 - loss: 0.6174  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519348.458054  490231 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 384 bytes spill stores, 448 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519348.604156  490228 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519348.688873  490230 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519348.706880  490237 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 336 bytes spill stores, 336 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519348.720246  490226 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 1176 bytes spill stores, 1176 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519348.792848  490236 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 620 bytes spill stores, 688 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519348.896984  490233 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519349.804676  490303 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 384 bytes spill stores, 448 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519349.834217  490298 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 620 bytes spill stores, 688 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519349.918413  490302 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519350.095240  490313 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519350.097011  490308 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519350.108054  490310 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 336 bytes spill stores, 336 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519350.108749  490304 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 1176 bytes spill stores, 1176 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - categorical_accuracy: 0.8563 - loss: 0.6172 - val_categorical_accuracy: 0.8771 - val_loss: 0.4704\n",
      "Epoch 2/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - categorical_accuracy: 0.8827 - loss: 0.4680 - val_categorical_accuracy: 0.8868 - val_loss: 0.4464\n",
      "Epoch 3/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - categorical_accuracy: 0.8853 - loss: 0.4551 - val_categorical_accuracy: 0.8873 - val_loss: 0.4434\n",
      "Epoch 4/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - categorical_accuracy: 0.8862 - loss: 0.4489 - val_categorical_accuracy: 0.8895 - val_loss: 0.4404\n",
      "Epoch 5/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - categorical_accuracy: 0.8881 - loss: 0.4436 - val_categorical_accuracy: 0.8919 - val_loss: 0.4284\n",
      "Epoch 6/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - categorical_accuracy: 0.8881 - loss: 0.4392 - val_categorical_accuracy: 0.8889 - val_loss: 0.4309\n",
      "Epoch 7/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - categorical_accuracy: 0.8899 - loss: 0.4317 - val_categorical_accuracy: 0.8908 - val_loss: 0.4294\n",
      "Epoch 8/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - categorical_accuracy: 0.8916 - loss: 0.4268 - val_categorical_accuracy: 0.8909 - val_loss: 0.4262\n",
      "Epoch 9/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - categorical_accuracy: 0.8912 - loss: 0.4279 - val_categorical_accuracy: 0.8939 - val_loss: 0.4229\n",
      "Epoch 10/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - categorical_accuracy: 0.8923 - loss: 0.4228 - val_categorical_accuracy: 0.8947 - val_loss: 0.4120\n",
      "Epoch 11/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - categorical_accuracy: 0.8920 - loss: 0.4227 - val_categorical_accuracy: 0.8939 - val_loss: 0.4170\n",
      "Epoch 12/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - categorical_accuracy: 0.8941 - loss: 0.4174 - val_categorical_accuracy: 0.8933 - val_loss: 0.4117\n",
      "Epoch 13/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - categorical_accuracy: 0.8933 - loss: 0.4184 - val_categorical_accuracy: 0.8952 - val_loss: 0.4100\n",
      "Epoch 14/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - categorical_accuracy: 0.8940 - loss: 0.4156 - val_categorical_accuracy: 0.8969 - val_loss: 0.4077\n",
      "Epoch 15/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8941 - loss: 0.4156 - val_categorical_accuracy: 0.8955 - val_loss: 0.4065\n",
      "Epoch 16/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - categorical_accuracy: 0.8949 - loss: 0.4128 - val_categorical_accuracy: 0.8969 - val_loss: 0.4051\n",
      "Epoch 17/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - categorical_accuracy: 0.8941 - loss: 0.4134 - val_categorical_accuracy: 0.8969 - val_loss: 0.4049\n",
      "Epoch 18/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - categorical_accuracy: 0.8939 - loss: 0.4119 - val_categorical_accuracy: 0.8982 - val_loss: 0.3997\n",
      "Epoch 19/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - categorical_accuracy: 0.8941 - loss: 0.4118 - val_categorical_accuracy: 0.8984 - val_loss: 0.3966\n",
      "Epoch 20/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - categorical_accuracy: 0.8961 - loss: 0.4073 - val_categorical_accuracy: 0.8967 - val_loss: 0.4039\n",
      "Epoch 21/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - categorical_accuracy: 0.8965 - loss: 0.4045 - val_categorical_accuracy: 0.8968 - val_loss: 0.4035\n",
      "Epoch 22/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - categorical_accuracy: 0.8953 - loss: 0.4073 - val_categorical_accuracy: 0.8972 - val_loss: 0.3997\n",
      "Epoch 23/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - categorical_accuracy: 0.8964 - loss: 0.4051 - val_categorical_accuracy: 0.8973 - val_loss: 0.3973\n",
      "Epoch 24/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - categorical_accuracy: 0.8963 - loss: 0.4043 - val_categorical_accuracy: 0.8984 - val_loss: 0.4013\n",
      "Epoch 25/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - categorical_accuracy: 0.8953 - loss: 0.4067 - val_categorical_accuracy: 0.8969 - val_loss: 0.3978\n",
      "Epoch 26/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - categorical_accuracy: 0.8968 - loss: 0.4024 - val_categorical_accuracy: 0.8986 - val_loss: 0.4006\n",
      "Epoch 27/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - categorical_accuracy: 0.8964 - loss: 0.4015 - val_categorical_accuracy: 0.8989 - val_loss: 0.3924\n",
      "Epoch 28/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - categorical_accuracy: 0.8972 - loss: 0.4016 - val_categorical_accuracy: 0.8990 - val_loss: 0.3973\n",
      "Epoch 29/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - categorical_accuracy: 0.8971 - loss: 0.3983 - val_categorical_accuracy: 0.8993 - val_loss: 0.3958\n",
      "Epoch 30/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - categorical_accuracy: 0.8984 - loss: 0.3977 - val_categorical_accuracy: 0.8994 - val_loss: 0.3928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:42:53,012] Trial 20 finished with value: 0.3884226405709526 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'batch_size': 380, 'decay_rate': 0.9, 'decay_steps': 2000, 'dropout_l1': 0.30000000000000004, 'dropout_l2': 0.2, 'learning_rate_init': 0.009884868035169839, 'n_units_l1': 101, 'n_units_l2': 104, 'num_layers': 2}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519375.527249  491909 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519376.003605  491915 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 260 bytes spill stores, 260 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519376.046602  491920 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519376.047458  491913 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519376.160557  491917 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1121', 528 bytes spill stores, 544 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1126/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 719us/step - categorical_accuracy: 0.8577 - loss: 0.6080"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519379.850219  492112 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519379.989267  492111 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.8582 - loss: 0.6054  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519382.030751  492313 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 520 bytes spill stores, 644 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519382.132958  492312 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 64 bytes spill stores, 124 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519382.141510  492317 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519382.297448  492309 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519383.777752  492423 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - categorical_accuracy: 0.8583 - loss: 0.6054 - val_categorical_accuracy: 0.8859 - val_loss: 0.4479\n",
      "Epoch 2/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - categorical_accuracy: 0.8854 - loss: 0.4567 - val_categorical_accuracy: 0.8902 - val_loss: 0.4370\n",
      "Epoch 3/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - categorical_accuracy: 0.8871 - loss: 0.4450 - val_categorical_accuracy: 0.8917 - val_loss: 0.4262\n",
      "Epoch 4/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - categorical_accuracy: 0.8889 - loss: 0.4346 - val_categorical_accuracy: 0.8918 - val_loss: 0.4237\n",
      "Epoch 5/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - categorical_accuracy: 0.8916 - loss: 0.4274 - val_categorical_accuracy: 0.8943 - val_loss: 0.4145\n",
      "Epoch 6/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - categorical_accuracy: 0.8927 - loss: 0.4208 - val_categorical_accuracy: 0.8922 - val_loss: 0.4186\n",
      "Epoch 7/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - categorical_accuracy: 0.8947 - loss: 0.4126 - val_categorical_accuracy: 0.8920 - val_loss: 0.4136\n",
      "Epoch 8/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - categorical_accuracy: 0.8933 - loss: 0.4156 - val_categorical_accuracy: 0.8959 - val_loss: 0.4082\n",
      "Epoch 9/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - categorical_accuracy: 0.8955 - loss: 0.4058 - val_categorical_accuracy: 0.8977 - val_loss: 0.4027\n",
      "Epoch 10/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - categorical_accuracy: 0.8955 - loss: 0.4057 - val_categorical_accuracy: 0.8967 - val_loss: 0.4072\n",
      "Epoch 11/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - categorical_accuracy: 0.8954 - loss: 0.4041 - val_categorical_accuracy: 0.8973 - val_loss: 0.3987\n",
      "Epoch 12/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - categorical_accuracy: 0.8962 - loss: 0.4027 - val_categorical_accuracy: 0.8972 - val_loss: 0.4015\n",
      "Epoch 13/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - categorical_accuracy: 0.8964 - loss: 0.4020 - val_categorical_accuracy: 0.8946 - val_loss: 0.4001\n",
      "Epoch 14/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - categorical_accuracy: 0.8958 - loss: 0.4023 - val_categorical_accuracy: 0.8994 - val_loss: 0.3904\n",
      "Epoch 15/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - categorical_accuracy: 0.8974 - loss: 0.3984 - val_categorical_accuracy: 0.8995 - val_loss: 0.3943\n",
      "Epoch 16/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - categorical_accuracy: 0.8973 - loss: 0.3971 - val_categorical_accuracy: 0.8983 - val_loss: 0.3948\n",
      "Epoch 17/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - categorical_accuracy: 0.8978 - loss: 0.3961 - val_categorical_accuracy: 0.8982 - val_loss: 0.3931\n",
      "Epoch 18/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - categorical_accuracy: 0.8995 - loss: 0.3901 - val_categorical_accuracy: 0.9002 - val_loss: 0.3839\n",
      "Epoch 19/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - categorical_accuracy: 0.8983 - loss: 0.3918 - val_categorical_accuracy: 0.8978 - val_loss: 0.3902\n",
      "Epoch 20/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - categorical_accuracy: 0.9000 - loss: 0.3890 - val_categorical_accuracy: 0.9019 - val_loss: 0.3867\n",
      "Epoch 21/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - categorical_accuracy: 0.8987 - loss: 0.3936 - val_categorical_accuracy: 0.9026 - val_loss: 0.3812\n",
      "Epoch 22/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - categorical_accuracy: 0.9003 - loss: 0.3876 - val_categorical_accuracy: 0.9038 - val_loss: 0.3850\n",
      "Epoch 23/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - categorical_accuracy: 0.9007 - loss: 0.3864 - val_categorical_accuracy: 0.9041 - val_loss: 0.3819\n",
      "Epoch 24/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - categorical_accuracy: 0.9012 - loss: 0.3853 - val_categorical_accuracy: 0.9025 - val_loss: 0.3811\n",
      "Epoch 25/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - categorical_accuracy: 0.9012 - loss: 0.3852 - val_categorical_accuracy: 0.9035 - val_loss: 0.3808\n",
      "Epoch 26/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - categorical_accuracy: 0.9031 - loss: 0.3815 - val_categorical_accuracy: 0.9046 - val_loss: 0.3836\n",
      "Epoch 27/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - categorical_accuracy: 0.9025 - loss: 0.3826 - val_categorical_accuracy: 0.9010 - val_loss: 0.3963\n",
      "Epoch 28/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - categorical_accuracy: 0.9034 - loss: 0.3807 - val_categorical_accuracy: 0.9025 - val_loss: 0.3799\n",
      "Epoch 29/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - categorical_accuracy: 0.9021 - loss: 0.3832 - val_categorical_accuracy: 0.9076 - val_loss: 0.3721\n",
      "Epoch 30/30\n",
      "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - categorical_accuracy: 0.9031 - loss: 0.3816 - val_categorical_accuracy: 0.9071 - val_loss: 0.3740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:43:38,502] Trial 21 finished with value: 0.3692257300732697 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'tanh', 'activation_l3': 'relu', 'batch_size': 231, 'decay_rate': 0.95, 'decay_steps': 1500, 'dropout_l1': 0.0, 'dropout_l2': 0.2, 'dropout_l3': 0.2, 'learning_rate_init': 0.002748257358806179, 'n_units_l1': 60, 'n_units_l2': 126, 'n_units_l3': 124, 'num_layers': 3}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519420.192179  494058 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519420.669783  494064 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 156 bytes spill stores, 156 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519421.252562  494057 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 356 bytes spill stores, 356 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519421.257893  494066 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 68 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519421.257904  494070 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 616 bytes spill stores, 616 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519421.380625  494058 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519422.098847  494072 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1121', 152 bytes spill stores, 152 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1075/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 610us/step - categorical_accuracy: 0.8294 - loss: 0.7411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519425.642086  494194 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519425.671262  494191 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_195', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.8316 - loss: 0.7308  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519427.793735  494334 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 40 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519427.940246  494332 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519428.084566  494345 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 324 bytes spill stores, 324 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519428.115586  494336 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519428.134581  494344 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519428.223338  494346 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 516 bytes spill stores, 532 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519428.238885  494338 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 636 bytes spill stores, 696 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519429.254581  494427 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519429.323900  494439 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 24 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519429.331082  494430 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 636 bytes spill stores, 696 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519429.364290  494436 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 484 bytes spill stores, 492 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519429.676352  494435 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519429.687600  494441 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519429.799019  494431 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 324 bytes spill stores, 324 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519430.174280  494439 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 68 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519430.204095  494434 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519430.213263  494427 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519430.385265  494435 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 244 bytes spill stores, 244 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519430.408374  494430 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 176 bytes spill stores, 176 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519430.485174  494437 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - categorical_accuracy: 0.8317 - loss: 0.7307 - val_categorical_accuracy: 0.8796 - val_loss: 0.4711\n",
      "Epoch 2/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - categorical_accuracy: 0.8823 - loss: 0.4781 - val_categorical_accuracy: 0.8874 - val_loss: 0.4461\n",
      "Epoch 3/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - categorical_accuracy: 0.8856 - loss: 0.4552 - val_categorical_accuracy: 0.8850 - val_loss: 0.4386\n",
      "Epoch 4/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - categorical_accuracy: 0.8876 - loss: 0.4432 - val_categorical_accuracy: 0.8881 - val_loss: 0.4359\n",
      "Epoch 5/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - categorical_accuracy: 0.8875 - loss: 0.4407 - val_categorical_accuracy: 0.8882 - val_loss: 0.4346\n",
      "Epoch 6/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - categorical_accuracy: 0.8892 - loss: 0.4352 - val_categorical_accuracy: 0.8880 - val_loss: 0.4286\n",
      "Epoch 7/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - categorical_accuracy: 0.8890 - loss: 0.4334 - val_categorical_accuracy: 0.8887 - val_loss: 0.4313\n",
      "Epoch 8/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - categorical_accuracy: 0.8905 - loss: 0.4300 - val_categorical_accuracy: 0.8917 - val_loss: 0.4168\n",
      "Epoch 9/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - categorical_accuracy: 0.8916 - loss: 0.4238 - val_categorical_accuracy: 0.8923 - val_loss: 0.4161\n",
      "Epoch 10/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - categorical_accuracy: 0.8931 - loss: 0.4180 - val_categorical_accuracy: 0.8938 - val_loss: 0.4117\n",
      "Epoch 11/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - categorical_accuracy: 0.8926 - loss: 0.4165 - val_categorical_accuracy: 0.8933 - val_loss: 0.4100\n",
      "Epoch 12/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - categorical_accuracy: 0.8942 - loss: 0.4123 - val_categorical_accuracy: 0.8951 - val_loss: 0.4064\n",
      "Epoch 13/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - categorical_accuracy: 0.8940 - loss: 0.4130 - val_categorical_accuracy: 0.8937 - val_loss: 0.4074\n",
      "Epoch 14/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - categorical_accuracy: 0.8956 - loss: 0.4075 - val_categorical_accuracy: 0.8959 - val_loss: 0.4015\n",
      "Epoch 15/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - categorical_accuracy: 0.8952 - loss: 0.4082 - val_categorical_accuracy: 0.8968 - val_loss: 0.3997\n",
      "Epoch 16/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - categorical_accuracy: 0.8948 - loss: 0.4087 - val_categorical_accuracy: 0.8972 - val_loss: 0.3982\n",
      "Epoch 17/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - categorical_accuracy: 0.8965 - loss: 0.4024 - val_categorical_accuracy: 0.8980 - val_loss: 0.3989\n",
      "Epoch 18/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - categorical_accuracy: 0.8963 - loss: 0.4021 - val_categorical_accuracy: 0.8976 - val_loss: 0.3943\n",
      "Epoch 19/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - categorical_accuracy: 0.8963 - loss: 0.4012 - val_categorical_accuracy: 0.8956 - val_loss: 0.4008\n",
      "Epoch 20/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - categorical_accuracy: 0.8966 - loss: 0.4004 - val_categorical_accuracy: 0.8983 - val_loss: 0.3924\n",
      "Epoch 21/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - categorical_accuracy: 0.8961 - loss: 0.4005 - val_categorical_accuracy: 0.8990 - val_loss: 0.3921\n",
      "Epoch 22/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - categorical_accuracy: 0.8975 - loss: 0.3977 - val_categorical_accuracy: 0.8999 - val_loss: 0.3894\n",
      "Epoch 23/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - categorical_accuracy: 0.8999 - loss: 0.3902 - val_categorical_accuracy: 0.8995 - val_loss: 0.3880\n",
      "Epoch 24/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - categorical_accuracy: 0.8974 - loss: 0.3993 - val_categorical_accuracy: 0.9018 - val_loss: 0.3902\n",
      "Epoch 25/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - categorical_accuracy: 0.8990 - loss: 0.3939 - val_categorical_accuracy: 0.8988 - val_loss: 0.3884\n",
      "Epoch 26/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - categorical_accuracy: 0.8986 - loss: 0.3944 - val_categorical_accuracy: 0.9007 - val_loss: 0.3857\n",
      "Epoch 27/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.8995 - loss: 0.3922 - val_categorical_accuracy: 0.9022 - val_loss: 0.3838\n",
      "Epoch 28/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - categorical_accuracy: 0.9014 - loss: 0.3861 - val_categorical_accuracy: 0.9011 - val_loss: 0.3845\n",
      "Epoch 29/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - categorical_accuracy: 0.9005 - loss: 0.3899 - val_categorical_accuracy: 0.9003 - val_loss: 0.3913\n",
      "Epoch 30/30\n",
      "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - categorical_accuracy: 0.9004 - loss: 0.3891 - val_categorical_accuracy: 0.9023 - val_loss: 0.3811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:44:23,067] Trial 22 finished with value: 0.37666508008237254 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'tanh', 'activation_l3': 'relu', 'batch_size': 234, 'decay_rate': 0.95, 'decay_steps': 1500, 'dropout_l1': 0.0, 'dropout_l2': 0.2, 'dropout_l3': 0.30000000000000004, 'learning_rate_init': 0.0014262803800514034, 'n_units_l1': 54, 'n_units_l2': 117, 'n_units_l3': 108, 'num_layers': 3}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519465.135781  496075 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1580', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.8469 - loss: 0.6512  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519471.226628  496258 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 108 bytes spill stores, 108 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519471.244554  496249 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519471.388368  496252 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 64 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519471.567153  496247 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 468 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519471.642906  496261 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 1580 bytes spill stores, 1652 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519471.712914  496248 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 48 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519471.782360  496256 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 232 bytes spill stores, 232 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519471.899489  496258 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 296 bytes spill stores, 296 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519472.105106  496249 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 272 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519472.144603  496252 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 132 bytes spill stores, 132 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519472.163469  496260 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 772 bytes spill stores, 632 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519472.280188  496254 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 456 bytes spill stores, 420 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519472.342109  496261 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 316 bytes spill stores, 304 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519472.508522  496247 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 468 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519472.643467  496259 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519472.793016  496248 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 1612 bytes spill stores, 1684 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519474.216238  496353 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519474.395284  496344 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 156 bytes spill stores, 208 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519474.468687  496342 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 436 bytes spill stores, 588 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519474.675853  496345 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 424 bytes spill stores, 576 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519475.089068  496342 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 144 bytes spill stores, 144 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519475.259842  496356 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519475.517206  496346 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - categorical_accuracy: 0.8469 - loss: 0.6511 - val_categorical_accuracy: 0.8842 - val_loss: 0.4515\n",
      "Epoch 2/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - categorical_accuracy: 0.8839 - loss: 0.4581 - val_categorical_accuracy: 0.8872 - val_loss: 0.4412\n",
      "Epoch 3/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - categorical_accuracy: 0.8881 - loss: 0.4408 - val_categorical_accuracy: 0.8853 - val_loss: 0.4414\n",
      "Epoch 4/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - categorical_accuracy: 0.8883 - loss: 0.4375 - val_categorical_accuracy: 0.8900 - val_loss: 0.4296\n",
      "Epoch 5/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - categorical_accuracy: 0.8892 - loss: 0.4316 - val_categorical_accuracy: 0.8909 - val_loss: 0.4273\n",
      "Epoch 6/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - categorical_accuracy: 0.8895 - loss: 0.4274 - val_categorical_accuracy: 0.8919 - val_loss: 0.4207\n",
      "Epoch 7/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - categorical_accuracy: 0.8908 - loss: 0.4229 - val_categorical_accuracy: 0.8956 - val_loss: 0.4137\n",
      "Epoch 8/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - categorical_accuracy: 0.8925 - loss: 0.4194 - val_categorical_accuracy: 0.8952 - val_loss: 0.4075\n",
      "Epoch 9/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - categorical_accuracy: 0.8934 - loss: 0.4140 - val_categorical_accuracy: 0.8953 - val_loss: 0.4079\n",
      "Epoch 10/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - categorical_accuracy: 0.8925 - loss: 0.4177 - val_categorical_accuracy: 0.8962 - val_loss: 0.4035\n",
      "Epoch 11/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - categorical_accuracy: 0.8948 - loss: 0.4087 - val_categorical_accuracy: 0.8963 - val_loss: 0.4009\n",
      "Epoch 12/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - categorical_accuracy: 0.8962 - loss: 0.4020 - val_categorical_accuracy: 0.8982 - val_loss: 0.4061\n",
      "Epoch 13/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8962 - loss: 0.4031 - val_categorical_accuracy: 0.8991 - val_loss: 0.3961\n",
      "Epoch 14/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - categorical_accuracy: 0.8960 - loss: 0.4042 - val_categorical_accuracy: 0.8995 - val_loss: 0.3927\n",
      "Epoch 15/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - categorical_accuracy: 0.8968 - loss: 0.3984 - val_categorical_accuracy: 0.8984 - val_loss: 0.3964\n",
      "Epoch 16/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - categorical_accuracy: 0.8969 - loss: 0.3980 - val_categorical_accuracy: 0.9003 - val_loss: 0.3916\n",
      "Epoch 17/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - categorical_accuracy: 0.8975 - loss: 0.3962 - val_categorical_accuracy: 0.8955 - val_loss: 0.3932\n",
      "Epoch 18/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - categorical_accuracy: 0.8991 - loss: 0.3903 - val_categorical_accuracy: 0.9017 - val_loss: 0.3867\n",
      "Epoch 19/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - categorical_accuracy: 0.8988 - loss: 0.3926 - val_categorical_accuracy: 0.8991 - val_loss: 0.3957\n",
      "Epoch 20/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - categorical_accuracy: 0.8986 - loss: 0.3915 - val_categorical_accuracy: 0.9024 - val_loss: 0.3831\n",
      "Epoch 21/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - categorical_accuracy: 0.9000 - loss: 0.3875 - val_categorical_accuracy: 0.9021 - val_loss: 0.3820\n",
      "Epoch 22/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - categorical_accuracy: 0.9009 - loss: 0.3848 - val_categorical_accuracy: 0.9043 - val_loss: 0.3800\n",
      "Epoch 23/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - categorical_accuracy: 0.9007 - loss: 0.3854 - val_categorical_accuracy: 0.9026 - val_loss: 0.3797\n",
      "Epoch 24/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - categorical_accuracy: 0.9020 - loss: 0.3830 - val_categorical_accuracy: 0.9026 - val_loss: 0.3782\n",
      "Epoch 25/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - categorical_accuracy: 0.9020 - loss: 0.3824 - val_categorical_accuracy: 0.9041 - val_loss: 0.3742\n",
      "Epoch 26/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - categorical_accuracy: 0.9023 - loss: 0.3802 - val_categorical_accuracy: 0.9026 - val_loss: 0.3799\n",
      "Epoch 27/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - categorical_accuracy: 0.9026 - loss: 0.3805 - val_categorical_accuracy: 0.9039 - val_loss: 0.3747\n",
      "Epoch 28/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - categorical_accuracy: 0.9039 - loss: 0.3759 - val_categorical_accuracy: 0.9059 - val_loss: 0.3699\n",
      "Epoch 29/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - categorical_accuracy: 0.9042 - loss: 0.3766 - val_categorical_accuracy: 0.9047 - val_loss: 0.3752\n",
      "Epoch 30/30\n",
      "\u001b[1m1379/1379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - categorical_accuracy: 0.9037 - loss: 0.3775 - val_categorical_accuracy: 0.9070 - val_loss: 0.3690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519510.737113  497901 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_23', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:45:12,704] Trial 23 finished with value: 0.3653896881475005 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'tanh', 'activation_l3': 'relu', 'activation_l4': 'relu', 'batch_size': 194, 'decay_rate': 0.95, 'decay_steps': 1000, 'dropout_l1': 0.1, 'dropout_l2': 0.30000000000000004, 'dropout_l3': 0.1, 'dropout_l4': 0.0, 'learning_rate_init': 0.002485262214698901, 'n_units_l1': 73, 'n_units_l2': 97, 'n_units_l3': 43, 'n_units_l4': 128, 'num_layers': 4}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519515.182035  498013 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1282', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.8604 - loss: 0.5908  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519520.621447  498206 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519521.340663  498202 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 68 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519521.391194  498199 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 360 bytes spill stores, 432 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519521.531195  498206 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 288 bytes spill stores, 288 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519521.554580  498195 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519521.656539  498200 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 168 bytes spill stores, 168 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519521.738178  498197 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 232 bytes spill stores, 232 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519521.755741  498196 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519522.295088  498201 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 320 bytes spill stores, 308 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519522.296705  498200 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519522.319205  498193 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519522.358594  498204 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519522.368711  498192 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 448 bytes spill stores, 448 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519522.377109  498207 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 1612 bytes spill stores, 1684 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519522.742567  498205 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 400 bytes spill stores, 400 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519524.145205  498314 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - categorical_accuracy: 0.8604 - loss: 0.5907 - val_categorical_accuracy: 0.8827 - val_loss: 0.4641\n",
      "Epoch 2/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - categorical_accuracy: 0.8845 - loss: 0.4542 - val_categorical_accuracy: 0.8880 - val_loss: 0.4430\n",
      "Epoch 3/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - categorical_accuracy: 0.8860 - loss: 0.4471 - val_categorical_accuracy: 0.8874 - val_loss: 0.4329\n",
      "Epoch 4/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - categorical_accuracy: 0.8872 - loss: 0.4402 - val_categorical_accuracy: 0.8913 - val_loss: 0.4237\n",
      "Epoch 5/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - categorical_accuracy: 0.8900 - loss: 0.4305 - val_categorical_accuracy: 0.8883 - val_loss: 0.4317\n",
      "Epoch 6/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - categorical_accuracy: 0.8911 - loss: 0.4241 - val_categorical_accuracy: 0.8937 - val_loss: 0.4130\n",
      "Epoch 7/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - categorical_accuracy: 0.8930 - loss: 0.4177 - val_categorical_accuracy: 0.8944 - val_loss: 0.4117\n",
      "Epoch 8/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - categorical_accuracy: 0.8933 - loss: 0.4157 - val_categorical_accuracy: 0.8951 - val_loss: 0.4049\n",
      "Epoch 9/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - categorical_accuracy: 0.8928 - loss: 0.4135 - val_categorical_accuracy: 0.8967 - val_loss: 0.3993\n",
      "Epoch 10/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - categorical_accuracy: 0.8937 - loss: 0.4094 - val_categorical_accuracy: 0.8976 - val_loss: 0.3958\n",
      "Epoch 11/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - categorical_accuracy: 0.8965 - loss: 0.4004 - val_categorical_accuracy: 0.8974 - val_loss: 0.3954\n",
      "Epoch 12/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - categorical_accuracy: 0.8960 - loss: 0.4021 - val_categorical_accuracy: 0.8986 - val_loss: 0.3932\n",
      "Epoch 13/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - categorical_accuracy: 0.8975 - loss: 0.3986 - val_categorical_accuracy: 0.9003 - val_loss: 0.3926\n",
      "Epoch 14/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - categorical_accuracy: 0.8976 - loss: 0.3962 - val_categorical_accuracy: 0.8987 - val_loss: 0.3928\n",
      "Epoch 15/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - categorical_accuracy: 0.8985 - loss: 0.3939 - val_categorical_accuracy: 0.9013 - val_loss: 0.3872\n",
      "Epoch 16/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - categorical_accuracy: 0.8996 - loss: 0.3910 - val_categorical_accuracy: 0.9038 - val_loss: 0.3869\n",
      "Epoch 17/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - categorical_accuracy: 0.9003 - loss: 0.3882 - val_categorical_accuracy: 0.9026 - val_loss: 0.3843\n",
      "Epoch 18/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - categorical_accuracy: 0.9006 - loss: 0.3886 - val_categorical_accuracy: 0.9032 - val_loss: 0.3817\n",
      "Epoch 19/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - categorical_accuracy: 0.9000 - loss: 0.3894 - val_categorical_accuracy: 0.9041 - val_loss: 0.3808\n",
      "Epoch 20/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - categorical_accuracy: 0.9012 - loss: 0.3870 - val_categorical_accuracy: 0.9050 - val_loss: 0.3807\n",
      "Epoch 21/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - categorical_accuracy: 0.9020 - loss: 0.3846 - val_categorical_accuracy: 0.9038 - val_loss: 0.3796\n",
      "Epoch 22/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - categorical_accuracy: 0.9013 - loss: 0.3865 - val_categorical_accuracy: 0.9046 - val_loss: 0.3780\n",
      "Epoch 23/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - categorical_accuracy: 0.9030 - loss: 0.3818 - val_categorical_accuracy: 0.9043 - val_loss: 0.3787\n",
      "Epoch 24/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - categorical_accuracy: 0.9030 - loss: 0.3815 - val_categorical_accuracy: 0.9046 - val_loss: 0.3776\n",
      "Epoch 25/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - categorical_accuracy: 0.9022 - loss: 0.3842 - val_categorical_accuracy: 0.9023 - val_loss: 0.3831\n",
      "Epoch 26/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - categorical_accuracy: 0.9044 - loss: 0.3774 - val_categorical_accuracy: 0.9041 - val_loss: 0.3788\n",
      "Epoch 27/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - categorical_accuracy: 0.9034 - loss: 0.3800 - val_categorical_accuracy: 0.9044 - val_loss: 0.3774\n",
      "Epoch 28/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - categorical_accuracy: 0.9033 - loss: 0.3785 - val_categorical_accuracy: 0.9048 - val_loss: 0.3766\n",
      "Epoch 29/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - categorical_accuracy: 0.9030 - loss: 0.3819 - val_categorical_accuracy: 0.9053 - val_loss: 0.3764\n",
      "Epoch 30/30\n",
      "\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - categorical_accuracy: 0.9029 - loss: 0.3833 - val_categorical_accuracy: 0.9046 - val_loss: 0.3769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519564.379345  499867 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_23', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:46:06,568] Trial 24 finished with value: 0.373494208638772 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'tanh', 'activation_l3': 'relu', 'activation_l4': 'relu', 'batch_size': 174, 'decay_rate': 0.9, 'decay_steps': 1000, 'dropout_l1': 0.1, 'dropout_l2': 0.30000000000000004, 'dropout_l3': 0.1, 'dropout_l4': 0.0, 'learning_rate_init': 0.0052938457435370056, 'n_units_l1': 74, 'n_units_l2': 97, 'n_units_l3': 35, 'n_units_l4': 123, 'num_layers': 4}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519568.873278  499973 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1778', 164 bytes spill stores, 164 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.8390 - loss: 0.7027  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519575.337788  500103 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519575.408651  500115 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519575.443863  500107 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_69', 184 bytes spill stores, 184 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519575.763797  500109 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 524 bytes spill stores, 524 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519575.921117  500105 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 316 bytes spill stores, 308 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519575.965263  500113 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519576.209677  500110 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519576.292774  500112 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519576.506767  500103 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519576.579830  500118 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519576.580248  500116 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 68 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519576.635744  500114 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519576.798216  500111 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 672 bytes spill stores, 804 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519576.920887  500106 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519576.951622  500117 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 376 bytes spill stores, 376 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519577.056680  500113 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 160 bytes spill stores, 160 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519577.188034  500115 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 344 bytes spill stores, 416 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519577.188804  500116 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519577.237493  500109 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 556 bytes spill stores, 620 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519578.475053  500227 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519578.520546  500228 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519578.533333  500229 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519578.535006  500224 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_62', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519578.584563  500236 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_69', 184 bytes spill stores, 184 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519578.618955  500238 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519578.787789  500236 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519579.222270  500231 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519579.269227  500238 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519579.346694  500223 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 344 bytes spill stores, 416 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519579.477241  500233 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519579.595034  500227 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519579.843849  500228 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 688 bytes spill stores, 760 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519579.951722  500224 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519579.977337  500238 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 160 bytes spill stores, 160 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519580.021843  500231 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 68 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519580.027169  500226 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 524 bytes spill stores, 524 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519580.112573  500233 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 228 bytes spill stores, 228 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519580.522641  500236 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_55', 556 bytes spill stores, 620 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - categorical_accuracy: 0.8390 - loss: 0.7026 - val_categorical_accuracy: 0.8810 - val_loss: 0.4631\n",
      "Epoch 2/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - categorical_accuracy: 0.8806 - loss: 0.4796 - val_categorical_accuracy: 0.8866 - val_loss: 0.4483\n",
      "Epoch 3/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - categorical_accuracy: 0.8848 - loss: 0.4558 - val_categorical_accuracy: 0.8864 - val_loss: 0.4373\n",
      "Epoch 4/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - categorical_accuracy: 0.8856 - loss: 0.4510 - val_categorical_accuracy: 0.8898 - val_loss: 0.4328\n",
      "Epoch 5/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - categorical_accuracy: 0.8872 - loss: 0.4422 - val_categorical_accuracy: 0.8907 - val_loss: 0.4289\n",
      "Epoch 6/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - categorical_accuracy: 0.8887 - loss: 0.4376 - val_categorical_accuracy: 0.8881 - val_loss: 0.4305\n",
      "Epoch 7/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - categorical_accuracy: 0.8887 - loss: 0.4345 - val_categorical_accuracy: 0.8893 - val_loss: 0.4268\n",
      "Epoch 8/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - categorical_accuracy: 0.8893 - loss: 0.4319 - val_categorical_accuracy: 0.8921 - val_loss: 0.4201\n",
      "Epoch 9/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - categorical_accuracy: 0.8894 - loss: 0.4330 - val_categorical_accuracy: 0.8928 - val_loss: 0.4173\n",
      "Epoch 10/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - categorical_accuracy: 0.8901 - loss: 0.4267 - val_categorical_accuracy: 0.8915 - val_loss: 0.4182\n",
      "Epoch 11/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - categorical_accuracy: 0.8907 - loss: 0.4250 - val_categorical_accuracy: 0.8931 - val_loss: 0.4128\n",
      "Epoch 12/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - categorical_accuracy: 0.8909 - loss: 0.4235 - val_categorical_accuracy: 0.8937 - val_loss: 0.4124\n",
      "Epoch 13/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - categorical_accuracy: 0.8916 - loss: 0.4214 - val_categorical_accuracy: 0.8944 - val_loss: 0.4077\n",
      "Epoch 14/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - categorical_accuracy: 0.8918 - loss: 0.4202 - val_categorical_accuracy: 0.8934 - val_loss: 0.4079\n",
      "Epoch 15/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - categorical_accuracy: 0.8931 - loss: 0.4158 - val_categorical_accuracy: 0.8960 - val_loss: 0.4057\n",
      "Epoch 16/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - categorical_accuracy: 0.8937 - loss: 0.4130 - val_categorical_accuracy: 0.8967 - val_loss: 0.4004\n",
      "Epoch 17/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - categorical_accuracy: 0.8942 - loss: 0.4112 - val_categorical_accuracy: 0.8978 - val_loss: 0.3985\n",
      "Epoch 18/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - categorical_accuracy: 0.8942 - loss: 0.4105 - val_categorical_accuracy: 0.8967 - val_loss: 0.3996\n",
      "Epoch 19/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - categorical_accuracy: 0.8957 - loss: 0.4071 - val_categorical_accuracy: 0.8975 - val_loss: 0.3970\n",
      "Epoch 20/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - categorical_accuracy: 0.8951 - loss: 0.4063 - val_categorical_accuracy: 0.8980 - val_loss: 0.3959\n",
      "Epoch 21/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - categorical_accuracy: 0.8952 - loss: 0.4075 - val_categorical_accuracy: 0.8981 - val_loss: 0.3955\n",
      "Epoch 22/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - categorical_accuracy: 0.8953 - loss: 0.4069 - val_categorical_accuracy: 0.8978 - val_loss: 0.3949\n",
      "Epoch 23/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - categorical_accuracy: 0.8959 - loss: 0.4039 - val_categorical_accuracy: 0.8978 - val_loss: 0.3936\n",
      "Epoch 24/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - categorical_accuracy: 0.8950 - loss: 0.4068 - val_categorical_accuracy: 0.8982 - val_loss: 0.3929\n",
      "Epoch 25/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - categorical_accuracy: 0.8968 - loss: 0.3999 - val_categorical_accuracy: 0.8987 - val_loss: 0.3919\n",
      "Epoch 26/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - categorical_accuracy: 0.8958 - loss: 0.4038 - val_categorical_accuracy: 0.8985 - val_loss: 0.3915\n",
      "Epoch 27/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - categorical_accuracy: 0.8970 - loss: 0.3994 - val_categorical_accuracy: 0.8984 - val_loss: 0.3915\n",
      "Epoch 28/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - categorical_accuracy: 0.8972 - loss: 0.3995 - val_categorical_accuracy: 0.9016 - val_loss: 0.3913\n",
      "Epoch 29/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - categorical_accuracy: 0.8970 - loss: 0.3997 - val_categorical_accuracy: 0.9026 - val_loss: 0.3914\n",
      "Epoch 30/30\n",
      "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - categorical_accuracy: 0.8975 - loss: 0.3980 - val_categorical_accuracy: 0.9027 - val_loss: 0.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519617.068969  501786 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_18', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:46:59,024] Trial 25 finished with value: 0.38633347084707576 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'tanh', 'activation_l3': 'relu', 'activation_l4': 'relu', 'batch_size': 190, 'decay_rate': 0.95, 'decay_steps': 1000, 'dropout_l1': 0.2, 'dropout_l2': 0.4, 'dropout_l3': 0.1, 'dropout_l4': 0.2, 'learning_rate_init': 0.0022698644437789206, 'n_units_l1': 78, 'n_units_l2': 81, 'n_units_l3': 46, 'n_units_l4': 69, 'num_layers': 4}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - categorical_accuracy: 0.8098 - loss: 0.8503 - val_categorical_accuracy: 0.8778 - val_loss: 0.5184\n",
      "Epoch 2/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 715us/step - categorical_accuracy: 0.8766 - loss: 0.5235 - val_categorical_accuracy: 0.8794 - val_loss: 0.4737\n",
      "Epoch 3/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 708us/step - categorical_accuracy: 0.8786 - loss: 0.4948 - val_categorical_accuracy: 0.8808 - val_loss: 0.4635\n",
      "Epoch 4/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714us/step - categorical_accuracy: 0.8802 - loss: 0.4832 - val_categorical_accuracy: 0.8858 - val_loss: 0.4586\n",
      "Epoch 5/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 696us/step - categorical_accuracy: 0.8820 - loss: 0.4736 - val_categorical_accuracy: 0.8854 - val_loss: 0.4535\n",
      "Epoch 6/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - categorical_accuracy: 0.8819 - loss: 0.4708 - val_categorical_accuracy: 0.8855 - val_loss: 0.4485\n",
      "Epoch 7/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 721us/step - categorical_accuracy: 0.8835 - loss: 0.4635 - val_categorical_accuracy: 0.8861 - val_loss: 0.4498\n",
      "Epoch 8/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 717us/step - categorical_accuracy: 0.8835 - loss: 0.4596 - val_categorical_accuracy: 0.8870 - val_loss: 0.4459\n",
      "Epoch 9/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714us/step - categorical_accuracy: 0.8842 - loss: 0.4578 - val_categorical_accuracy: 0.8871 - val_loss: 0.4427\n",
      "Epoch 10/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 698us/step - categorical_accuracy: 0.8840 - loss: 0.4581 - val_categorical_accuracy: 0.8872 - val_loss: 0.4434\n",
      "Epoch 11/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716us/step - categorical_accuracy: 0.8854 - loss: 0.4545 - val_categorical_accuracy: 0.8873 - val_loss: 0.4429\n",
      "Epoch 12/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - categorical_accuracy: 0.8842 - loss: 0.4577 - val_categorical_accuracy: 0.8876 - val_loss: 0.4414\n",
      "Epoch 13/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - categorical_accuracy: 0.8840 - loss: 0.4578 - val_categorical_accuracy: 0.8875 - val_loss: 0.4416\n",
      "Epoch 14/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 800us/step - categorical_accuracy: 0.8852 - loss: 0.4535 - val_categorical_accuracy: 0.8876 - val_loss: 0.4415\n",
      "Epoch 15/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 861us/step - categorical_accuracy: 0.8847 - loss: 0.4546 - val_categorical_accuracy: 0.8876 - val_loss: 0.4415\n",
      "Epoch 16/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 924us/step - categorical_accuracy: 0.8858 - loss: 0.4521 - val_categorical_accuracy: 0.8876 - val_loss: 0.4412\n",
      "Epoch 17/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 785us/step - categorical_accuracy: 0.8851 - loss: 0.4528 - val_categorical_accuracy: 0.8878 - val_loss: 0.4405\n",
      "Epoch 18/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 795us/step - categorical_accuracy: 0.8842 - loss: 0.4546 - val_categorical_accuracy: 0.8878 - val_loss: 0.4403\n",
      "Epoch 19/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 786us/step - categorical_accuracy: 0.8855 - loss: 0.4515 - val_categorical_accuracy: 0.8878 - val_loss: 0.4404\n",
      "Epoch 20/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716us/step - categorical_accuracy: 0.8844 - loss: 0.4567 - val_categorical_accuracy: 0.8878 - val_loss: 0.4404\n",
      "Epoch 21/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - categorical_accuracy: 0.8851 - loss: 0.4527 - val_categorical_accuracy: 0.8878 - val_loss: 0.4402\n",
      "Epoch 22/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723us/step - categorical_accuracy: 0.8854 - loss: 0.4524 - val_categorical_accuracy: 0.8879 - val_loss: 0.4403\n",
      "Epoch 23/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 715us/step - categorical_accuracy: 0.8866 - loss: 0.4488 - val_categorical_accuracy: 0.8878 - val_loss: 0.4402\n",
      "Epoch 24/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 721us/step - categorical_accuracy: 0.8849 - loss: 0.4534 - val_categorical_accuracy: 0.8878 - val_loss: 0.4403\n",
      "Epoch 25/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720us/step - categorical_accuracy: 0.8836 - loss: 0.4589 - val_categorical_accuracy: 0.8879 - val_loss: 0.4400\n",
      "Epoch 26/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 713us/step - categorical_accuracy: 0.8847 - loss: 0.4522 - val_categorical_accuracy: 0.8878 - val_loss: 0.4401\n",
      "Epoch 27/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718us/step - categorical_accuracy: 0.8842 - loss: 0.4582 - val_categorical_accuracy: 0.8878 - val_loss: 0.4402\n",
      "Epoch 28/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 711us/step - categorical_accuracy: 0.8865 - loss: 0.4518 - val_categorical_accuracy: 0.8878 - val_loss: 0.4401\n",
      "Epoch 29/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 735us/step - categorical_accuracy: 0.8846 - loss: 0.4544 - val_categorical_accuracy: 0.8878 - val_loss: 0.4401\n",
      "Epoch 30/30\n",
      "\u001b[1m2228/2228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - categorical_accuracy: 0.8854 - loss: 0.4516 - val_categorical_accuracy: 0.8878 - val_loss: 0.4401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:48:05,652] Trial 26 finished with value: 0.4370877178794046 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'activation_l3': 'tanh', 'activation_l4': 'relu', 'batch_size': 120, 'decay_rate': 0.9, 'decay_steps': 1000, 'dropout_l1': 0.1, 'dropout_l2': 0.30000000000000004, 'dropout_l3': 0.30000000000000004, 'dropout_l4': 0.2, 'learning_rate_init': 0.0006614229097553846, 'n_units_l1': 47, 'n_units_l2': 65, 'n_units_l3': 16, 'n_units_l4': 127, 'num_layers': 4}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519687.382766  504371 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_510', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - categorical_accuracy: 0.8582 - loss: 0.5921  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519691.051403  504536 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519691.051940  504539 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - categorical_accuracy: 0.8582 - loss: 0.5920 - val_categorical_accuracy: 0.8838 - val_loss: 0.4585\n",
      "Epoch 2/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - categorical_accuracy: 0.8844 - loss: 0.4577 - val_categorical_accuracy: 0.8826 - val_loss: 0.4534\n",
      "Epoch 3/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - categorical_accuracy: 0.8859 - loss: 0.4502 - val_categorical_accuracy: 0.8858 - val_loss: 0.4469\n",
      "Epoch 4/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - categorical_accuracy: 0.8881 - loss: 0.4371 - val_categorical_accuracy: 0.8900 - val_loss: 0.4311\n",
      "Epoch 5/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - categorical_accuracy: 0.8895 - loss: 0.4292 - val_categorical_accuracy: 0.8910 - val_loss: 0.4221\n",
      "Epoch 6/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - categorical_accuracy: 0.8917 - loss: 0.4241 - val_categorical_accuracy: 0.8912 - val_loss: 0.4238\n",
      "Epoch 7/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - categorical_accuracy: 0.8906 - loss: 0.4252 - val_categorical_accuracy: 0.8925 - val_loss: 0.4164\n",
      "Epoch 8/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - categorical_accuracy: 0.8921 - loss: 0.4214 - val_categorical_accuracy: 0.8926 - val_loss: 0.4153\n",
      "Epoch 9/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - categorical_accuracy: 0.8932 - loss: 0.4150 - val_categorical_accuracy: 0.8931 - val_loss: 0.4133\n",
      "Epoch 10/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - categorical_accuracy: 0.8932 - loss: 0.4144 - val_categorical_accuracy: 0.8944 - val_loss: 0.4100\n",
      "Epoch 11/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - categorical_accuracy: 0.8942 - loss: 0.4109 - val_categorical_accuracy: 0.8938 - val_loss: 0.4115\n",
      "Epoch 12/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - categorical_accuracy: 0.8943 - loss: 0.4112 - val_categorical_accuracy: 0.8948 - val_loss: 0.4080\n",
      "Epoch 13/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - categorical_accuracy: 0.8941 - loss: 0.4108 - val_categorical_accuracy: 0.8958 - val_loss: 0.4062\n",
      "Epoch 14/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.8951 - loss: 0.4085 - val_categorical_accuracy: 0.8951 - val_loss: 0.4042\n",
      "Epoch 15/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - categorical_accuracy: 0.8959 - loss: 0.4042 - val_categorical_accuracy: 0.8966 - val_loss: 0.4031\n",
      "Epoch 16/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - categorical_accuracy: 0.8962 - loss: 0.4048 - val_categorical_accuracy: 0.8962 - val_loss: 0.4032\n",
      "Epoch 17/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - categorical_accuracy: 0.8961 - loss: 0.4031 - val_categorical_accuracy: 0.8957 - val_loss: 0.4024\n",
      "Epoch 18/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - categorical_accuracy: 0.8962 - loss: 0.4033 - val_categorical_accuracy: 0.8965 - val_loss: 0.4013\n",
      "Epoch 19/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - categorical_accuracy: 0.8961 - loss: 0.4038 - val_categorical_accuracy: 0.8965 - val_loss: 0.4013\n",
      "Epoch 20/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - categorical_accuracy: 0.8973 - loss: 0.3997 - val_categorical_accuracy: 0.8963 - val_loss: 0.4008\n",
      "Epoch 21/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - categorical_accuracy: 0.8959 - loss: 0.4033 - val_categorical_accuracy: 0.8960 - val_loss: 0.4006\n",
      "Epoch 22/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - categorical_accuracy: 0.8964 - loss: 0.4019 - val_categorical_accuracy: 0.8967 - val_loss: 0.4003\n",
      "Epoch 23/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - categorical_accuracy: 0.8964 - loss: 0.4023 - val_categorical_accuracy: 0.8966 - val_loss: 0.4003\n",
      "Epoch 24/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - categorical_accuracy: 0.8965 - loss: 0.4003 - val_categorical_accuracy: 0.8964 - val_loss: 0.3997\n",
      "Epoch 25/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - categorical_accuracy: 0.8958 - loss: 0.4031 - val_categorical_accuracy: 0.8965 - val_loss: 0.3999\n",
      "Epoch 26/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - categorical_accuracy: 0.8963 - loss: 0.3999 - val_categorical_accuracy: 0.8967 - val_loss: 0.3996\n",
      "Epoch 27/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590us/step - categorical_accuracy: 0.8960 - loss: 0.4025 - val_categorical_accuracy: 0.8967 - val_loss: 0.3995\n",
      "Epoch 28/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - categorical_accuracy: 0.8967 - loss: 0.3991 - val_categorical_accuracy: 0.8966 - val_loss: 0.3996\n",
      "Epoch 29/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - categorical_accuracy: 0.8966 - loss: 0.3983 - val_categorical_accuracy: 0.8967 - val_loss: 0.3994\n",
      "Epoch 30/30\n",
      "\u001b[1m1783/1783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - categorical_accuracy: 0.8965 - loss: 0.3998 - val_categorical_accuracy: 0.8967 - val_loss: 0.3994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:48:51,895] Trial 27 finished with value: 0.39537635213017236 and parameters: {'activation_l1': 'relu', 'activation_l2': 'tanh', 'batch_size': 150, 'decay_rate': 0.95, 'decay_steps': 500, 'dropout_l1': 0.1, 'dropout_l2': 0.0, 'learning_rate_init': 0.005762601822284723, 'n_units_l1': 31, 'n_units_l2': 103, 'num_layers': 2}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519734.271340  506157 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_932', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519734.470272  506159 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1441', 172 bytes spill stores, 172 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519734.529364  506162 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_932', 252 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519734.638704  506152 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_932', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519734.771660  506163 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_932', 416 bytes spill stores, 416 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519734.814213  506155 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_932', 1620 bytes spill stores, 1120 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519734.984530  506166 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_932', 284 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519735.018963  506158 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_932', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519735.417739  506155 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1441', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519735.616248  506156 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1565', 120 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519735.899413  506165 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1565', 80 bytes spill stores, 84 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.8578 - loss: 0.6161  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519741.460823  506363 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519741.472873  506361 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 472 bytes spill stores, 472 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519741.497794  506365 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 284 bytes spill stores, 284 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519741.556377  506359 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 64 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519741.583007  506355 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519741.632195  506351 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519741.706121  506356 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 232 bytes spill stores, 232 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519741.789502  506360 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 276 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519741.981764  506366 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519742.177172  506357 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 224 bytes spill stores, 216 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519742.283725  506363 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_71', 272 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519742.287802  506365 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519742.400011  506361 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 1608 bytes spill stores, 1680 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519742.431822  506359 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 416 bytes spill stores, 416 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519742.488465  506354 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_57', 2080 bytes spill stores, 1604 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519743.603878  506439 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_64', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - categorical_accuracy: 0.8578 - loss: 0.6160 - val_categorical_accuracy: 0.8832 - val_loss: 0.4529\n",
      "Epoch 2/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - categorical_accuracy: 0.8859 - loss: 0.4547 - val_categorical_accuracy: 0.8906 - val_loss: 0.4322\n",
      "Epoch 3/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - categorical_accuracy: 0.8886 - loss: 0.4399 - val_categorical_accuracy: 0.8870 - val_loss: 0.4328\n",
      "Epoch 4/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - categorical_accuracy: 0.8905 - loss: 0.4303 - val_categorical_accuracy: 0.8902 - val_loss: 0.4233\n",
      "Epoch 5/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8903 - loss: 0.4274 - val_categorical_accuracy: 0.8931 - val_loss: 0.4144\n",
      "Epoch 6/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - categorical_accuracy: 0.8932 - loss: 0.4191 - val_categorical_accuracy: 0.8942 - val_loss: 0.4118\n",
      "Epoch 7/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - categorical_accuracy: 0.8941 - loss: 0.4133 - val_categorical_accuracy: 0.8935 - val_loss: 0.4092\n",
      "Epoch 8/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - categorical_accuracy: 0.8944 - loss: 0.4105 - val_categorical_accuracy: 0.8952 - val_loss: 0.3988\n",
      "Epoch 9/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8954 - loss: 0.4065 - val_categorical_accuracy: 0.8954 - val_loss: 0.4049\n",
      "Epoch 10/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.8955 - loss: 0.4033 - val_categorical_accuracy: 0.8988 - val_loss: 0.3964\n",
      "Epoch 11/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - categorical_accuracy: 0.8970 - loss: 0.3988 - val_categorical_accuracy: 0.8979 - val_loss: 0.3933\n",
      "Epoch 12/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - categorical_accuracy: 0.8977 - loss: 0.3970 - val_categorical_accuracy: 0.8992 - val_loss: 0.3912\n",
      "Epoch 13/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - categorical_accuracy: 0.8983 - loss: 0.3935 - val_categorical_accuracy: 0.8995 - val_loss: 0.3898\n",
      "Epoch 14/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - categorical_accuracy: 0.8983 - loss: 0.3933 - val_categorical_accuracy: 0.8997 - val_loss: 0.3904\n",
      "Epoch 15/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - categorical_accuracy: 0.8980 - loss: 0.3936 - val_categorical_accuracy: 0.8986 - val_loss: 0.3893\n",
      "Epoch 16/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - categorical_accuracy: 0.8983 - loss: 0.3918 - val_categorical_accuracy: 0.8998 - val_loss: 0.3882\n",
      "Epoch 17/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - categorical_accuracy: 0.8994 - loss: 0.3904 - val_categorical_accuracy: 0.8995 - val_loss: 0.3881\n",
      "Epoch 18/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - categorical_accuracy: 0.8992 - loss: 0.3893 - val_categorical_accuracy: 0.8999 - val_loss: 0.3854\n",
      "Epoch 19/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - categorical_accuracy: 0.9005 - loss: 0.3842 - val_categorical_accuracy: 0.9001 - val_loss: 0.3839\n",
      "Epoch 20/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - categorical_accuracy: 0.8992 - loss: 0.3879 - val_categorical_accuracy: 0.9001 - val_loss: 0.3852\n",
      "Epoch 21/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - categorical_accuracy: 0.9000 - loss: 0.3841 - val_categorical_accuracy: 0.8999 - val_loss: 0.3845\n",
      "Epoch 22/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - categorical_accuracy: 0.8984 - loss: 0.3883 - val_categorical_accuracy: 0.9009 - val_loss: 0.3815\n",
      "Epoch 23/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686us/step - categorical_accuracy: 0.9008 - loss: 0.3826 - val_categorical_accuracy: 0.9011 - val_loss: 0.3811\n",
      "Epoch 24/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - categorical_accuracy: 0.8995 - loss: 0.3842 - val_categorical_accuracy: 0.9009 - val_loss: 0.3817\n",
      "Epoch 25/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - categorical_accuracy: 0.8993 - loss: 0.3864 - val_categorical_accuracy: 0.9034 - val_loss: 0.3826\n",
      "Epoch 26/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - categorical_accuracy: 0.9007 - loss: 0.3825 - val_categorical_accuracy: 0.9008 - val_loss: 0.3792\n",
      "Epoch 27/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - categorical_accuracy: 0.9014 - loss: 0.3819 - val_categorical_accuracy: 0.9037 - val_loss: 0.3778\n",
      "Epoch 28/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - categorical_accuracy: 0.9015 - loss: 0.3808 - val_categorical_accuracy: 0.9045 - val_loss: 0.3770\n",
      "Epoch 29/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - categorical_accuracy: 0.9019 - loss: 0.3791 - val_categorical_accuracy: 0.9046 - val_loss: 0.3760\n",
      "Epoch 30/30\n",
      "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - categorical_accuracy: 0.9029 - loss: 0.3766 - val_categorical_accuracy: 0.9052 - val_loss: 0.3747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519779.096058  507968 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_18', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:49:40,906] Trial 28 finished with value: 0.37115353958359804 and parameters: {'activation_l1': 'tanh', 'activation_l2': 'relu', 'activation_l3': 'relu', 'activation_l4': 'relu', 'batch_size': 196, 'decay_rate': 0.95, 'decay_steps': 1000, 'dropout_l1': 0.1, 'dropout_l2': 0.1, 'dropout_l3': 0.0, 'dropout_l4': 0.1, 'learning_rate_init': 0.001714579247369366, 'n_units_l1': 93, 'n_units_l2': 83, 'n_units_l3': 75, 'n_units_l4': 73, 'num_layers': 4}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519782.156870  508083 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_621', 592 bytes spill stores, 592 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519782.184200  508087 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_621', 596 bytes spill stores, 596 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m430/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 468us/step - categorical_accuracy: 0.4484 - loss: 1.9169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519784.056880  508157 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_621', 596 bytes spill stores, 596 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519784.065796  508156 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_621', 592 bytes spill stores, 592 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519784.175506  508155 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_661', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4970 - loss: 1.7734  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762519785.531048  508245 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "I0000 00:00:1762519785.615540  508252 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_46', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - categorical_accuracy: 0.4974 - loss: 1.7723 - val_categorical_accuracy: 0.8544 - val_loss: 0.6711\n",
      "Epoch 2/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - categorical_accuracy: 0.8593 - loss: 0.6477 - val_categorical_accuracy: 0.8720 - val_loss: 0.5691\n",
      "Epoch 3/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - categorical_accuracy: 0.8715 - loss: 0.5753 - val_categorical_accuracy: 0.8756 - val_loss: 0.5400\n",
      "Epoch 4/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - categorical_accuracy: 0.8755 - loss: 0.5469 - val_categorical_accuracy: 0.8763 - val_loss: 0.5250\n",
      "Epoch 5/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - categorical_accuracy: 0.8764 - loss: 0.5351 - val_categorical_accuracy: 0.8769 - val_loss: 0.5154\n",
      "Epoch 6/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - categorical_accuracy: 0.8776 - loss: 0.5212 - val_categorical_accuracy: 0.8775 - val_loss: 0.5079\n",
      "Epoch 7/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - categorical_accuracy: 0.8787 - loss: 0.5156 - val_categorical_accuracy: 0.8780 - val_loss: 0.5018\n",
      "Epoch 8/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - categorical_accuracy: 0.8792 - loss: 0.5058 - val_categorical_accuracy: 0.8784 - val_loss: 0.4967\n",
      "Epoch 9/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - categorical_accuracy: 0.8791 - loss: 0.5028 - val_categorical_accuracy: 0.8786 - val_loss: 0.4920\n",
      "Epoch 10/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - categorical_accuracy: 0.8791 - loss: 0.4993 - val_categorical_accuracy: 0.8788 - val_loss: 0.4884\n",
      "Epoch 11/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - categorical_accuracy: 0.8793 - loss: 0.4958 - val_categorical_accuracy: 0.8794 - val_loss: 0.4858\n",
      "Epoch 12/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - categorical_accuracy: 0.8801 - loss: 0.4922 - val_categorical_accuracy: 0.8795 - val_loss: 0.4820\n",
      "Epoch 13/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - categorical_accuracy: 0.8796 - loss: 0.4895 - val_categorical_accuracy: 0.8796 - val_loss: 0.4794\n",
      "Epoch 14/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - categorical_accuracy: 0.8805 - loss: 0.4858 - val_categorical_accuracy: 0.8799 - val_loss: 0.4770\n",
      "Epoch 15/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - categorical_accuracy: 0.8804 - loss: 0.4819 - val_categorical_accuracy: 0.8799 - val_loss: 0.4747\n",
      "Epoch 16/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - categorical_accuracy: 0.8806 - loss: 0.4808 - val_categorical_accuracy: 0.8801 - val_loss: 0.4727\n",
      "Epoch 17/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - categorical_accuracy: 0.8812 - loss: 0.4764 - val_categorical_accuracy: 0.8802 - val_loss: 0.4705\n",
      "Epoch 18/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - categorical_accuracy: 0.8815 - loss: 0.4742 - val_categorical_accuracy: 0.8802 - val_loss: 0.4688\n",
      "Epoch 19/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - categorical_accuracy: 0.8812 - loss: 0.4729 - val_categorical_accuracy: 0.8803 - val_loss: 0.4676\n",
      "Epoch 20/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - categorical_accuracy: 0.8822 - loss: 0.4699 - val_categorical_accuracy: 0.8804 - val_loss: 0.4658\n",
      "Epoch 21/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - categorical_accuracy: 0.8831 - loss: 0.4672 - val_categorical_accuracy: 0.8804 - val_loss: 0.4646\n",
      "Epoch 22/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - categorical_accuracy: 0.8817 - loss: 0.4691 - val_categorical_accuracy: 0.8805 - val_loss: 0.4633\n",
      "Epoch 23/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - categorical_accuracy: 0.8814 - loss: 0.4691 - val_categorical_accuracy: 0.8805 - val_loss: 0.4624\n",
      "Epoch 24/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - categorical_accuracy: 0.8818 - loss: 0.4661 - val_categorical_accuracy: 0.8805 - val_loss: 0.4612\n",
      "Epoch 25/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - categorical_accuracy: 0.8823 - loss: 0.4656 - val_categorical_accuracy: 0.8807 - val_loss: 0.4601\n",
      "Epoch 26/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - categorical_accuracy: 0.8820 - loss: 0.4658 - val_categorical_accuracy: 0.8807 - val_loss: 0.4592\n",
      "Epoch 27/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - categorical_accuracy: 0.8830 - loss: 0.4618 - val_categorical_accuracy: 0.8807 - val_loss: 0.4584\n",
      "Epoch 28/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - categorical_accuracy: 0.8822 - loss: 0.4659 - val_categorical_accuracy: 0.8808 - val_loss: 0.4580\n",
      "Epoch 29/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - categorical_accuracy: 0.8842 - loss: 0.4598 - val_categorical_accuracy: 0.8808 - val_loss: 0.4567\n",
      "Epoch 30/30\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - categorical_accuracy: 0.8829 - loss: 0.4645 - val_categorical_accuracy: 0.8815 - val_loss: 0.4560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/flower_py3-10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2025-11-07 13:50:02,485] Trial 29 finished with value: 0.4528050302101597 and parameters: {'activation_l1': 'relu', 'batch_size': 498, 'decay_rate': 0.9, 'decay_steps': 2000, 'dropout_l1': 0.2, 'learning_rate_init': 0.0003838187805115565, 'n_units_l1': 117, 'num_layers': 1}. Best is trial 11 with value: 0.36115995079696805.\n"
     ]
    }
   ],
   "source": [
    "study = optuna_create_study(\"mlp_edge_iiot_coreset\", direction=['minimize'])\n",
    "study.optimize(edge_iiot_coreset_optimization, n_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electric Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search MLP HAR\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "metric_list = [\"MAE\"]\n",
    "\n",
    "dataset_factory = dataset_model_dictionary[\"electric-consumption\"]()\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def electric_consumption_optimisation(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    shape: int\n",
    "    try: shape = y_train.shape[1] \n",
    "    except: shape = 1\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=shape, parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna_create_study(\"mlp_electric_consumption\", direction=['minimize'])\n",
    "study.optimize(electric_consumption_optimisation, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def electric_consumption_optimisation_xgboost(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"xgboost\")\n",
    "    dmatrix = xgb.DMatrix(X_train, label=y_train)\n",
    "    dmatrix_test = xgb.DMatrix(X_test, label=y_test)\n",
    "    shape: int\n",
    "    try: shape = y_train.shape[1] \n",
    "    except: shape = 1\n",
    "\n",
    "    xgboost_hyperparameters = get_xgboost_tree(input_dim=X_train.shape[1], num_classes=shape, parameters=parameters)\n",
    "    bst = xgb.train(xgboost_hyperparameters, dmatrix, evals=[(dmatrix_test, \"validate\"), (dmatrix, \"train\")], num_boost_round=2000, early_stopping_rounds=5) \n",
    "    eval_results = bst.eval(dmatrix_test)\n",
    "    loss = round(float(eval_results.split(\"\\t\")[1].split(\":\")[1]), 4)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna_create_study(\"xgboost_electric_consumption\", direction=['minimize'])\n",
    "study.optimize(electric_consumption_optimisation_xgboost, n_trials=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower_py3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
