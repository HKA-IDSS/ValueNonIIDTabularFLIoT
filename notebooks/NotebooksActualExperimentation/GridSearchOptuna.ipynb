{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Hyperparameter Optimisation\n",
    "\n",
    "This notebook is used to perform the Hyperparameter Optimisation (HO) of the centralised model on centralised data. The centralised model serves as a reference of the gold standard that can be achieved in Federated Learning. For this reason, we also run HO in the centralised data. The code of this notebook uses an interface that we developed for communication with [Optuna](https://optuna.org/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..' + os.sep + '..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_parameters.model_builder.ModelBuilder import Director, get_training_configuration\n",
    "from metrics.Metrics import DictOfMetrics\n",
    "from metrics.Evaluator import evaluator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Factory\n",
    "\n",
    "We use the director pattern for generating models with different configurations given by Optuna. The hyperparameters of the model are given by optuna using _trial_. We use [Cross Entropy Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss) for classification and [Median Absolute Error](https://en.wikipedia.org/wiki/Mean_absolute_error) for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director = Director()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(trial, model_type):\n",
    "    parameters = get_training_configuration(trial=trial, model_type=model_type)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp(input_dim, num_classes, parameters):\n",
    "    return director.create_mlp(input_parameters=input_dim, num_classes=num_classes, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgboost_tree(input_dim, num_classes, parameters):\n",
    "    return director.create_xgboost(input_parameters=input_dim, num_classes=num_classes, parameters=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We offer a quick training using the Wine dataset, so you can check if the code works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [\"CrossEntropyLoss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_factory = dataset_model_dictionary[\"wine\"]()\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine_mlp_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"mlp_wine\", direction=['minimize'])\n",
    "study.optimize(wine_mlp_optimization, n_trials=60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP HAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code for optimisation on the Human Activity Recognition(HAR) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_factory = dataset_model_dictionary[\"har\"]()\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def har_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, epochs=20, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna_create_study(\"mlp_har\", direction=['minimize'])\n",
    "study.optimize(har_optimization, n_trials=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Edge-IIOT-Coreset\n",
    "\n",
    "This is the code for optimisation on the IIoT attack dataset, with the reduction using the _Coreset_ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search MLP HAR\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "dataset_factory = dataset_model_dictionary[\"edge-iot-coreset\"]()\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_iiot_coreset_optimization(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=y_train.shape[1], parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, epochs=30, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna_create_study(\"mlp_edge_iiot_coreset\", direction=['minimize'])\n",
    "study.optimize(edge_iiot_coreset_optimization, n_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Electric Consumption\n",
    "\n",
    "This is the code for optimisation on the Electric Consumption dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search MLP HAR\n",
    "from experiment_parameters.TrainerFactory import dataset_model_dictionary\n",
    "from util.OptunaConnection import optuna_create_study\n",
    "\n",
    "metric_list = [\"MAE\"]\n",
    "\n",
    "dataset_factory = dataset_model_dictionary[\"electric-consumption\"]()\n",
    "X_train, y_train = dataset_factory.get_dataset().get_training_data()\n",
    "X_test, y_test = dataset_factory.get_dataset().get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def electric_consumption_optimisation(trial):\n",
    "    parameters = get_parameters(trial=trial, model_type=\"mlp\")\n",
    "    shape: int\n",
    "    try: shape = y_train.shape[1] \n",
    "    except: shape = 1\n",
    "    ml_model = get_mlp(input_dim=X_train.shape[1], num_classes=shape, parameters=parameters)\n",
    "    ml_model.fit(X_train, y_train, batch_size=parameters[\"batch_size\"]) \n",
    "    metrics: DictOfMetrics = evaluator(X_train, y_train, ml_model, metric_list)\n",
    "    return metrics.get_value_of_metric(\"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna_create_study(\"mlp_electric_consumption\", direction=['minimize'])\n",
    "study.optimize(electric_consumption_optimisation, n_trials=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repo_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
